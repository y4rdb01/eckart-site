<!doctype HTML public "-//W3C//DTD HTML 3.2//EN">
<html lang="en">
<head>
<title>Dr. J Dana Eckart</title>
<link rev="mail" href="mailto:eckart_dana@columbusstate.edu">
</head>
<body>

<!--
	This is the primary overall style for the web site.
-->
<style>
	A:link    { color: #007a00; text-decoration: underline }
	A:visited { color: #7a0000; text-decoration: none }
	A:hover   { text-decoration: none }
	A:active  { color: #ff0000; text-decoration: none }
	Body	{ background-color: #ffffe5; color: #000000 }
	Body	{ font-size: 12pt }
	Address	{ font-size: 10pt }
	Table	{ font-size: 12pt }
	Th, Td	{ vertical-align: top }
	Th, Td	{ padding: 5px }
</style>

<p style="text-align: center; margin: auto; font-size: 150%">
	<strong>Dr. J Dana Eckart</strong>: Operating Systems (CPSC 3125)
	- Study Questions for Final Exam
</p>

<style type="text/css">
	ol.question_list {list-style-type: none;}
	ol.question_list li:before {content: counter(question, decimal) ") ";}
	ol.question_list li { counter-increment: question;}

	ol.answer_list {list-style-type: none;}
	ol.answer_list li:before {content: counter(answer, lower-latin) ") ";}
	ol.answer_list li { counter-increment: answer;}

	ol.match_list {list-style-type: none;}
	ol.match_list li:before {content: counter(match, upper-latin) ") ";}
	ol.match_list li { counter-increment: match;}

	ul.bullet_list {list-style-type: disc;}
	ul.bullet_list li:before {content: "";}
	ul.bullet_list li { counter-increment: bogus;}
</style>

<p>
The following list of exam study questions are provided as a means to help you
assess your understanding of the topics presented in class. While every
reasonable attempt has been made to create a comprehensive list of questions,
they should <strong>not</strong> be the only means by which you assess your
own understanding of the course materials. While many of these questions
may appear on your exam, be aware that the exam may include questions
that do not appear below. However, it is unlikely you will perform well on
the exam if you have difficulty answering these questions correctly.
</p>


<ol class="question_list">
<li> Many of the statements in "C" are similar to those in "Java" since
	<ol class="answer_list">
	<li> C is based on the design of Java.
	<li> C is a design ancestor of C++ and Java.
	<li> All programming languages use the same style of statements.
	<li> Both C and Java share Eiffel as a common design ancestor.
	<li> None of the above
	</ol>
</li><br/>
<li> C has primitive types that are built into the language, but which of the
	following are <strong>not</strong> primitive types in C?
	<ol class="answer_list">
	<li> bool
	<li> string
	<li> int
	<li> char
	<li> None of the above
	</ol>
</li><br/>
<li> C has primitive types that are built into the language, but which of the
	following are <strong>not</strong> primitive types in C?
	<ol class="answer_list">
	<li> bool
	<li> int
	<li> float
	<li> string
	<li> None of the above
	</ol>
</li><br/>
<li> Whenever a boolean type result is required in C (e.g., in an "if"
	statement),
	<ol class="answer_list">
	<li> Any non-zero value represents false.
	<li> Only the zero value represents false.
	<li> Only one value represents true.
	<li> Any non-zero value represents true.
	<li> None of the above
	</ol>
</li><br/>
<li> In C, "&&" and "||" are short-circuit boolean operators just like in
	Java, while the "&" and "|" operators in C
	<ol class="answer_list">
	<li> Perform full boolean evaluation.
	<li> Are undefined.
	<li> Are synonyms for "&&" and "||".
	<li> Perform the bitwise-and and bitwise-or functions.
	<li> None of the above
	</ol>
</li><br/>
<li> The "!" operator in C is used to perform
	<ol class="answer_list">
	<li> Logical negation (e.g., turn "true" into "false").
	<li> Numeric negation (e.g., turn "-3" into "3").
	<li> Numeric inversion (e.g., turn "5" into "1/5").
	<li> Array reversal (reversing the items within an array).
	<li> None of the above
	</ol>
</li><br/>
<li> The assignment operator (=) in C
	<ol class="answer_list">
	<li> works exactly like assignment in Java.
	<li> cannot be used in boolean expressions.
	<li> cannot be used in arithmetic expressions.
	<li> returns the value assigned as its value.
	<li> None of the above
	</ol>
</li><br/>
<li> The assignment operator (=) in C
	<ol class="answer_list">
	<li> is also the equality operator.
	<li> tests for equality, but only when used in boolean expressions.
	<li> cannot be used in arithmetic expressions.
	<li> returns the value assigned as its value.
	<li> None of the above
	</ol>
</li><br/>
<li> Which pairs of operators can be easy to confuse but difficult to notice
	and debug because they can often (though not always) yield the same
	results?
	<ol class="answer_list">
	<li> + and ++
	<li> = and ==
	<li> & and &&
	<li> | and ||
	<li> None of the above
	</ol>
</li><br/>
<li> This example of a pre-increment operator, "x = 12; array[++x] = 3;",
	assigns
	<ol class="answer_list">
	<li> "array[12]" the value of 3 
	<li> "array[13]" the value of 3
	<li> "array[12]" the value of 4
	<li> "array[13]" the value of 4
	<li> None of the above
	</ol>
</li><br/>
<li> This example of a compound assignment, "x = 12; array[x += 2] = 5;",
	<ol class="answer_list">
	<li> is <strong>not</strong> allowed.
	<li> assigns "array[12]" the value of 5
	<li> assigns "array[14]" the value of 5
	<li> assigns "x" the value of 7
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> used for either
	input or output in C?
	<ol class="answer_list">
	<li> scanf
	<li> getc
	<li> printf
	<li> fprintf
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are used for input in C?
	<ol class="answer_list">
	<li> scanf
	<li> getc
	<li> printf
	<li> fprintf
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are used for output in C?
	<ol class="answer_list">
	<li> scanf
	<li> getc
	<li> printf
	<li> fprintf
	<li> None of the above
	</ol>
</li><br/>
<li> All C programs should contain a "main" function with a signature matching
        <ol class="answer_list">
        <li> void main(char* argv[])
        <li> int main(string argv[])
        <li> void main(int argc, string argv[])
        <li> int main(int argc, char* argv[])
        <li> None of the above
        </ol>
</li><br/>
<li> The int value returned by the "main" function is used to indicate
	<ol class="answer_list">
	<li> whether or not the program terminated normally.
	<li> nothing, this is a holdover from early Unix that is no longer used.
	<li> how long (in milliseconds) the program took to complete.
	<li> the error a program experienced if there was a problem.
	<li> None of the above
	</ol>
</li><br/>
<li> Function declarations in C <strong>must always</strong> have
	<ol class="answer_list">
	<li> an implementation given as part of the declaration.
	<li> only primitive types given as formal parameters.
	<li> a non-empty set of formal parameters.
	<li> a non-void return type.
	<li> None of the above
	</ol>
</li><br/>
<li> Function declarations (though not necessarily their implementations) in C
	<ol class="answer_list">
	<li> <strong>must</strong> be given inside of a class definition.
	<li> <strong>must</strong> appear within the source code file in
		which they are used.
	<li> can be nested within another function's implementation/body.
	<li> <strong>must</strong> be given in a separate file (a ".h" file)
		from their implementation.
	<li> None of the above
	</ol>
</li><br/>
<li> Function implementations in C
	<ol class="answer_list">
	<li> cannot be given within another function's implementation/body.
	<li> begin with the "function" reserved keyword, if given separate
		from the function declaration.
	<li> <strong>must always</strong> be given at the same time the
		function is declared.
	<li> appear within curly braces (i.e., { }) directly after the
		function signature.
	<li> None of the above
	</ol>
</li><br/>
<li> A "static" variable declaration within a function
	<ol class="answer_list">
	<li> reserves space for the variable apart from the run-time stack.
	<li> allows the variable to be accessed outside of the function
		implementation.
	<li> ensures that only one version of the variable exists, so that
		recursive calls to the function share the exact same variable
		storage.
	<li> is optional as <strong>all</strong> variables within function
		implementations are treated as "static" by default.
	<li> None of the above
	</ol>
</li><br/>
<li> Variables declared as "static"
	<ol class="answer_list">
	<li> may only appear within a function implementation.
	<li> can be accessed outside the scope of the function in which
		it is declared.
	<li> cannot change their values (i.e., they're constants).
	<li> have space for their values reserved outside of the run-time stack.
	<li> None of the above
	</ol>
</li><br/>
<li> Large C programs are often broken up into files ending with ".c" and ".h", 
	but
	<ol class="answer_list">
	<li> ".c" files <strong>must</strong> contain only function
		implementations.
	<li> ".h" files should contain declarations used by multiple ".c" files.
	<li> the "#include" directives allow ".c" files to use the declarations
		in the named ".h" file.
	<li> variables should <strong>never</strong> be delcared in a ".h" file.
	<li> None of the above
	</ol>
</li><br/>
<li> The "extern" declaration in C is
	<ol class="answer_list">
	<li> used to declare variables <strong>without</strong> setting
		aside storage space.
	<li> implicit for <strong>all</strong> function declarations.
	<li> used for variables declared within a function so that they can be
		accessed outside of the function.
	<li> have space for their values reserved outside of the run-time stack.
	<li> None of the above
	</ol>
</li><br/>

<li> Arrays in C are indexed starting with
	<ol class="answer_list">
	<li> -1
	<li> 0
	<li> 1
	<li> the value indicated when they are declared. 
	<li> None of the above
	</ol>
</li><br/>
<li> The index given for an array reference in C
	<ol class="answer_list">
	<li> only needs to be checked at <em>compile time</em> to ensure that
		it's within range. 
	<li> is <strong>always</strong> checked at <em>run time</em> to ensure
		that it's within range.
	<li> <strong>never</strong> needs to be checked as it is
		<strong>always</strong> within range.
	<li> is <strong>not</strong> checked since it doesn't have to be
		within its range.
	<li> None of the above
	</ol>
</li><br/>
<li> A "string" value in C is really an array of type "char". So the
	<ol class="answer_list">
	<li> string value needs to be null terminated.
	<li> array <strong>must</strong> be exactly as long as the desired
		string.
	<li> array should be at least one char longer than the desired string.
	<li> programer <strong>must</strong> use another variable to keep
		track of the length of the string.
	<li> None of the above
	</ol>
</li><br/>
<li> If an array index in C is outside the bounds of the array, then
	<ol class="answer_list">
	<li> an error may or may not occur as a result of accessing the array
		element.
	<li> an error <strong>always</strong> occurs and the program stops
		execution.
	<li> there may or may not be accessible storage associated with
		that array location.
	<li> there is <strong>always</strong> accessible storage associated
		with that array location.
	<li> None of the above
	</ol>
</li><br/>
<li> The declaration of an array (e.g., variables, function formal parameters)
	<strong>must always</strong> include the
	<ol class="answer_list">
	<li> starting index of the array.
	<li> size of the array.
	<li> corresponding "#define" declaration for the array size.
	<li> type of the array elements.
	<li> None of the above
	</ol>
</li><br/>
<li> Arrays in C
	<ol class="answer_list">
	<li> grow dynamically as more items are added (similar to
		<em>ArrayList</em>s in Java).
	<li> <strong>always</strong> have an associated length that can be
		queried to determine the number of items in the array.
	<li> are polymorphic, meaning that any mix of items can be stored in
		the same array.
	<li> are really just pointers to their item type (e.g., "int x[]" and
		"int *x" are the same).
	<li> None of the above
	</ol>
</li><br/>
<li> A pointer is another name for the
	<ol class="answer_list">
	<li> type of values that can be assigned to a variable.
	<li> forward declaration of a function.
	<li> declaration of a "struct"ure.
	<li> address of the memory location holding a desired value.
	<li> None of the above
	</ol>
</li><br/>
<li> In C, pointers are declared
	<ol class="answer_list">
	<li> only for declarations of arrays.
	<li> by giving an asterisk (*) before the variable name declaration.
	<li> by giving an ampersand (&) before the variable name declaration.
	<li> for <strong>all</strong> formal parameters of functions.
	<li> None of the above
	</ol>
</li><br/>
<li> In C, if "x" and "y" are declared by "int x, *y;", then "y = &x;"
	<ol class="answer_list">
	<li> is undefined.
	<li> assigns "y" the value of "x".
	<li> makes "y" an alias for "x" so that any value assigned to one
		is automatically assigned to the other.
	<li> assigns "y" the memory address where the value for "x" is located.
	<li> None of the above
	</ol>
</li><br/>
<li> This array declaration in C, "char name[10];",
	<ol class="answer_list">
	<li> reserves 10 contiguous bytes (characters) of storage for "name".
	<li> is equivalent to the declaration "string name;".
	<li> declares "name" as a pointer to the reserved storage.
	<li> declares each element of the array "name" as a pointer to a "char".
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following declarations in C is equivalent to "char *var;"?
	<ol class="answer_list">
	<li> char &var;
	<li> char var[10];
	<li> char var[];
	<li> char &var[];
	<li> None of the above
	</ol>
</li><br/>
<li> Strings in C are represented as an array of "char"acters
	<ol class="answer_list">
	<li> with the length kept separately so that the size of the string
		is known (e.g., when printing).
	<li> that are terminated by a null value to denote their end.
	<li> and can be referenced via a "char"acter pointer (e.g., "char *").
	<li> which are immutable, so that the value cannot be changed
		(only copied).
	<li> None of the above
	</ol>
</li><br/>
<li> The address operator in C, ampersand (&),
	<ol class="answer_list">
	<li> converts a variable into a pointer, so that "&y" makes "y" a
		pointer to an "int" when "y" was declared via "int y;".
	<li> is only used when passing parameters.
	<li> returns the memory address of any expression it is applied to
		(e.g., "&(2*x + 3)").
	<li> returns the memory address of the variable it is applied to
		(e.g., "&x").
	<li> None of the above
	</ol>
</li><br/>
<li> In C, if the following declaration/initialization is made,
	"int *x = &y;", then "x++"
	<ol class="answer_list">
	<li> makes "x" point to the next address in memory (following "y")
		that can hold an "int" value.
	<li> is undefined and causes a compilation error.
	<li> is defined but causes a run-time error.
	<li> increases the value of "y" by 1.
	<li> None of the above
	</ol>
</li><br/>
<li> Write a C program that takes a single command line argument and prints
	"YES" if the argument is a palindrome, and "NO" otherwise. The
	program should <strong>not</strong> declare any additional arrays
	other than the one that is a parameter to "main".
</li><br/>
<li> Write a C program that reverses the input given to it. So that the last
	character on the last line of input will be the first one printed.
	You may assume that the input is no more than 2047 characters long.
</li><br/>
<li> Write a C program that reads floats from the input, calculates and prints
	out their average, and indicates how many of the original values were
	above and how many were below the average.
	You may assume that there are no more than 2047 numbers in the input.
</li><br/>

<li> A "struct" declaration in C can group together
	<ol class="answer_list">
	<li> multiple data items.
	<li> data of the same type.
	<li> data of different types.
	<li> None of the above
	</ol>
</li><br/>
<li> A "struct" declaration in C <strong>always</strong> creates
	<ol class="answer_list">
	<li> a new type name that can be used in declaring variables (e.g.,
		"person bob;").
	<li> a named structure form that can be referred to by "struct"
		followed by the structure name (e.g., "struct person").
	<li> a recursive structure so that linked structures (e.g., lists,
		graphs) can be coded.
	<li> a non-recursive structure since recursive structures
		<strong>must</strong> be declared as types instead of "struct"s.
	<li> None of the above
	</ol>
</li><br/>
<li> A self-recursive "struct" requires that at least one of its elements be
	declared as
	<ol class="answer_list">
	<li> "struct NAME", where "NAME" is the name given the "struct" and the
		pointer type is inferred.
	<li> "struct NAME *", where "NAME" is the name given the "struct".
	<li> "struct" where the current structure and pointer type are inferred.
	<li> "struct *" where the current structure name is inferred.
	<li> None of the above
	</ol>
</li><br/>
<li> The "typedef" declaration in C declares the new type NAME corresponding
	to a specified TYPE_DESCRIPTION (either an existing type name or other
	type specification - such as a "struct") via
	<ol class="answer_list">
	<li> "typedef NAME = TYPE_DESCRIPTION;"
	<li> "typedef TYPE_DESCRIPTION NAME;"
	<li> "typedef NAME TYPE_DESCRIPTION;"
	<li> "NAME = typedef TYPE_DESCRIPTION;"
	<li> None of the above
	</ol>
</li><br/>
<li> Assuming the legal C variable declaration "person bob;" then the following
	declaration <strong>must</strong> also have been previously given
	("..." represents other appropriate declarations):
	<ol class="answer_list">
	<li> "struct bob { ... };"
	<li> "typedef struct person { ... } bob;"
	<li> "typedef struct bob bob;"
	<li> "typedef person bob;"
	<li> None of the above
	</ol>
</li><br/>
<li> Assuming the legal C variable declaration "person bob;" then the following
	declaration <strong>must</strong> also have been previously given
	("..." represents other appropriate declarations):
	<ol class="answer_list">
	<li> "struct person { ... };"
	<li> "typedef struct { ... } person;"
	<li> "typedef struct person bob;"
	<li> "typedef person bob;"
	<li> None of the above
	</ol>
</li><br/>
<li> Given the following legal C declarations
<pre><code>
	typedef struct node {
		int x;
		struct node *next;
	} *nodeType;
</code></pre>
	<ol class="answer_list">
	<li> "nodeType" is a type equivalent to "struct node".
	<li> "nodeType" is a type equivalent to the type of the "next" field.
	<li> "nodeType" is <strong>not</strong> a type, but really a variable
		of type "struct node".
	<li> "nodeType" is <strong>not</strong> a type, but really a variable
		of type pointer to a "struct node".
	<li> None of the above
	</ol>
</li><br/>
<li> In C, the standard way to request heap storage space while a program is
	running is to use the function
	<ol class="answer_list">
	<li> <em>getmem</em>
	<li> <em>new</em>
	<li> <em>allocate</em>
	<li> <em>heap_request</em>
	<li> None of the above
	</ol>
</li><br/>
<li> In C, the standard way to request heap storage space while a program is
	running is to use the function
	<ol class="answer_list">
	<li> <em>malloc</em>
	<li> <em>new</em>
	<li> <em>getmem</em>
	<li> <em>getheap</em>
	<li> None of the above
	</ol>
</li><br/>
<li> The standard way in C to return heap storage that was previously allocated
	is to use the function
	<ol class="answer_list">
	<li> <em>delete</em>
	<li> <em>return</em>
	<li> <em>free</em>
	<li> <em>putmem</em>
	<li> None of the above
	</ol>
</li><br/>
<li> In C, it is possible to determine the size of a type (in bytes) by using
	the function
	<ol class="answer_list">
	<li> <em>getsize</em>
	<li> <em>sizeof</em>
	<li> <em>sizeOfType</em>
	<li> <em>typeSize</em>
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following C statements is a typical way that dynamic storage
	might be allocated?
	<ol class="answer_list">
	<li> int x = new int();
	<li> int *x = (int) getmem(int);
	<li> int x = malloc(typeSize(int));
	<li> int *x = (int*) malloc(sizeof(int));
	<li> None of the above
	</ol>
</li><br/>
<li> Write a C program that reads in text of unknown length and prints out
	"YES" if the text forms a palindrome and "NO" if it does not. The
	program <strong>must not</strong> assume a maximal length of the text
	that is read in, and <em>must avoid</em> using arraylist and realloc.
</li><br/>
<li> Write a C program that reads in a list of words (given one per line) and
	prints them out (one word per line) in sorted order. You
	<strong>must</strong> write your own sorting routine (insertion sort
	is recommended). The solution may use arrays and malloc, but
	<strong>must avoid</strong> using arraylist and realloc.
</li><br/>
<li> Write a C program that reads floats from the input, calculates and prints
	out their average, and indicates how many of the original values were
	above and how many were below the average. The program <strong>must
	not</strong> assume a maximal numbers of input, and
	<strong>must avoid</strong> using arraylist and realloc.
</li><br/>

<li> An operating system (OS) provides
	<ol class="answer_list">
	<li> a clean and simple model of the computer.
	<li> manages the computer's resources.
	<li> support for the creation and use of user programs.
	<li> an abstract view of the computer, independent of the specific
		hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are program <em>types</em> in an operating system
	(OS)?
	<ol class="answer_list">
	<li> System programs
	<li> Adventure games.
	<li> Application programs
	<li> CAPTCHAs (Completely Automated Public Turing test to tell
		Computers and Humans Apart).
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are layers <strong>within</strong> an
	operating system (OS)?
	<ol class="answer_list">
	<li> Machine language
	<li> Command interpreter (shell)
	<li> Physical devices
	<li> Microcode
	<li> None of the above
	</ol>
</li><br/>
<li> The operating system (OS) is that part of the system which
	<ol class="answer_list">
	<li> implements the editors, compilers, and interpreters used to
		create other programs.
	<li> provides the command line interpreter (e.g., shell) for users.
	<li> comes pre-loaded on purchased computer hardware.
	<li> runs in supervisor (or kernel) mode.
	<li> None of the above
	</ol>
</li><br/>
<li> When viewed as an abstract machine, the operating system (OS)
	<ol class="answer_list">
	<li> enables Windows and Unix to run at the same time.
	<li> hides the details of lower level facilities (e.g., writing data
		to disk).
	<li> operates exactly the way a Turing machine does.
	<li> provides the implementations for data abstractions (e.g., stack,
		queue) leveraged by user programs.
	<li> None of the above
	</ol>
</li><br/>
<li> When viewed as a resource manager, the operating system (OS)
	<ol class="answer_list">
	<li> coordinates the sharing of parts of the computer by different
		programs.
	<li> enables different programs to share the computer hardware.
	<li> determines when more memory or disk should be purchased.
	<li> ensures that the computer hardware is utilized with optimal
		efficiency regarding every user's needs.
	<li> None of the above
	</ol>
</li><br/>

<li> The most common small computer architecture is the
	<ol class="answer_list">
	<li> packet switched.
	<li> bus.
	<li> circuit switched.
	<li> fully connected backplane.
	<li> None of the above
	</ol>
</li><br/>
<li> Match the components in the below diagram (indicated by the letters A-G)
	of a typical small computer system to their names.
	<br/>
	<img src="/eckart/classes/cpsc3125/questions/SystemArch.png" width="532" height="394" alt="Simple computer architecture" />
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> Control bus
		<li> Instruction decoder
		<li> Memory
		<li> System bus
		<li> Input and Output
		<li> Peripheral bus
		<li> CPU
		<li> Address bus
		<li> Memory interface
		<li> Data bus
		</ol>
	</td></tr></table>
</li><br/>
<li> The system bus on a small computer system is typically composed of the
	<ol class="answer_list">
	<li> control bus.
	<li> address bus
	<li> data bus.
	<li> memory bus.
	<li> None of the above
	</ol>
</li><br/>
<li> A bus architecture typically allows
	<ol class="answer_list">
	<li> only a single pair of components to communicate at a time.
	<li> one or two different pairs of components to communicate
		simultaneously.
	<li> up to three different components (<strong>not</strong> pairs)
		to communicate simultaneously.
	<li> <strong>all</strong> components to communicate simultaneously.
	<li> None of the above
	</ol>
</li><br/>
<li> The internet is an example of a
	<ol class="answer_list">
	<li> packet switched architecture.
	<li> bus architecture.
	<li> circuit switched architecture.
	<li> fully connected architecture.
	<li> None of the above
	</ol>
</li><br/>
<li> A computer processor is commonly composed of
	<ol class="answer_list">
	<li> an instruction fetch unit.
	<li> an instruction decoder.
	<li> an arithmetic logic unit.
	<li> a memory interface.
	<li> None of the above
	</ol>
</li><br/>
<li> Match the components in the below diagram (indicated by the letters A-E)
	of a typical computer processor to their names. [Note: No choice is
	used more than once, and some may not be used.]
	<br/>
	<img src="/eckart/classes/cpsc3125/questions/CPUarch.png" alt="CPU" width="663" height="525" />
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> Registers
		<li> Control bus
		<li> Translation Lookaside Buffer (TLB)
		<li> Instruction decoder
		<li> Direct Memory Access (DMA)
		<li> Arithmetic Logic Unit (ALU)
		<li> Instruction fetcher
		<li> Address bus
		<li> Memory interface
		<li> Data bus
		</ol>
	</td></tr></table>
</li><br/>
<li> Registers in those processors which utilize them
	<ol class="answer_list">
	<li> are <strong>always</strong> grouped into sets of "register windows".
	<li> are <strong>sometimes</strong> dedicated to specific purposes
		(e.g., program counter, stack pointer).
	<li> are <strong>always</strong> general purpose, meaning they can be
		used for any activity needing to use a register.
	<li> usually have the same number of bits as the address bus.
	<li> None of the above
	</ol>
</li><br/>
<li> Processor designs that can speed up computation include:
	<ol class="answer_list">
	<li> pipelining
	<li> multi-register
	<li> hyperthreaded
	<li> multi-core
	<li> None of the above
	</ol>
</li><br/>
<li> The memory hierarchy in computer design primarily reflects the
	<ol class="answer_list">
	<li> desire to reduce single points of failure.
	<li> tradeoff between speed and cost for a given amount of memory.
	<li> difference between volatile and non-volatile memory technologies.
	<li> large amounts of certain types of memories.
	<li> None of the above
	</ol>
</li><br/>
<li> A hard disk drive (HDD) can have access times that are
	<ol class="answer_list">
	<li> up to 10 million times slower than a register.
	<li> 10-100 times slower than a solid state disk (SSD).
	<li> only 100 times slower than main memory (e.g., RAM).
	<li> 1 million times slower than main memory (e.g., RAM).
	<li> None of the above
	</ol>
</li><br/>
<li> Physical devices are accessed via their
	<ol class="answer_list">
	<li> corresponding user level resource managers.
	<li> associated (physical) controllers.
	<li> device drivers by the operating system (OS).
	<li> associated command interpreter (e.g., shell) programs.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are device communications styles used by
	operating systems?
	<ol class="answer_list">
	<li> Notify and Sleep
	<li> Busy waiting
	<li> Interrup driven
	<li> Direct Memory Access
	<li> None of the above
	</ol>
</li><br/>
<li> Approaches currently in common use for "installing" a new device driver
	include
	<ol class="answer_list">
	<li> relinking the device driver object code with the OS kernel.
	<li> adding the device driver file to an OS config and rebooting.
	<li> adding the ".h" file to the OS config, recompiling the kernel,
		and then rebooting the system.
	<li> dynamically loading the device driver code (no reboot).
	<li> None of the above
	</ol>
</li><br/>
<li> Device drivers that start an I/O then sit in a tight loop, checking to
	see when the operation is complete are using the
	<ol class="answer_list">
	<li> Notify and Sleep communication style.
	<li> Busy waiting communication style.
	<li> Interrup driven communication style.
	<li> Direct Memory Access communication style.
	<li> None of the above
	</ol>
</li><br/>
<li> Device drivers that start an I/O but then block, returning control so
	that other work can be done until the driver is awakened by an
	interrupt are using the
	<ol class="answer_list">
	<li> Notify and Sleep communication style.
	<li> Busy waiting communication style.
	<li> Interrup driven communication style.
	<li> Direct Memory Access communication style.
	<li> None of the above
	</ol>
</li><br/>
<li> Device drivers that utilize special hardware to initiate and complete
	an entire data transfer are using the
	<ol class="answer_list">
	<li> Notify and Sleep communication style.
	<li> Busy waiting communication style.
	<li> Interrup driven communication style.
	<li> Direct Memory Access communication style.
	<li> None of the above
	</ol>
</li><br/>
<li> While the operating system (OS) is handling an interrupt
	<ol class="answer_list">
	<li> <strong>all</strong> other interrupts are disabled to ensure it
		completes.
	<li> only higher-priority interrupts are enabled.
	<li> <strong>all</strong> interrupts continue to be enabled,
		since none should be missed.
	<li> only interrupts of the same kind are enabled.
	<li> None of the above
	</ol>
</li><br/>
<li> The boot process for most small computer systems begins with the
	execution of the
	<ol class="answer_list">
	<li> hard disk drive device driver to allow loading of the OS
		executable file.
	<li> Basic Input/Output System (BIOS).
	<li> OS executable file directly from the boot device (e.g., HDD, SSD).
	<li> GRand Unified Bootloader (GRUB).
	<li> None of the above
	</ol>
</li><br/>

<li> The system calls that an OS makes available
	<ol class="answer_list">
	<li> can only be used by the OS.
	<li> <strong>must never</strong> be used by the OS
	<li> are the OS interface for user programs.
	<li> are provided as a convenience, but aren't really necessary.
	<li> None of the above
	</ol>
</li><br/>
<li> The difference(s) between a program and a process are
	<ol class="answer_list">
	<li> programs are static (non-executing).
	<li> programs are <strong>never</strong> part of the operating system.
	<li> processes also contain a run-time stack and program counter.
	<li> processes make use of system calls, but programs don't.
	<li> None of the above
	</ol>
</li><br/>
<li> A process
	<ol class="answer_list">
	<li> <strong>must</strong> use system calls to accomplish anything
		useful.
	<li> usually only directly communicates with its parent (or child)
		process(es).
	<li> may create a child process.
	<li> cannot use system calls unless it is being run by the
		administrator/root user.
	<li> None of the above
	</ol>
</li><br/>
<li> When a problem or unusual condition is encountered, a process can send
	signals to other processes. Processes receiving a signal
	<ol class="answer_list">
	<li> are required to provide a signal handler.
	<li> can specify specific functions to be called when a particular
		type of signal is received.
	<li> run the function named "sighand" to handle the signal.
	<li> run the specified signal handler function, which takes over
		execution when the signal is received. 
	<li> None of the above
	</ol>
</li><br/>
<li> Every process is limited by the restrictions placed upon it by the
	OS as determined by the process' associated
	<ol class="answer_list">
	<li> programming language in which the code was written.
	<li> program source code file.
	<li> working directory in the file system.
	<li> user identification (uid).
	<li> None of the above
	</ol>
</li><br/>
<li> The address space of a process
	<ol class="answer_list">
	<li> is the size of the program file for the process.
	<li> is the range of addressable bytes starting at 0 up to a maximum, 
		usually 2^N - 1 (where N is the number of address bits).
	<li> is the amount of main memory <em>initially</em>
		requested/needed by the process.
	<li> can be broken into smaller chunks so that programs larger than
		the amount of main memory can be executed.
	<li> None of the above
	</ol>
</li><br/>
<li> System calls <strong>must</strong> be used to create new
	<ol class="answer_list">
	<li> processes.
	<li> user accounts.
	<li> programs.
	<li> files or directories.
	<li> None of the above
	</ol>
</li><br/>
<li> Every process has an associated
	<ol class="answer_list">
	<li> system call for accessing it.
	<li> working directory in the file system.
	<li> user identification (uid).
	<li> address space.
	<li> None of the above
	</ol>
</li><br/>
<li> A file descriptor is a unsigned number that processes use to reference
	(e.g., read, write)
	<ol class="answer_list">
	<li> files that the process currently has open.
	<li> any file in the file system that the process is permitted to
		access/open.
	<li> entries in the process' table of active/open files.
	<li> <strong>all</strong> directories with the same user
		identification (uid) as the process.
	<li> None of the above
	</ol>
</li><br/>
<li> In addition to normal user files (e.g., text files) there are
	also special files that enable
	<ol class="answer_list">
	<li> users to create new file systems.
	<li> hard disk drives (HDDs) to look like files.
	<li> keyboards and mice to look like files.
	<li> processes to directly communicate with one another.
	<li> None of the above
	</ol>
</li><br/>
<li> Every OS has an I/O subsystem that
	<ol class="answer_list">
	<li> implements the details of <strong>all</strong>
		read/write operations.
	<li> performs <strong>all</strong> of the cryptographic functions.
	<li> manages the devices attached to the computer.
	<li> enforces <strong>all</strong> of the OS security measures.
	<li> None of the above
	</ol>
</li><br/>
<li> The command interpreter which provides the non-GUI interface to the OS is
	<ol class="answer_list">
	<li> an ordinary program that uses system calls to access the
		capabilities of the OS.
	<li> a special program that directly implements <strong>all</strong>
		of the available commands.
	<li> often called the "shell".
	<li> unique, with each system having only one such program available.
	<li> None of the above
	</ol>
</li><br/>

<li> Which system organization is <strong>best</strong> described as having:
	a set of service procedures that perform system calls; utility
	procedures to assist in service procedure implementation; and a
	main program that calls requested service procedures?
	<ol class="answer_list">
	<li> Monolithic System
	<li> Layered System
	<li> Micorkernel
	<li> Client-Server
	<li> None of the above
	</ol>
</li><br/>
<li> Which system organization is <strong>best</strong> described
	as a sequence of abstractions built one on top of the other?
	<ol class="answer_list">
	<li> Layered System
	<li> Micorkernel
	<li> Exokernel
	<li> Client-Server
	<li> None of the above
	</ol>
</li><br/>
<li> Which system organization is <strong>best</strong> described as having
	the absolute minimal portion of the OS facilities running in
	kernel/supervisor mode, with the remaining portions running in user
	mode?
	<ol class="answer_list">
	<li> Layered System
	<li> Micorkernel
	<li> Exokernel
	<li> Client-Server
	<li> None of the above
	</ol>
</li><br/>
<li> Which system organization <strong>best</strong> enables the clean
	separation of policy and mechanism?
	<ol class="answer_list">
	<li> Layered System
	<li> Micorkernel
	<li> Exokernel
	<li> Client-Server
	<li> None of the above
	</ol>
</li><br/>
<li> Which system organization is <strong>best</strong> suited for
	distributed systems?
	<ol class="answer_list">
	<li> Monolithic System
	<li> Layered System
	<li> Micorkernel
	<li> Client-Server
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are examples of a layered OS?
	<ol class="answer_list">
	<li> Minix v1
	<li> THE
	<li> Windows NT
	<li> MULTICS
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are examples of a microkernel OS?
	<ol class="answer_list">
	<li> Minix v1
	<li> THE
	<li> Windows NT
	<li> MULTICS
	<li> None of the above
	</ol>
</li><br/>
<li> A virtual machine is designed to
	<ol class="answer_list">
	<li> mimic any type of hardware so that older software can be run.
	<li> provide "copies" of the existing hardware so that multiple
		operating systems can be run at the same time.
	<li> allow the remote (aka "virtual") execution of programs on
		non-local hardware.
	<li> enable the use of virtual memory to run processes that require
		a larger address space than is otherwise supported by the
		hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> An OS that runs directly on the hardware and provides virtual machines in
	which other OSes can run, is called a(n)
	<ol class="answer_list">
	<li> type 1 hypervisor.
	<li> type 2 hypervisor.
	<li> exokernel.
	<li> microkernel.
	<li> None of the above
	</ol>
</li><br/>
<li> An OS that runs on top of a host OS (that in turn is running on top of
	the physical hardware), and which can host other OSes running on top
	of it, is called a(n)
	<ol class="answer_list">
	<li> type 1 hypervisor.
	<li> type 2 hypervisor.
	<li> exokernel.
	<li> microkernel.
	<li> None of the above
	</ol>
</li><br/>
<li> Software that divides up the underlying physical hardware so that each
	running OS has sole access to its assigned hardware is called a(n)
	<ol class="answer_list">
	<li> type 1 hypervisor.
	<li> type 2 hypervisor.
	<li> exokernel.
	<li> microkernel.
	<li> None of the above
	</ol>
</li><br/>
<li> A type 1 hypervisor
	<ol class="answer_list">
	<li> runs directly on the hardware and the operating systems run in
		the hypervisor.
	<li> runs on top of the host OS (which is running directly on the
		hardware).  Additional operating systems run in the hypervisor.
	<li> divides the hardware up into slices, with each OS running
		directly on the hardware. It ensures that each OS
		only uses the parts of the hardware is was assigned.
	<li> provides a microkernel used by each of the operating systems
		running in the hypervisor. Each OS uses the microkernel
		system calls to interact with the hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> A type 2 hypervisor
	<ol class="answer_list">
	<li> runs directly on the hardware and the operating systems run in
		the hypervisor.
	<li> runs on top of the host OS (which is running directly on the
		hardware).  Additional operating systems run in the hypervisor.
	<li> divides the hardware up into slices, with each OS running
		directly on the hardware. It ensures that each OS
		only uses the parts of the hardware is was assigned.
	<li> provides a microkernel used by each of the operating systems
		running in the hypervisor. Each OS uses the microkernel
		system calls to interact with the hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> An exokernel is different from a virtual machine in that it
	<ol class="answer_list">
	<li> runs directly on the hardware and the operating systems run in
		the hypervisor.
	<li> runs on top of the host OS (which is running directly on the
		hardware).  Additional operating systems run in the hypervisor.
	<li> divides the hardware up into slices, with each OS running
		directly on the hardware. It ensures that each OS
		only uses the parts of the hardware is was assigned.
	<li> provides a microkernel used by each of the operating systems
		running in the hypervisor. Each OS uses the microkernel
		system calls to interact with the hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following mechanisms for running multiple operating systems
	on shared hardware has the least amount of additional overhead?
	<ol class="answer_list">
	<li> type 1 hypervisor
	<li> type 2 hypervisor
	<li> microkernel
	<li> exokernel
	<li> None of the above
	</ol>
</li><br/>

<li> The illusion that multiple processes are running at the same time is
	known as
	<ol class="answer_list">
	<li> parallelism.
	<li> pseudoparallelism.
	<li> hyperthreading.
	<li> multiprocessing.
	<li> None of the above
	</ol>
</li><br/>
<li> Pseudoparallelism is commonly achieved on a single processor system by
	<ol class="answer_list">
	<li> letting each process run to completion.
	<li> executing each process until it blocks before running the next
		process.
	<li> running <em>exactly</em> one instruction from each process in
		round-robin fashion.
	<li> rapidly switching of the CPU between processes (multiprogramming).
	<li> None of the above
	</ol>
</li><br/>
<li> A process is
	<ol class="answer_list">
	<li> another name for a program.
	<li> the compiled (executable) version of a program.
	<li> a program in execution.
	<li> a program that is either running (in the CPU) or ready, but
		<strong>not</strong> blocked.
	<li> None of the above
	</ol>
</li><br/>
<li> Existing processes in a Unix/Linix/POSIX system can be viewed using
	which command/facility?
	<ol class="answer_list">
	<li> task manager
	<li> pwd
	<li> ps
	<li> listAll
	<li> None of the above
	</ol>
</li><br/>
<li> Existing processes in a (Microsoft) Windows system can be viewed using
	which command/facility?
	<ol class="answer_list">
	<li> task manager
	<li> pwd
	<li> ps
	<li> listAll
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <em>voluntary</em> reasons for a process to
	terminate/exit?
	<ol class="answer_list">
	<li> Normal
	<li> Error
	<li> Fatal
	<li> Killed
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <em>INvoluntary</em> reasons for a process to
	terminate/exit?
	<ol class="answer_list">
	<li> Normal
	<li> Error
	<li> Fatal
	<li> Killed
	<li> None of the above
	</ol>
</li><br/>
<li> Processes in a POSIX system exist as a hierarchy because
	<ol class="answer_list">
	<li> each process corresponds to a program file (and files are
		hierarchical).
	<li> except for the first process, <strong>all</strong> other
		processes are created by an existing process.
	<li> each process corresponds to a user identification, and uids are
		arranged hierarchically.
	<li> of the time frames in which they were created.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> a state in which an
	executing process can exist?
	<ol class="answer_list">
	<li> Running
	<li> Blocked
	<li> Ready
	<li> Waiting
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> a transition between
	process states?
	<ol class="answer_list">
	<li> running to blocked
	<li> running to ready
	<li> ready to running
	<li> ready to blocked
	<li> blocked to running
	<li> blocked to ready
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following transition(s) are accomplished by the scheduler?
	<ol class="answer_list">
	<li> running to blocked
	<li> running to ready
	<li> ready to running
	<li> ready to blocked
	<li> blocked to running
	<li> blocked to ready
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following transition(s) occur as the result of receiving
	a signal?
	<ol class="answer_list">
	<li> running to blocked
	<li> running to ready
	<li> ready to running
	<li> ready to blocked
	<li> blocked to running
	<li> blocked to ready
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following transition(s) are accomplished when an I/O
	operation is completed?
	<ol class="answer_list">
	<li> running to blocked
	<li> running to ready
	<li> ready to running
	<li> ready to blocked
	<li> blocked to running
	<li> blocked to ready
	<li> None of the above
	</ol>
</li><br/>
<li> Which state is a process in when it terminates normally?
	<ol class="answer_list">
	<li> Running
	<li> Blocked
	<li> Ready
	<li> Waiting
	<li> None of the above
	</ol>
</li><br/>
<li> Which state does a process first start in when it is created?
	<ol class="answer_list">
	<li> Running
	<li> Blocked
	<li> Ready
	<li> Waiting
	<li> None of the above
	</ol>
</li><br/>
<li> Match the ovals (process states) and arcs (state transitions) in the below
	diagram (indicated by the letters A-I) with their names/descriptions.
	[Note: No choice is used more than once, and some may not be used.]
	<br/>
	<img src="/eckart/classes/cpsc3125/questions/ProcessState.png" alt="Process state diagram" width="637" height="417" />
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> I/O Wait
		<li> Process Termination
		<li> Reload
		<li> Blocked
		<li> Dispatch (scheduling)
		<li> Parked
		<li> Process Entry
		<li> I/O Completion
		<li> Running
		<li> Swapping
		<li> Timeout
		<li> Ready
		</ol>
	</td></tr></table>
</li><br/>
<li> The process table is an array with each entry containing
	<ol class="answer_list">
	<li> the file of the corresponding program.
	<li> only the current program counter for that process.
	<li> only the process id number for that process.
	<li> <strong>all</strong> of the associated information for a single
		process.
	<li> None of the above
	</ol>
</li><br/>
<li> A process that has been started but has <strong>not</strong> yet
	terminated, is represented by an entry in the process table when
	the process is in which of the following states?
	<ol class="answer_list">
	<li> Running
	<li> Blocked
	<li> Ready
	<li> Waiting
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX system call that creates a new process is called
	<ol class="answer_list">
	<li> new
	<li> create
	<li> dup
	<li> fork
	<li> None of the above
	</ol>
</li><br/>
<li> The family of POSIX system calls that replace the current process with a
	new one is called
	<ol class="answer_list">
	<li> replace
	<li> exec
	<li> dup2
	<li> getpid
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX system call that causes a parent process to wait for a specific
	child process to finish is called
	<ol class="answer_list">
	<li> wait
	<li> waitpid
	<li> fini
	<li> done
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX system call, <em>signal</em> is used to
	<ol class="answer_list">
	<li> send a signal to another process.
	<li> declare what signals may be sent to a process.
	<li> respond back to a signal sent from another process.
	<li> indicate which function should be called when a particular
		signal is received by the process.
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX system call that moves a running process to the blocked state
	is called
	<ol class="answer_list">
	<li> wait
	<li> break
	<li> pause
	<li> block
	<li> None of the above
	</ol>
</li><br/>
<li> Write a C program that takes a single command line argument indicating the
	number of child processes to create. Each child process prints out its
	PID to the stdout and then exits. The parent process prints the message
	"All done." after <strong>all</strong> of the children have completed,
	and then exits as well.
</li><br/>

<li> Threads are also commonly referred to as
	<ol class="answer_list">
	<li> hyperthreads
	<li> lightweight processes
	<li> execution traces
	<li> shared libraries
	<li> None of the above
	</ol>
</li><br/>
<li> When compared to processes, threads
	<ol class="answer_list">
	<li> are more limited in the size of their address space.
	<li> cannot be used for multiprogramming.
	<li> take the same amount of time for a context switch.
	<li> can be created and destroyed 10-100 times faster.
	<li> None of the above
	</ol>
</li><br/>
<li> Each thread <strong>must</strong> maintain its own
	<ol class="answer_list">
	<li> address space.
	<li> program counter.
	<li> run-time stack.
	<li> heap storage area.
	<li> signal handlers.
	<li> state (blocked, ready, running).
	<li> None of the above
	</ol>
</li><br/>
<li> Every process contains at least
	<ol class="answer_list">
	<li> one thread.
	<li> two threads, one each for execution and garbage collection.
	<li> three threads, for execution, signal management, and garbage
		collection.
	<li> one child process.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following items belong to the process (rather than to
	each of its threads)?
	<ol class="answer_list">
	<li> Program counter
	<li> Address space
	<li> Static variables
	<li> Run-time stack
	<li> Heap storage
	<li> Registers
	<li> File descriptors
	<li> Signal handlers
	<li> State (blocked, ready, running)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following items belong to each thread (rather than to
	the process)?
	<ol class="answer_list">
	<li> Program counter
	<li> Address space
	<li> Static variables
	<li> Run-time stack
	<li> Heap storage
	<li> Registers
	<li> File descriptors
	<li> Signal handlers
	<li> State (blocked, ready, running)
	<li> None of the above
	</ol>
</li><br/>
<li> Because the address space is shared by the process' threads, care must
	be taken (to avoid race conditions) when
	<ol class="answer_list">
	<li> calling the same function from multiple threads.
	<li> reading/setting values for the same static variables and heap
		allocated objects from multiple threads.
	<li> creating new threads.
	<li> a thread terminates.
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX pthread library call that creates a new thread is called
	<ol class="answer_list">
	<li> pthread_new
	<li> pthread_fork
	<li> pthread_create
	<li> pthread_dup
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX pthread library call that returns the thread's identification is
	called
	<ol class="answer_list">
	<li> pthread_getid
	<li> pthread_self
	<li> pthread_pid
	<li> pthread_thread_id
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX pthread library call that terminates the calling thread is called
	<ol class="answer_list">
	<li> pthread_exit
	<li> pthread_terminate
	<li> pthread_yield
	<li> pthread_return
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX pthread library call that blocks the calling thread, resuming
	when the indicated thread completes, is called
	<ol class="answer_list">
	<li> pthread_wait
	<li> pthread_block
	<li> pthread_pause
	<li> pthread_join
	<li> None of the above
	</ol>
</li><br/>
<li> The POSIX pthread library call that moves a running thread to the blocked
	state is called
	<ol class="answer_list">
	<li> pthread_block
	<li> pthread_yield
	<li> pthread_stop
	<li> pthread_pause
	<li> None of the above
	</ol>
</li><br/>
<li> Threads that are managed in user/process space
	<ol class="answer_list">
	<li> require the OS to be thread aware.
	<li> require the process to keep track of the threads via a thread
		table (in addition to the process table that the OS maintains).
	<li> enable context switching that is about 10x faster than
		kernel space threads.
	<li> cause the entire process to block if any one of its threads blocks
		for a system resource.
	<li> None of the above
	</ol>
</li><br/>
<li> Threads that are managed in kernel space
	<ol class="answer_list">
	<li> requires the OS to be thread aware.
	<li> requires the process to keep track of the threads via a thread
		table (in addition to the process table that the OS maintains).
	<li> enables context switching that is about 10x faster than
		user/process space threads.
	<li> cause the entire process to block if any one of its threads blocks
		for a system resource.
	<li> None of the above
	</ol>
</li><br/>
<li> Thread pools are collections of already allocated/created threads that
	<ol class="answer_list">
	<li> are assigned as requested to reduce the costs of thread creation
		and destruction.
	<li> are only beneficial for user/process space managed threads.
	<li> are only beneficial for kernel space managed threads.
	<li> prevent an over abundance of threads, if the pool is the only
		means for acquiring a thread.
	<li> None of the above
	</ol>
</li><br/>
<li> Hybrid User-Kernel space thread management allocates
	<ol class="answer_list">
	<li> one or more kernel threads to a process, with the process able
		to start multiple user threads within each kernel thread.
	<li> exactly one user space and one kernel space thread to each
		process.
	<li> any number of user space and kernel space threads to each process
		as long as they are requested from the corresponding user and
		kernel thread pools.
	<li> only user space threads, but enables the kernel to recognize when
		a user thread is blocked.
	<li> None of the above
	</ol>
</li><br/>
<li> Scheduler activations use
	<ol class="answer_list">
	<li> kernel space threads, but only the process schedules them.
	<li> kernel space threads, but the process recommends to the OS
		which thread to schedule/run next.
	<li> user space threads, but the kernel recognizes when a blocked
		thread doesn't prevent other threads from running.
	<li> both user and kernel space threads for a process, with each
		thread type being scheduled as it normally would be.
	<li> None of the above
	</ol>
</li><br/>

<li> The key issues for interprocess communication are
	<ol class="answer_list">
	<li> message passing.
	<li> sharing information.
	<li> semaphores.
	<li> sequencing process interactions.
	<li> None of the above
	</ol>
</li><br/>
<li> A race condition exists when
	<ol class="answer_list">
	<li> two or more processes share the same variable.
	<li> only user space threads are used for multiprogramming.
	<li> only kernel space threads are used for multiprogramming.
	<li> different execution orderings of instructions in multiple
		threads/processes can produce different results.
	<li> None of the above
	</ol>
</li><br/>
<li> Race conditions can occur when
	<ol class="answer_list">
	<li> two or more threads/processes can read (but <strong>not</strong>
		change) the same variable(s).
	<li> two or more threads/processes can read and write the same
		variable(s) via UNinterruptible actions.
	<li> two or more threads/processes can read and write the same
		variable(s) via interruptible actions.
	<li> when there is a mix of user space and kernel space threads
		within the same process, but no shared variable(s).
	<li> None of the above
	</ol>
</li><br/>
<li> A critical section is a portion of executable code
	<ol class="answer_list">
	<li> that makes system calls.
	<li> in which only one thread (or process) should be active at a time.
	<li> that is protected by one or more semaphores.
	<li> which is shared by multiple threads.
	<li> None of the above
	</ol>
</li><br/>
<li> Critical sections should be as small as possible because
	<ol class="answer_list">
	<li> larger critical sections run more slowly.
	<li> this reduces the amount of process blocking.
	<li> there is a maximum code size for which semaphores will work.
	<li> they <strong>must</strong> run completely through
		<strong>without</strong> blocking.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following help to prevent difficulties when simultaneous
	threads/processes share data?
	<ol class="answer_list">
	<li> No 2 threads/processes are in their critical sections at the
		same time.
	<li> No assumptions are made about process execution speeds.
	<li> No thread/process should wait arbitrarily long to enter its
		critical section.
	<li> No thread/process outside its critical section should block other
		threads/processes.
	<li> None of the above
	</ol>
</li><br/>

<li> Allowing processes to disable interrupts to prevent their being interrupted
	while in their critical section(s) is <strong>not</strong> a desirable
	solution since
	<ol class="answer_list">
	<li> it requires process threads to run in kernel space.
	<li> it requires process threads to run in user space.
	<li> a user program could use this to hog the CPU.
	<li> it fails to work if there are multiple CPUs.
	<li> None of the above
	</ol>
</li><br/>
<li> Strict alternation of processes can be accomplished by setting and
	repeatedly checking a shared variable (i.e., spin locking), but this
	<ol class="answer_list">
	<li> is only suitable if the expected wait time is very short.
	<li> solution only works for two processes (or threads).
	<li> solution only works if there is only a single CPU involved.
	<li> is wasteful of the CPU resource.
	<li> None of the above
	</ol>
</li><br/>
<li> Peterson's solution uses what mechanism(s) to implement mutual exclusion
	for a critical section?
	<ol class="answer_list">
	<li> disabling interrupts.
	<li> kernel space threads.
	<li> lock variable(s).
	<li> busy waiting.
	<li> None of the above
	</ol>
</li><br/>
<li> A test and set instruction is special because it
	<ol class="answer_list">
	<li> runs with interrupts disabled.
	<li> does the value copy and set as a single indivisible action.
	<li> works by performing the busy wait within a single instruction.
	<li> locks the memory bus (for multiple CPU systems).
	<li> None of the above
	</ol>
</li><br/>
<li> The priority inversion problem occurs when a busy waiting solution
	for critical section access is used and
	<ol class="answer_list">
	<li> the busy waiting process/thread has a higher priority.
	<li> the busy waiting process/thread has a lower priority.
	<li> the busy waiting process/thread is a user space thread.
	<li> the busy waiting process/thread is a kernel space thread.
	<li> None of the above
	</ol>
</li><br/>
<li> Fill in the rest of the code that implements Peterson's solution:
<pre><code>
	int turn;
	int interested[2];	// Solution for 2 processes.

	void enterRegion(int process) {
		int other = 1 - process;	// Other process.

		// Missing Code

	}

	void leaveRegion(int process) {
		interested[process] = 0;	// process NOT interested.
	}
</code></pre>
</li><br/>
<li> The key feature(s) of the TSL instruction which allows it to implement
	critical section access is
	<ol class="answer_list">
	<li> only being callable by the OS (and <strong>not</strong> by user
		programs).
	<li> saving the current value of a register while the register's
		value is set to a new value.
	<li> blocks if the value being assigned is different from the current
		value of the register.
	<li> that it is atomic (i.e., cannot be interrupted once begun).
	<li> None of the above
	</ol>
</li><br/>
<li> Fill in the rest of the code that implements a busy-waiting solution using
	the TSL (test and set lock) instruction:
<pre><code>
	enterRegion:

		// Missing Code

		JNE enterRegion ; if register N isn't 0 then loop ("lock" was set)
		RET		; if register N is 0 then enter critical section

	leaveRegion:

		// Missing Code

		RET
</code></pre>
</li><br/>

<li> Assuming that <em>sleep</em> (causing the calling process to block) and
	<em>wakeup</em> (which unblocks the indicated process) are system
	calls, then they can be used to implement critical sections if the
	following condition(s) are kept:
	<ol class="answer_list">
	<li> <em>wakeup</em> signals are <strong>not</strong> buffered.
	<li> <em>sleep</em> cannot be called by an already blocked process.
	<li> only strict alternation of critical sections is implemented.
	<li> <em>wakeup</em> is <strong>never</strong> called first.
	<li> None of the above
	</ol>
</li><br/>
<li> The <em>sleep</em> (causing the calling process to block) and
        <em>wakeup</em> (which unblocks the indicated process) calls enable
	<ol class="answer_list">
	<li> strictly alternating critical sections to be protected
		<strong>without</strong> busy waiting.
	<li> strictly alternating critical sections to be protected but only
		when a test and set instruction is available.
	<li> the protection of any critical section so long as
		<em>wakeup</em> is <strong>never</strong> called first.
	<li> the protection of any critical section so long as
		<em>sleep</em> is <strong>never</strong> called twice in a row.
	<li> None of the above
	</ol>
</li><br/>
<li> The <em>sleep</em> (causing the calling process to block) and
        <em>wakeup</em> (which unblocks the indicated process) calls, can
	only support strictly alternating critical sections because
	<ol class="answer_list">
	<li> <em>sleep</em> only blocks a process for a maximum period of
		time.
	<li> <em>sleep</em> cannot be called by an already blocked process.
	<li> <em>wakeup</em> cannot unblock a process that called <em>sleep</em>
		twice in a row.
	<li> <em>wakeup</em> calls are <strong>not</strong> buffered.
	<li> None of the above
	</ol>
</li><br/>
<li> Indicate where the <em>sleep()</em> and <em>wakeup(...)</em> calls should
	go (with the correct argument for <em>wakeup</em>) in the following
	code to allow alternation of producer and consumer actions. [Note: Some
	options may be used more than once, or not at all.]
<pre><code>
	void producer() {
		while (1) {
			ITEM item = produceItem();
			insertItem(item);

			// Insert statement(s) for section "A" here.

		}
	}

	void consumer() {
		while (1) {

			// Insert statement(s) for section "B" here.

			ITEM item = removeItem();
			consumeItem(item);

			// Insert statement(s) for section "C" here.

		}
	}
</code></pre>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> /* No Operation */
		<li> sleep();
		<li> wakeup(producer);
		<li> sleep(); wakeup(producer);
		<li> wakeup(producer); sleep();
		<li> wakeup(consumer);
		<li> sleep(); wakeup(consumer);
		<li> wakeup(consumer); sleep();
		</ol>
	</td></tr></table>
</li><br/>

<li> Semaphores were introduced in 1965 by 
	<ol class="answer_list">
	<li> Gary Peterson
	<li> Andrew Tannenbaum
	<li> Edgar Dijkstra
	<li> Alan Turing
	<li> None of the above
	</ol>
</li><br/>
<li> The P (DOWN) semaphore operation is <strong>best</strong> described by
	<ol class="answer_list">
	<li> count--; if (count <= 0) { sleep(); }
	<li> sleep(); if (count <= 0) { count--; }
	<li> if (count <= 0) { count--; } sleep();
	<li> if (count <= 0) { sleep(); } count--;
	<li> None of the above
	</ol>
</li><br/>
<li> The V (UP) semaphore operation is <strong>best</strong> described by
	<ol class="answer_list">
	<li> if (count == 1) { wakeup(sleeping_process); } count++;
	<li> if (count == 1) { count++; } wakeup(sleeping_process);
	<li> wakeup(sleeping_process); if (count == 1) { count++; }
	<li> count++; if (count == 1) { wakeup(sleeping_process); }
	<li> None of the above
	</ol>
</li><br/>
<li> The starting value (count) of a semaphore indicates the number of
	<ol class="answer_list">
	<li> total times that the semaphore can be used (e.g., P/DOWN
		operations).
	<li> available items of that resource.
	<li> different types of resources.
	<li> concurrent processes (but <strong>not</strong> threads) that can
		share the resource(s).
	<li> None of the above
	</ol>
</li><br/>
<li> If semaphores are compared to having copies of a book in the library, then
	<ol class="answer_list">
	<li> P/DOWN is the equivalent of checking out a book.
	<li> P/DOWN is the equivalent of returning a book.
	<li> V/UP is the equivalent of checking out a book.
	<li> V/UP is the equivalent of returning a book.
	<li> None of the above
	</ol>
</li><br/>
<li> The semaphore operations of P/DOWN and V/UP <strong>must</strong>
	<ol class="answer_list">
	<li> be system calls.
	<li> behave atomically (i.e., uninterruptible).
	<li> be implemented in the OS kernel.
	<li> be implemented by the computer hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> A mutex is a binary semaphore that
	<ol class="answer_list">
	<li> is implemented using lock variables.
	<li> uses <em>sleep</em> and <em>wakeup</em> calls for its
		implementation.
	<li> is implemented using monitors.
	<li> is optimized for having only two values/states.
	<li> None of the above
	</ol>
</li><br/>
<li> Indicate where the <em>down(&mutex)</em> and <em>up(&mutex)</em> calls
	should go in the following code to allow interleaving of producer
	and consumer actions, where "insertItem" and "removeItem" are
	operations on a shared buffer.
	[Note: Some options may be used more than once, or not at all.]
<pre><code>
	int mutex = 1;

	void producer() {
		while (1) {
			ITEM item = produceItem();

			// Insert statement(s) for section "A" here.

			insertItem(item);

			// Insert statement(s) for section "B" here.

		}
	}

	void consumer() {
		while (1) {

			// Insert statement(s) for section "C" here.

			ITEM item = removeItem();

			// Insert statement(s) for section "D" here.

			consumeItem(item);
		}
	}
</code></pre>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> /* No Operation */
		<li> down(&mutex);
		<li> up(&mutex);
		<li> down(&mutex); up(&mutex);
		<li> up(&mutex); down(&mutex);
		</ol>
	</td></tr></table>
</li><br/>
<li> Write a C program that takes a single command line argument which
	indicates the initial value of a shared counter (called "counter").
	The program should use 5 threads to eventually reduce the value of
	"counter" down to 0. Each thread will reduce "counter" by 1, then
	sleep for 1 second before continuing to decrease "counter".  The
	"counter" value should NOT go below 0 and the program should exit
	once "counter" reaches 0. You may use the following library calls to
	help write your program: <em>pthread_create</em>, <em>pthread_exit</em>,
	<em>pthread_mutex_lock</em>, <em>pthread_mutex_unlock</em>,
	<em>ptrhead_mutex_init</em>.  You can write your code without the usual
	"include"s or the use of <em>pthread_attr_init</em> and
	<em>pthread_attr_setscope</em>.
</li><br/>

<li> Monitors, unlike semaphores, <strong>must</strong> be implemented as
	<ol class="answer_list">
	<li> a (system) library so that different languages can share the
		same implementation.
	<li> part of the programming language design.
	<li> part of the OS design.
	<li> a feature within the computer hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> Monitors are most easily adapted to programming languages that support
	<ol class="answer_list">
	<li> classes (e.g., Java).
	<li> records/structures (e.g., C).
	<li> functions (e.g., C, Cobol, Fortran).
	<li> conditional looping constructs, like "while" (e.g., C, Java).
	<li> None of the above
	</ol>
</li><br/>
<li> What feature in Java can be used to implement a monitor?
	<ol class="answer_list">
	<li> virtualized
	<li> try-catch
	<li> finalized
	<li> synchronized
	<li> None of the above
	</ol>
</li><br/>
<li> A different semaphore associated with each object instance can be used
	to implement a monitor by having each
	<ol class="answer_list">
	<li> object do P/DOWN when it is created and a V/UP
		when it is destroyed.
	<li> object do V/UP when it is created and a P/DOWN
		when it is destroyed.
	<li> object method do P/DOWN when begun, and V/UP just before returning.
	<li> object method do V/UP when begun, and P/DOWN just before returning.
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following interprocess communication mechanisms is well
	suited for distributed sharing (i.e., across multiple computer systems)?
	<ol class="answer_list">
	<li> lock variables
	<li> semaphores
	<li> monitors
	<li> message passing
	<li> None of the above
	</ol>
</li><br/>
<li> Message passing, like semaphores (and unlike monitors),
	<ol class="answer_list">
	<li> can easily be implemented as a (system) library so that different
		languages can share the same implementation.
	<li> <strong>must</strong> be part of the programming language design.
	<li> <strong>must</strong> be part of the OS design.
	<li> <strong>must</strong> be a feature within the computer hardware.
	<li> None of the above
	</ol>
</li><br/>
<li> The "send" and "receive" system calls for message passing generally
	<ol class="answer_list">
	<li> <strong>must</strong> be used in conjunction with semaphores to
		perform the coordination (e.g., to ensure the "receive"r
		is ready and waiting when the "send" is done).
	<li> can only be used when the communicating processes are on
		different systems.
	<li> are considered impractically for efficiency reasons, and thus
		are seldom used.
	<li> <strong>must</strong> indicate the message contents and
		destination (for "send") and a place to store the message
		and the source (for "received").
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are typical design issues associated with messages?
	<ol class="answer_list">
	<li> Handling lost (or missing) messages.
	<li> Minimum message size.
	<li> Maximum time between messages (not counting acknowledgements).
	<li> Messages are received in the order they were sent.
	<li> None of the above
	</ol>
</li><br/>
<li> Indicate where the <em>send</em> and <em>receive</em> calls should go (with
	the appropriate arguments) in the following code to allow alternation of
	producer and consumer actions.
	[Note: Some options may be used more than once, or not at all.]
<pre><code>
	void producer() {
		MESSAGE msg;
		while (1) {
			ITEM item = produceItem();
			addItem(&msg, item);

			// Insert statement(s) for section "A" here.

		}
	}

	void consumer() {
		MESSAGE msg;
		while (1) {

			// Insert statement(s) for section "B" here.

			ITEM item = removeItem(msg);

			// Insert statement(s) for section "C" here.

			consumeItem(item);
		}
	}
</code></pre>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> /* No Operation */
		<li> send(consumer, &msg);
		<li> send(producer, &msg);
		<li> receive(consumer, &msg);
		<li> receive(producer, &msg);
		<li> send(consumer, &msg); receive(producer, &msg);
		<li> send(producer, &msg); receive(consumer, &msg);
		<li> receive(consumer, &msg); send(producer, &msg);
		<li> receive(producer, &msg); send(consumer, &msg);
		</ol>
	</td></tr></table>
</li><br/>
<li> A popular system that implements message passing, developed in the
	early 1990s, and available for a variety of different languages
	(e.g., Java, Python, C) is called
	<ol class="answer_list">
	<li> The Messaging Library (TML)
	<li> Message Passing Interface (MPI)
	<li> Distributed Messaging Library (DML)
	<li> Distributed Process Communication (DPC)
	<li> None of the above
	</ol>
</li><br/>
<li> When a message passing system causes the sender to block until the
	receiver is ready (and vice versa), these semantics are called a
	<ol class="answer_list">
	<li> rendezvous.
	<li> date.
	<li> coupling.
	<li> synch-up.
	<li> None of the above
	</ol>
</li><br/>
<li> The mechanism in POSIX systems that provides a maximum size "mailbox"
	that causes the writing/sending process to block once the "mailbox"
	becomes full (allowing the writer/sender to proceed only when there
	is room in the "mailbox" - perhaps due to the receiver reading/removing
	items), is called
	<ol class="answer_list">
	<li> mail.
	<li> spooling.
	<li> pipes.
	<li> conduits.
	<li> None of the above
	</ol>
</li><br/>
<li> Write a C program that creates a single child process. The parent process
	reads in numbers (separated by white-space) from stdin and sends them
	to the child process using a pipe. The child process then writes the
	numbers to stdout (one number per line).
</li><br/>

<li> Barriers are useful when a number of different threads/processes need to
	<ol class="answer_list">
	<li> take turns working on a common task.
	<li> <strong>must all</strong> meet at a common place before
		proceeding to the next phase of a computation.
	<li> share a set of common variables/objects.
	<li> none of the threads/processes are allowed to go past a
		certain point in the computation.
	<li> None of the above
	</ol>
</li><br/>
<li> If <strong>all</strong> the threads/processes take very close to the same
	amount of time to reach the barrier, then a good way of implementing
	the barrier is
	<ol class="answer_list">
	<li> spin locks.
	<li> semaphores.
	<li> monitors.
	<li> message passing.
	<li> None of the above
	</ol>
</li><br/>
<li> The "thread" function below is run multiple times simultaneously (each
	instance is passed a different value of "i" from 0 to N-1). The
	"barrier" function ensures that <strong>all</strong>
	the threads wait until <strong>all</strong> have
	reached this point before proceeding. Use "count", and the "down"
	and "up" operations on both the N "mutex_thread" (declared
	as an array) and "mutex_count" semaphores to implement the
	"barrier" function semantics.
<pre><code>
        pthread_mutex_t mutex_thread[N];
        pthread_mutex_t mutex_count;
        int count = 0;

        int main(...) {
                ...
                int thread_num;
                pthread_mutex_init(&mutex_count);
                for (thread_num = 0; thread_num < N; thread_num++) {
                        pthread_t thread_id;
                        pthread_mutex_init(&mutex_thread[thread_num]);
                        pthread_mutex_lock(&mutex_thread[thread_num]);
                        pthread_create(&thread_id, thread, thread_num)
                }
                ...
        }

        void thread(int i) {
                while (1) {
                        do_something(i);
                        barrier(i);
                        do_something_else(i);
                        barrier(i);
                }
        }
        void barrier(int i) {

                // MISSING CODE

        }
</code></pre>
</li><br/>

<li> The Dining Philosophers Problem is a synchronization problem developed
	by Edgar Dijkstra to
	<ol class="answer_list">
	<li> show how monitors can handle situations that semaphores cannot.
	<li> show how semaphores can handle situations that message
		passing cannot.
	<li> demonstrate the use of semaphores.
	<li> demonstrate the use of message passing.
	<li> None of the above
	</ol>
</li><br/>
<li> The Dining Philosophers Problem is comprised of
	<ol class="answer_list">
	<li> 5 philosophers each with a plate of slippery pasta.
	<li> philosophers needing to take turns eating, going around the
		table in a clockwise fashion.
	<li> 5 forks, one between each philosopher.
	<li> philosophers needing 2 forks to eat.
	<li> None of the above
	</ol>
</li><br/>
<li> If no process within a group of processes is able to run because they
	are <strong>all</strong> in the blocked state, and each is waiting
	for the other to do something before it can continue, this situation
	is called
	<ol class="answer_list">
	<li> starvation.
	<li> deadlock.
	<li> livelock.
	<li> mutual stall.
	<li> None of the above
	</ol>
</li><br/>
<li> If <strong>all</strong> the processes within a group of processes is able
	to run (i.e., none are in the blocked state), but none is able to
	accomplish any useful work for lack of a resource, this situation is
	called
	<ol class="answer_list">
	<li> starvation.
	<li> deadlock.
	<li> livelock.
	<li> resource hogging.
	<li> None of the above
	</ol>
</li><br/>
<li> In the Dining Philosophers Problem, if each philosopher grabs a fork and
	holds it until they are able to grab a second fork, this
	<ol class="answer_list">
	<li> leads to starvation.
	<li> leads to deadlock.
	<li> leads to livelock.
	<li> provides a correct solution.
	<li> None of the above
	</ol>
</li><br/>
<li> In the Dining Philosophers Problem, if each philosopher grabs the fork
	to their right, then seeing that the left fork is unavailable (having
	been grabbed by the philosopher to their left) puts down the fork they
	are holding, counts to 10, then tries again. This algorithm
	<ol class="answer_list">
	<li> leads to livelock.
	<li> leads to deadlock.
	<li> leads to resource hogging.
	<li> provides a correct solution.
	<li> None of the above
	</ol>
</li><br/>
<li> The key to one working solution of the Dining Philosophers Problem is to
	have philosophers exist in one of three states (THINING, HUNGRY, EATING)
	and that when a philosopher is
	<ol class="answer_list">
	<li> finished EATING, she ensures that any HUNGRY philosopher sitting
		next to her gets an opportunity to eat.
	<li> HUNGRY, she waits until each of her neighbors is THINKING before
		trying to pick up forks.
	<li> THINKING, she waits until a neighbor is also THINKING before
		becoming HUNGRY.
	<li> finished THINKING, she waits until one of her neighbors is EATING
		before becoming HUNGRY.
	<li> None of the above
	</ol>
</li><br/>

<li> The Readers and Writers Problem involves multiple processes trying to
	read or write to the same shared variable, in which 
	<ol class="answer_list">
	<li> only one reader or writer can access the variable at a time.
	<li> only one reader or multiple writers can access the variable
		at a time.
	<li> multiple readers or a single writer can access the variable
		at a time.
	<li> multiple readers or multiple writers can access the variable
		at a time.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary types of solutions to the Readers and Writers Problem are
	when
	<ol class="answer_list">
	<li> writers are given preference over readers.
	<li> readers are given preference over writers.
	<li> readers and writers have simultaneous access so that no
		preference is given to either one.
	<li> readers and writers strictly alternate, with every read followed
		by a write and every write followed by a read.
	<li> None of the above
	</ol>
</li><br/>
<li> Indicate where the <em>down(...)</em> and <em>up(...)</em> calls
	should go in the following code to allow a single reader or a single
	writer to access the shared database <strong>without</strong> giving
	either readers or writers any preference.
	[Note: Some options may be used more than once, or not at all.]
<pre><code>
	int mutex = 1;

	void reader() {
		while (1) {

			// Insert statement(s) for section "A" here.

			readDatabase();

			// Insert statement(s) for section "B" here.

		}
	}

	void writer() {
		while (1) {
			acquireData();

			// Insert statement(s) for section "C" here.

			writeDatabase();

			// Insert statement(s) for section "D" here
}}
	}
</code></pre>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> /* No Operation */
		<li> down(&mutex);
		<li> up(&mutex);
		<li> up(&mutex); down(&mutex);
		<li> down(&mutex); up(&mutex);
		</ol>
	</td></tr></table>
</li><br/>
<li> Indicate where the <em>down(...)</em> and <em>up(...)</em> calls
	should go in the following code to give readers preference over
	writers for access to the shared database.
	[Note: Some options may be used more than once, or not at all.]
<pre><code>
	int db_mutex = 1;
	int counter_mutex = 1;
	int counter = 0;

	void reader() {
		while (1) {

			// Insert statement(s) for section "A" here.

			if (1 == ++counter) {

				// Insert statement(s) for section "B" here.

			}


			// Insert statement(s) for section "C" here.

			readDatabase();


			// Insert statement(s) for section "D" here.

			if (0 == --counter) {

				// Insert statement(s) for section "E" here.

			}

			// Insert statement(s) for section "F" here.

		}
	}

	void writer() {
		while (1) {
			acquireData();

			// Insert statement(s) for section "G" here.

			writeDatabase();

			// Insert statement(s) for section "H" here.

		}
	}
</code></pre>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> /* No Operation */
		<li> up(&db_mutex);
		<li> up(&counter_mutex);
		<li> down(&db_mutex);
		<li> down(&counter_mutex);
		</ol>
	</td></tr></table>
</li><br/>
<li> Indicate where the <em>down(...)</em> and <em>up(...)</em> calls
	should go in the following code to give writers preference over
	readers for access to the shared database.
	[Note: Some options may be used more than once, or not at all.]
<pre><code>
	int read_mutex = 1;
	int write_mutex = 1;
	int counter_mutex = 1;
	int counter = 0;

	void reader() {
		while (1) {

			// Insert statement(s) for section "A" here.

			readDatabase();

			// Insert statement(s) for section "B" here.

		}
	}

	void writer() {
		while (1) {
			acquireData();


			// Insert statement(s) for section "C" here.

			if (1 == ++counter) {


				// Insert statement(s) for section "D" here.


			}

			// Insert statement(s) for section "E" here.


			writeDatabase();


			// Insert statement(s) for section "F" here.

			if (0 == --counter) {


				// Insert statement(s) for section "G" here.


			}

			// Insert statement(s) for section "H" here.

		}
	}
</code></pre>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> /* No Operation */
		<li> up(&counter_mutex);
		<li> up(&read_mutex);
		<li> up(&write_mutex);
		<li> down(&counter_mutex);
		<li> down(&read_mutex);
		<li> down(&write_mutex);
		<li> up(&counter_mutex); down(&read_mutex);
		<li> up(&read_mutex); down(&counter_mutex);
		<li> up(&counter_mutex); down(&write_mutex);
		<li> up(&write_mutex); down(&counter_mutex);
		</ol>
	</td></tr></table>
</li><br/>

<li> The scheduler is that part of the OS that
	<ol class="answer_list">
	<li> starts a new process.
	<li> manages the CPU.
	<li> determines when a blocked process becomes ready.
	<li> determines when a running process blocks.
	<li> None of the above
	</ol>
</li><br/>
<li> A process scheduling algorithm should try to address the following
	concerns:
	<ol class="answer_list">
	<li> memory availability for the process to use.
	<li> fairness, so that every process gets their fair share.
	<li> the efficient use of the CPU.
	<li> ensure availability of peripheral resources.
	<li> maximize the number of processes completed per hour.
	<li> minimize response time for interactive users.
	<li> None of the above
	</ol>
</li><br/>
<li> The ability of the OS to switch from running one process to another
	process VERY quickly is important because it
	<ol class="answer_list">
	<li> reduces the chance of an OS bug causing a problem.
	<li> increases the efficient use of the CPU.
	<li> helps reduce the response time for interactive users.
	<li> ensures peripheral resource availability.
	<li> None of the above
	</ol>
</li><br/>
<li> Regarding the set of concerns that a process scheduling algorithm
	should address,
	<ol class="answer_list">
	<li> <strong>all</strong> of them can be effectively address by a
		single algorithm.
	<li> an OS should use two or more scheduling algorithms alternately
		so as to address <strong>all</strong> of the concerns.
	<li> only a couple of the concerns are truly important, and the
		remainder can be safely ignored.
	<li> some of the concerns are contradictory, so invariably
		<strong>not all</strong> concerns can be addressed by the OS.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to process scheduling, it is helpful to view a process as
	<ol class="answer_list">
	<li> being primarily CPU bound.
	<li> being primarily I/O bound.
	<li> an intense period of CPU usage. 
	<li> alternating sequences of CPU usage and waiting for I/O.
	<li> None of the above
	</ol>
</li><br/>
<li> A CPU bound process is one in which
	<ol class="answer_list">
	<li> it spends most of its time in the ready or running state.
	<li> it spends most of its time in the blocked state.
	<li> once it obtains the CPU, it runs to completion.
	<li> most of the time it's waiting for the memory to be available.
	<li> None of the above
	</ol>
</li><br/>
<li> An I/O bound process is one in which
	<ol class="answer_list">
	<li> it spends most of its time in the ready or running state.
	<li> it spends most of its time in the blocked state.
	<li> once it obtains the CPU, it runs to completion.
	<li> most of the time it's waiting for the memory to be available.
	<li> None of the above
	</ol>
</li><br/>
<li> Preemptive scheduling is when a process
	<ol class="answer_list">
	<li> spends most of its time in the ready or running state.
	<li> spends most of its time in the blocked state.
	<li> can be booted out of the CPU by the scheduler, before the
		process is finished.
	<li> can be booted out of the CPU by another user process, before the
		process is finished.
	<li> None of the above
	</ol>
</li><br/>
<li> Non-preemptive scheduling is when a process
	<ol class="answer_list">
	<li> spends most of its time in the ready or running state.
	<li> spends most of its time in the blocked state.
	<li> <strong>never</strong> becomes blocked.
	<li> <strong>always</strong> runs to termination once it's in the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of process scheduling is <strong>best</strong> suited
	for interactive processing?
	<ol class="answer_list">
	<li> non-preemptive.
	<li> dedicated.
	<li> busy wait.
	<li> preemptive.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are batch process scheduling algorithms?
	<ol class="answer_list">
	<li> Priority Scheduling.
	<li> First Come, First Serverd.
	<li> Guaranteed Scheduling.
	<li> Shortest Remaining Time.
	<li> None of the above
	</ol>
</li><br/>
<li> The following steps describe which process scheduling algorithm?
	<blockquote>
	<ul class="bullet_list">
	<li> Processes are added to a single queue in the order they are
		started.
	<li> The process at the front of the queue is run until it either
		completes, or blocks.
	<li> Once a process becomes ready again (after being blocked), it joins
		 the end of the queue.
	</ul>
	</blockquote>
	<ol class="answer_list">
	<li> Round Robin Scheduling.
	<li> First Come, First Served.
	<li> Guaranteed Scheduling.
	<li> Fair-Share Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following process scheduling algorithms needs to know the
	typical amount of time that a process often takes to complete?
	<ol class="answer_list">
	<li> Guaranteed Scheduling.
	<li> Shortest Job First.
	<li> Priority Scheduling.
	<li> Fair-Share Scheduling.
	<li> Shortest Remaining Time.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following process scheduling algorithms favors CPU bound
	over I/O bound processes?
	<ol class="answer_list">
	<li> First Come, First Served
	<li> Shortest Job First
	<li> Shortest Remaining Time
	<li> Guaranteed Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following process scheduling algorithms improves the average
	turnaround time on a batch system?
	<ol class="answer_list">
	<li> First Come, First Served
	<li> Shortest Job First
	<li> Shortest Remaining Time
	<li> Guaranteed Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following process scheduling algorithms improves the average
	throughput on a batch system?
	<ol class="answer_list">
	<li> First Come, First Served
	<li> Shortest Job First
	<li> Shortest Remaining Time
	<li> Guaranteed Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> The following steps describe which process scheduling algorithm?
	<blockquote>
	<ul class="bullet_list">
	<li> Processes are chosen to run from the front of a single ready queue.
	<li> Each process can run a max time called a quantum.
	<li> Processes may block before <strong>all</strong> of their
		time quantum is used.
	<li> As processes become ready, they go to the end of the ready queue.
	</ul>
	</blockquote>
	<ol class="answer_list">
	<li> First Come, First Served.
	<li> Round Robin Scheduling.
	<li> Priority Scheduling.
	<li> Fair-Share Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> The following steps describe which process scheduling algorithm?
	<blockquote>
	<ul class="bullet_list">
	<li> Each process has a priority.
	<li> The ready process with the highest priority runs next.
	<li> Priorities can be set statically and/or dynamically.
	</ul>
	</blockquote>
	<ol class="answer_list">
	<li> Round Robin Scheduling.
	<li> Guaranteed Scheduling.
	<li> Priority Scheduling.
	<li> Fair-Share Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> The following steps describe which process scheduling algorithm?
	<blockquote>
	<ul class="bullet_list">
	<li> Each queue corresponds to a different max time quantum to run.
	<li> If a process uses <strong>all</strong> of its time quantum,
		it's added to the end of the next highest quantum queue when
		it's moved to the ready state.
	<li> If a process blocks before exhausting its time quantum, it's added
		to the end of the next lowest quantum queue when it's moved to
		the ready state.
	<li> The processes in queues with larger quantum are run less
		frequently.
	</ul>
	</blockquote>
	<ol class="answer_list">
	<li> Round Robin Scheduling.
	<li> Multiple Queues.
	<li> Priority Scheduling.
	<li> Fair-Share Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> Which process scheduling algorithm(s) are particularly well suited to
	<em>very</em> slow context switching?
	<ol class="answer_list">
	<li> Guaranteed Scheduling.
	<li> Multiple Queues.
	<li> Lottery Scheduling.
	<li> First Come, First Served.
	<li> None of the above
	</ol>
</li><br/>
<li> Which process scheduling algorithm(s) are particularly well suited to
	enforcing an advertised policy?
	<ol class="answer_list">
	<li> Multiple Queues.
	<li> Guaranteed Scheduling.
	<li> Lottery Scheduling.
	<li> Fair-Share Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> The following steps describe which process scheduling algorithm?
	<blockquote>
	<ul class="bullet_list">
	<li> Each process (in the ready queue) is given a (probably different)
		number of tickets.
	<li> When picking the next process to run, a ticket is chosen at random
		and the ready process with that ticket is run.
	</ul>
	</blockquote>
	<ol class="answer_list">
	<li> Multiple Queues.
	<li> Guaranteed Scheduling.
	<li> Lottery Scheduling.
	<li> Fair-Share Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> The <em>most</em> space efficient way of implementing Lottery Scheduling
	is to have
	<ol class="answer_list">
	<li> each ready process use a hash table to keep track of its randomly
		assigned tickets.
	<li> each ready process use a unsorted linked list of its randomly
		assigned tickets, performing a linear search to determine if
		it holds the "winning" ticket.
	<li> each ready process stores the range of tickets that it holds,
		so finding the process to run requires searching the queue of
		ready processes for the correct range that holds the "winning"
		ticket.
	<li> a common array used by <strong>all</strong> processes. Each array
		entry corresponds to a ticket, and records the process holding
		that ticket.
	<li> None of the above
	</ol>
</li><br/>
<li> The way of implementing Lottery Scheduling so that finding the process
	with the "winning" ticket is the <em>fastest</em> is to have
	<ol class="answer_list">
	<li> each ready process use a hash table to keep track of its randomly
		assigned tickets.
	<li> each ready process use a unsorted linked list of its randomly
		assigned tickets, performing a linear search to determine if
		it holds the "winning" ticket.
	<li> each ready process stores the range of tickets that it holds,
		so finding the process to run requires searching the queue of
		ready processes for the correct range that holds the "winning"
		ticket.
	<li> a common array used by <strong>all</strong> processes. Each array
		entry corresponds to a ticket, and records the process holding
		that ticket.
	<li> None of the above
	</ol>
</li><br/>
<li> Which process scheduling algorithm ensures that each user (rather than
	each process) gets an equal share of the CPU resource?
	<ol class="answer_list">
	<li> Multiple Queues.
	<li> Guaranteed Scheduling.
	<li> Lottery Scheduling.
	<li> Fair-Share Scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> Real-time process scheduling is used
	<ol class="answer_list">
	<li> when processes <strong>must never</strong> block.
	<li> to ensure "quick" response to real world events.
	<li> to ensure the <strong>most</strong> efficient use of the
		CPU resource. 
	<li> when there is <strong>never</strong> more than one ready process
		at a time.
	<li> None of the above
	</ol>
</li><br/>
<li> <em>Hard</em> real-time systems
	<ol class="answer_list">
	<li> try to meet most deadlines, but terminate processes when its
		deadline is missed.
	<li> should meet <strong>all</strong> deadlines, but sometimes they
		are missed.
	<li> <strong>must</strong> meet <strong>all</strong> deadlines,
		otherwise something dire happens.
	<li> guarantees that <strong>all</strong> deadlines are met,
		no deadline is ever missed.
	<li> None of the above
	</ol>
</li><br/>
<li> <em>Soft</em> real-time systems
	<ol class="answer_list">
	<li> try to meet most deadlines, but terminate processes when its
		deadline is missed.
	<li> should meet <strong>all</strong> deadlines, but sometimes they
		are missed.
	<li> <strong>must</strong> meet <strong>all</strong> deadlines,
		otherwise something dire happens.
	<li> guarantees that <strong>all</strong> deadlines are met,
		no deadline is ever missed.
	<li> None of the above
	</ol>
</li><br/>
<li> The process scheduling policy and the scheduling mechanism are
	<ol class="answer_list">
	<li> different, with the policy choosing what to run next and the
		mechanism performing the context switch.
	<li> different, with mechanism used for batch systems and policy  
		used for real-time systems.
	<li> similar, with policy doing everything that mechanism does but
		adding to it support for non-preemptive scheduling.
	<li> actually different names for the same thing.
	<li> None of the above
	</ol>
</li><br/>
<li> Thread scheduling is
	<ol class="answer_list">
	<li> <strong>always</strong> done by the OS kernel.
	<li> <strong>always</strong> done by the process, when the process
		is running.
	<li> performed by both the kernel <em>and</em> by the process (if
		it is running).
	<li> accomplished by another aspect of the OS kernel using algorithms
		very different from those for process scheduling.
	<li> None of the above
	</ol>
</li><br/>
<li> The following describes which type of thread scheduling?
	<blockquote>
	<ul class="bullet_list">
	<li> The kernel picks/schedules a process.
	<li> The scheduled process then schedules its own threads.
	<li> If a thread blocks for a system resource,
		then the entire process blocks and no other
		threads from the process can be run until the block is
		"cleared".
	</ul>
	</blockquote>
	<ol class="answer_list">
	<li> Process scheduling
	<li> Kernel scheduling
	<li> Hybrid scheduling
	<li> Combined scheduling
	<li> None of the above
	</ol>
</li><br/>
<li> The following describes which type of thread scheduling?
	<blockquote>
	<ul class="bullet_list">
	<li> The kernel picks/schedules a thread (from any process).
	<li> If the thread blocks for a system resource,
		then the kernel picks/schedules another
		thread that can be from the same or another process.
	</ul>
	</blockquote>
	<ol class="answer_list">
	<li> Process scheduling
	<li> Kernel scheduling
	<li> Hybrid scheduling
	<li> Combined scheduling
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following thread scheduling mechanisms provides the fastest
	switching between threads from the same process?
	<ol class="answer_list">
	<li> Process scheduling
	<li> Kernel scheduling
	<li> Hybrid scheduling
	<li> Combined scheduling
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following thread scheduling mechanisms avoids a single
	blocked thread from preventing <strong>all</strong> of that
	process' threads from running?
	<ol class="answer_list">
	<li> Preemptive scheduling
	<li> Process scheduling
	<li> Kernel scheduling
	<li> Non-preemptive scheduling
	<li> None of the above
	</ol>
</li><br/>

<li> Which Unix command is used to display system documentation?
	<ol class="answer_list">
	<li> man
	<li> help
	<li> doc
	<li> system
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints out the current date and time?
	<ol class="answer_list">
	<li> time
	<li> date
	<li> today
	<li> now
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints out the calendar for the current month?
	<ol class="answer_list">
	<li> dates
	<li> year
	<li> cal
	<li> calendar
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command provides an arbitrary precision calculator?
	<ol class="answer_list">
	<li> cal
	<li> apc
	<li> rpn
	<li> bc
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints where a specified command is located?
	<ol class="answer_list">
	<li> find
	<li> where
	<li> which
	<li> locate
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command captures a transcript of the terminal session?
	<ol class="answer_list">
	<li> script
	<li> term
	<li> session
	<li> capture
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command lists the "real", user, and system time taken by
	another command?
	<ol class="answer_list">
	<li> date
	<li> time
	<li> timer
	<li> sw
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> a common Unix command shell?
	<ol class="answer_list">
	<li> shell
	<li> sh
	<li> cmd
	<li> bash
	<li> term
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command is a commonly used full screen editor?
	<ol class="answer_list">
	<li> edit
	<li> fse
	<li> vi
	<li> ed
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command allows the filtering and transformation of text?
	<ol class="answer_list">
	<li> edit
	<li> fse
	<li> tr
	<li> sed
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints out the type of a specified file?
	<ol class="answer_list">
	<li> file
	<li> type
	<li> ft
	<li> kind
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints the contents of one or more files to the screen?
	<ol class="answer_list">
	<li> print
	<li> cat
	<li> type
	<li> list
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command makes a copy of a file?
	<ol class="answer_list">
	<li> mv
	<li> dup
	<li> cp
	<li> copy
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command is used to rename a file or directory?
	<ol class="answer_list">
	<li> cp
	<li> rename
	<li> dup
	<li> mv
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command displays a file, a page at a time, on the screen?
	<ol class="answer_list">
	<li> more
	<li> page
	<li> type
	<li> list
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints the first few lines of a file?
	<ol class="answer_list">
	<li> start
	<li> head
	<li> begin
	<li> first
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints the last few lines of a file?
	<ol class="answer_list">
	<li> end
	<li> fini
	<li> tail
	<li> rest
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command can sort the lines of a file?
	<ol class="answer_list">
	<li> order
	<li> list
	<li> file
	<li> sort
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command shows the differences between two files?
	<ol class="answer_list">
	<li> diff
	<li> filecmp
	<li> compare
	<li> shdiff
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command returns the number of characters, words, and lines in
	a file?
	<ol class="answer_list">
	<li> count
	<li> wc
	<li> words
	<li> list
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command lists the contents of a directory?
	<ol class="answer_list">
	<li> list
	<li> files
	<li> ls
	<li> show
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix shell command changes the current working directory?
	<ol class="answer_list">
	<li> dir
	<li> pwd
	<li> cwd
	<li> cd
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints the location of the current working directory?
	<ol class="answer_list">
	<li> pwd
	<li> show
	<li> whereami
	<li> location
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints the lines of a file that match a specified
	pattern?
	<ol class="answer_list">
	<li> pat
	<li> grep
	<li> match
	<li> files
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command recursively visits a directory structure looking for
	files that match a set of criteria?
	<ol class="answer_list">
	<li> list
	<li> files
	<li> find
	<li> match
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command creates a new directory?
	<ol class="answer_list">
	<li> new
	<li> create
	<li> touch
	<li> mkdir
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command removes files (or directories)?
	<ol class="answer_list">
	<li> rm
	<li> del
	<li> purge
	<li> mv
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command reports the amount of free disk space remaining?
	<ol class="answer_list">
	<li> free
	<li> df
	<li> disksp
	<li> dstat
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command estimates the amount of disk currently being used?
	<ol class="answer_list">
	<li> usage
	<li> disk
	<li> du
	<li> dstat
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command prints the status of existing processes?
	<ol class="answer_list">
	<li> pstat
	<li> procs
	<li> ready
	<li> ps
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix command is used to send signals to processes?
	<ol class="answer_list">
	<li> kill
	<li> signal
	<li> send
	<li> ping
	<li> None of the above
	</ol>
</li><br/>

<li> The input redirection provided by the Unix "bash" shell enables
	<ol class="answer_list">
	<li> output from one command to be used as input to another command.
	<li> the contents of a file to be fed as input to a command (as if
		coming from the keyboard).
	<li> keyboard input to be captured within a file.
	<li> keyboard input to be fed directly to a running command.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are example(s) of input redirection using the Unix
	"bash" shell, where "data_file" is the name of a file containing
	input data and "command" is the name of a Unix executable?
	<ol class="answer_list">
	<li> data_file > command
	<li> data_file | command
	<li> command | data_file
	<li> command < data_file
	<li> None of the above
	</ol>
</li><br/>
<li> The output redirection provided by the Unix "bash" shell enables
	<ol class="answer_list">
	<li> output from one command to be used as input to another command.
	<li> the output of a command to be captured within a file.
	<li> the output of a command to be displayed on the screen.
	<li> keyboard "output" to be fed directly as input to a running command.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are example(s) of output redirection using the Unix
	"bash" shell, where "data_file" is the name of an output file
        and "command" is the name of a Unix executable?
	<ol class="answer_list">
	<li> data_file > command
	<li> data_file | command
	<li> command | data_file
	<li> command < data_file
	<li> None of the above
	</ol>
</li><br/>
<li> The Unix "bash" shell concept of pipe enables
	<ol class="answer_list">
	<li> the output of a command to be captured within a file.
	<li> output from one command to be used as input to another command.
	<li> the contents of a file to be fed as input to a command (as if
		coming from the keyboard).
	<li> both the input and output for a command to be associated with the
		same file.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are example(s) of pipe(s) using the Unix
	"bash" shell, where "data_file" is the name of a file containing
        data and "command" is the name of a Unix executable?
	<ol class="answer_list">
	<li> data_file > command
	<li> data_file | command
	<li> command | data_file
	<li> command < data_file
	<li> None of the above
	</ol>
</li><br/>
<li> The following Unix "bash" shell expression uses which of these
	capabilities, where "data_file" is the name of a file containing
        data?
<pre><code>
	cmd_1 < data_file | cmd_2 | cmd_3
</code></pre>
	<ol class="answer_list">
	<li> Input redirection
	<li> Output redirection
	<li> Pipe(s)
	<li> The expression is illegal
	<li> None of the above
	</ol>
</li><br/>
<li> The following Unix "bash" shell expression uses which of these
	capabilities, where "data_file" is the name of a file that can
        hold data?
<pre><code>
	cmd_1 | cmd_2 > data_file
</code></pre>
	<ol class="answer_list">
	<li> Input redirection
	<li> Output redirection
	<li> Pipe(s)
	<li> The expression is illegal
	<li> None of the above
	</ol>
</li><br/>
<li> The following Unix "bash" shell expression uses which of these
	capabilities, where "data_file_1" and "data_file_2" are the names
        of files that can hold data?
<pre><code>
	cmd_1 < data_file_1 | cmd_2 | cmd_3 > data_file_2
</code></pre>
	<ol class="answer_list">
	<li> Input redirection
	<li> Output redirection
	<li> Pipe(s)
	<li> The expression is illegal
	<li> None of the above
	</ol>
</li><br/>
<li> The following Unix "bash" shell expression uses which of these
	capabilities, where "data_file" is the name of a file containing
        data?
<pre><code>
	data_file > cmd_1 | cmd_2
</code></pre>
	<ol class="answer_list">
	<li> Input redirection
	<li> Output redirection
	<li> Pipe(s)
	<li> The expression is illegal
	<li> None of the above
	</ol>
</li><br/>
<li> In the Unix "bash" shell, to run a command in the background when it
	is first started
	<ol class="answer_list">
	<li> put a "|" at the end of the command line.
	<li> place a "&" at the end of the command line.
	<li> put the parts of the command line to run in the background
		between "<" and ">".
	<li> put the parts of the command line to run in the background
		between two "&".
	<li> None of the above
	</ol>
</li><br/>
<li> In the Unix "bash" shell, the job control action accomplished by
	^c (ctl-c) is to
	<ol class="answer_list">
	<li> terminate the foreground process.
	<li> terminate <strong>all</strong> background processes.
	<li> suspend the foreground process.
	<li> suspend <strong>all</strong> background processes.
	<li> None of the above
	</ol>
</li><br/>
<li> In the Unix "bash" shell, the job control action accomplished by
	^z (ctl-z) is to
	<ol class="answer_list">
	<li> terminate the foreground process.
	<li> terminate <strong>all</strong> background processes.
	<li> suspend the foreground process.
	<li> suspend <strong>all</strong> background processes.
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix "bash" shell command lists <strong>all</strong> (and only)
	the child processes of the current shell execution?
	<ol class="answer_list">
	<li> ps
	<li> list
	<li> procs
	<li> jobs
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix "bash" shell command causes a suspended/background process
	to run in the foreground?
	<ol class="answer_list">
	<li> fore
	<li> fg
	<li> &
	<li> job
	<li> None of the above
	</ol>
</li><br/>
<li> Which Unix "bash" shell command causes a suspended process to run in the
	background?
	<ol class="answer_list">
	<li> back
	<li> bg
	<li> &
	<li> job
	<li> None of the above
	</ol>
</li><br/>
<li> To get a listing of the signals which can be sent to a process in Unix,
	use this command
	<ol class="answer_list">
	<li> signal -list
	<li> kill -l
	<li> proc -sig
	<li> ps -l
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are true about Unix signals?
	<ol class="answer_list">
	<li> There is no mechanism to handle multiple signals of the same kind.
	<li> If a process doesn't specify a handler for a signal, then the OS
		will handle the signal using the default handler.
	<li> All signals have the same priority.
	<li> A process does <strong>not</strong> necessarily run immediately
		in the CPU when a signal is sent to it.
	<li> None of the above
	</ol>
</li><br/>


<li> The technique that allows data that flows from one "program piece" to
	the next "program piece" to remain in memory is known as
	<ol class="answer_list">
	<li> overflows.
	<li> overlays.
	<li> piecewise communication.
	<li> memory mapping.
	<li> None of the above
	</ol>
</li><br/>
<li> When the OS automatically breaks a process into multiple pieces of the
	same size, thus enabling processes otherwise too large to run within
	a smaller amount of memory, this is called
	<ol class="answer_list">
	<li> overlays.
	<li> memory mapping.
	<li> break out.
	<li> virtual memory.
	<li> None of the above
	</ol>
</li><br/>
<li> What is the most common virtual memory technique?
	<ol class="answer_list">
	<li> Overlays
	<li> Paging
	<li> Memory Mapping.
	<li> Swapping.
	<li> None of the above
	</ol>
</li><br/>
<li> The virtual address space of a process is
	<ol class="answer_list">
	<li> composed of those parts of main memory (e.g., RAM) holding
		parts of the process (e.g., code, run-time stack).
	<li> exactly the same size as the main memory (e.g., RAM) of the
		computer system.
	<li> larger than the maximum number of addressable bytes (e.g.,
		more than 2^32 bytes on a 32 bit architecture).
	<li> the address space the process would exist in if main memory
		(e.g., RAM) were big enough to hold the process, and the
		process was loaded into memory starting at address 0.
	<li> None of the above
	</ol>
</li><br/>
<li> Page frames are the
	<ol class="answer_list">
	<li> blocks in physical memory that hold virtual address space pages.
	<li> uniformly sized chunks that the virtual address space is divided
		into.
	<li> disk blocks that hold the virtual address space pages.
	<li> entries in the Memory Management Unit (MMU) that indicate which
		virtual address space page holds a desired address.
	<li> None of the above
	</ol>
</li><br/>
<li> What part of the computer system is responsible for converting a virtual
	address into a physical memory address?
	<ol class="answer_list">
	<li> Virtual Address Translation (VAT)
	<li> Memory Management Unit (MMU)
	<li> Arithmetic Logic Unit (ALU)
	<li> System Bus
	<li> None of the above
	</ol>
</li><br/>
<li> The standard implementation for a page (map) table of a process has an
	entry for each
	<ol class="answer_list">
	<li> page in the process' virtual address space.
	<li> page frame in physical (main) memory.
	<li> and only those virtual address space pages currently residing in
		a page frame.
	<li> and only those virtual address space pages currently
		<strong>not</strong> residing in a page frame.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> part of the page (map)
	table entries?
	<ol class="answer_list">
	<li> Referenced bit
	<li> Modified bit
	<li> Present/Absent bit
	<li> Page Frame number
	<li> None of the above
	</ol>
</li><br/>
<li> The higher order bits of a big-endian virtual address normally
	<ol class="answer_list">
	<li> are used as the index into the page table when translating
		a virtual address into a physical address.
	<li> represent the page in the virtual address space.
	<li> indicates which page frame the virtual address resides in.
	<li> provide the offset into the page frame for the virtual address.
	<li> None of the above
	</ol>
</li><br/>
<li> The lower order bits of a big-endian virtual address normally
	<ol class="answer_list">
	<li> are used as the index into the page table when translating
		a virtual address into a physical address.
	<li> represent the page in the virtual address space.
	<li> indicates which page frame the virtual address resides in.
	<li> provide the offset into the page frame for the virtual address.
	<li> None of the above
	</ol>
</li><br/>
<li> The page size for paged virtual memory is <strong>always</strong> a
	power of 2 because
	<ol class="answer_list">
	<li> it allows a fixed number of bits of the virtual address to be used
		as the page offset.
	<li> that's the convention often used when using binary computers.
	<li> adding the page offset to the page frame base can be done more
		quickly using "bit-wise or" rather than addition. 
	<li> the arrays (used to implement page tables) <strong>must</strong>
		have a power of 2 size.
	<li> None of the above
	</ol>
</li><br/>
<li> If, during virtual address translation, the entry in the page table for
	the virtual address has a 0 for the "present" bit, then 
	<ol class="answer_list">
	<li> the 0 page frame is used in calculating the physical address.
	<li> a page fault is generated.
	<li> the "present" bit is set to 1.
	<li> the "modified" bit is set to 1.
	<li> None of the above
	</ol>
</li><br/>
<li> The page table associated with a process is used when
	<ol class="answer_list">
	<li> the process transitions from the blocked to the ready state.
	<li> the next instruction in the process <strong>must</strong> be
		loaded.
	<li> a global page replacement algorithm is determining which page
		frame to reuse.
	<li> a value is stored into a variable (in memory).
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> normally part of the
	page table entry?
	<ol class="answer_list">
	<li> Caching disabled flag
	<li> Referenced bit
	<li> Modified bit
	<li> Present/Absent bit
	<li> Protection bit(s)
	<li> Page frame number
	<li> None of the above
	</ol>
</li><br/>
<li> Virtual address translation <strong>must</strong> be <em>very</em> fast
	since it
	<ol class="answer_list">
	<li> can happen many times for every instruction, depending upon the
		machine instructions provided by that computer system.
	<li> prevents the CPU from doing any other work while it is happening.
	<li> happens at least once for every instruction (to retrieve it).
	<li> ties up the system bus while it is happening.
	<li> None of the above
	</ol>
</li><br/>
<li> Assuming that page sizes remain the same, as virtual memories get bigger,
	so does the size of the
	<ol class="answer_list">
	<li> process table.
	<li> page frames.
	<li> page table.
	<li> Memory Management Unit (MMU).
	<li> None of the above
	</ol>
</li><br/>
<li> The Translation Lookaside Buffer (TLB) is part of the
	<ol class="answer_list">
	<li> System Bus.
	<li> Memory Management Unit (MMU).
	<li> Page Table.
	<li> Arithmetic Logic Unit (ALU).
	<li> None of the above
	</ol>
</li><br/>
<li> The Translation Lookaside Buffer (TLB) holds
	<ol class="answer_list">
	<li> the entire page table for a process.
	<li> many of the most recent virtual address translation results
		(since they're likely to be seen again - e.g., loops).
	<li> the process table entries for processes in the ready state.
	<li> a small number of (recently used) page table entries.
	<li> None of the above
	</ol>
</li><br/>
<li> Entries in the Translation Lookaside Buffer (TLB) <strong>must</strong>
	add this item as a field since it cannot be used as an index.
	<ol class="answer_list">
	<li> Page frame number.
	<li> Virtual address page number.
	<li> Present/absent bit.
	<li> Page offset.
	<li> None of the above
	</ol>
</li><br/>
<li> Finding the desired entry in a Translation Lookaside Buffer (TLB)
	<strong>must</strong> be very fast, so this is done by using a(n)
	<ol class="answer_list">
	<li> linear search.
	<li> binary search.
	<li> hash table.
	<li> associative memory.
	<li> None of the above
	</ol>
</li><br/>
<li> If a virtual address doesn't correspond to one of the rows in the
	Translation Lookaside Buffer (TLB), then
	<ol class="answer_list">
	<li> a page fault is generated.
	<li> the MMU updates the TLB immediately.
	<li> the TLB is purged and reloaded.
	<li> a lookup is performed using the full page table.
	<li> None of the above
	</ol>
</li><br/>
<li> If a Translation Lookaside Buffer (TLB) is larger, it can be effectively
	managed by software instead of by the Memory Management Unit (MMU).
	If a page entry is <strong>not</strong> in the TLB, but is in memory,
	this is called a
	<ol class="answer_list">
	<li> cache miss.
	<li> soft miss.
	<li> hard miss.
	<li> page entry fault.
	<li> None of the above
	</ol>
</li><br/>
<li> If a Translation Lookaside Buffer (TLB) is larger, it can be effectively
	managed by software instead of by the Memory Management Unit (MMU).
	If a page entry is <strong>not</strong> in the TLB, and is also
	<strong>not</strong> in memory, this is called a
	<ol class="answer_list">
	<li> cache miss.
	<li> soft miss.
	<li> hard miss.
	<li> page entry fault.
	<li> None of the above
	</ol>
</li><br/>
<li> As the size of the virtual address space increases, so to does the
	size of the page table (provided page size remains the same). 
	Techniques for dealing with very large page tables include
	<ol class="answer_list">
	<li> Multi-level Page Tables.
	<li> Hashed Page Tables.
	<li> Memory Mapped Page Tables.
	<li> Inverted Page Tables.
	<li> None of the above
	</ol>
</li><br/>
<li> Multi-level Page Tables divide the page table up into segments based on
	<ol class="answer_list">
	<li> which pages of the page table are referenced most frequently,
		reducing the number of page entries which need to be kept in
		memory.
	<li> how many processes are in the process table.
	<li> the higher order bits that index the page table (e.g., the top
		10 bits of the 32 bit virtual address indicates which group
		of 1024 pages to use - for 4K sized pages).
	<li> the size of a software managed Translation Lookaside Buffer (TLB),
		with each segment reflecting the TLB size.
	<li> None of the above
	</ol>
</li><br/>
<li> Instead of keeping a page table for each process, Inverted Page Tables
	have an entry for each
	<ol class="answer_list">
	<li> process, keeping track of which page frames are being used by
		that process.
	<li> virtual page, keeping track of which process the virtual page
		belongs to.
	<li> page frame, keeping track of which virtual page from which
		process is loaded in the corresponding page frame.
	<li> virtual page and process pairing, keeping track of which page
		frame corresponds to the pairing.
	<li> None of the above
	</ol>
</li><br/>
<li> In order to speed access to an Inverted Page Table, while still
	conserving space, they are often implemented using
	<ol class="answer_list">
	<li> content addressable memories.
	<li> hash tables.
	<li> 2 dimensional arrays.
	<li> balance B-trees.
	<li> None of the above
	</ol>
</li><br/>

<li> After <strong>all</strong> page frames in a system are occupied,
	page replacement in a virtual memory system is the process
	<ol class="answer_list">
	<li> of choosing a virtual page to load into a given page frame.
	<li> of choosing both a virtual page and a page frame in which to
		load the chosen virtual page.
	<li> of choosing a page frame and loading a given virtual page into that
		page frame.
	<li> that's performed in response to a page fault.
	<li> None of the above
	</ol>
</li><br/>
<li> The essentially unobtainable aspect of optimal page replacement which sets
	it apart from <strong>all</strong> other page replacement algorithms is
	<ol class="answer_list">
	<li> only loading virtual pages that will be used immediately (or in
		the very near future).
	<li> ensuring that no process ever thrashes.
	<li> ensuring that no page frame is replaced before
		<strong>all</strong> other frames have already been replaced.
	<li> only replacing page frames whose resident virtual page wont be
		used for the longest period of time.
	<li> None of the above
	</ol>
</li><br/>
<li> Nearly <strong>all</strong> page replacement algorithms make use of the
	following flag(s) which are associated with each page frame:
	<ol class="answer_list">
	<li> reference bit
	<li> cached bit
	<li> present bit
	<li> modified bit
	<li> None of the above
	</ol>
</li><br/>
<li> The reference bit associated with a page frame is set to
	<ol class="answer_list">
	<li> 0 whenever a virtual page is loaded into the frame. 
	<li> 0 only the first time a virtual page is loaded from the
		virtual address space.
	<li> 1 whenever a virtual page is loaded into a new page frame.
	<li> 1 whenever the page frame contents are changed.
	<li> None of the above
	</ol>
</li><br/>
<li> The modified bit associated with a page frame is set to
	<ol class="answer_list">
	<li> 0 whenever a virtual page is loaded into the frame. 
	<li> 0 only the first time a virtual page is loaded from the
		virtual address space.
	<li> 1 whenever a virtual page is loaded into a new page frame.
	<li> 1 whenever the page frame contents are changed.
	<li> None of the above
	</ol>
</li><br/>
<li> The Not-Recently-Used (NRU) page replacement algorithm replaces pages
	based on the values of their reference and modified bits. What is
	the preference ordering (most prefered replacement listed first) given
	the following combinations?
<pre>
	1 -> referenced, <strong>not</strong> modified
	2 -> <strong>not</strong> referenced, <strong>not</strong> modified
	3 -> referenced, modified
	4 -> <strong>not</strong> referenced, modified
</pre>
	<ol class="answer_list">
	<li> 1, 2, 3, 4
	<li> 2, 4, 1, 3
	<li> 3, 1, 2, 4
	<li> 4, 3, 2, 1
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm <strong>always</strong> replaces the
	oldest page, regardless of the value of the referenced and modified
	bits, is
	<ol class="answer_list">
	<li> First-in First-out Page Replacement
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm is the easiest to implement and often
	performs adequately?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Not Frequently Used (NFU) Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm is a variation of First-in First-out
	page replacement that uses the reference (R) bit. If the page frame
	being considered has R = 0, the page is replaced. Otherwise, if R = 1,
	then R is set to 0 and the page frame is put at the end of the queue
	to be considered again later.
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm cycles through the set of page frames
	in order (starting after where it left off last time) looking for one
	with R = 0, which it replaces when found. If R = 1, then R is set to
	0 and the next page frame is considered (until a suitable one is found).
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> A disadvantage of both Second-Chance and Clock page replacement algorithms
	is that
	<ol class="answer_list">
	<li> they can immediately (re)load the exact same virtual page already
		in the page frame.
	<li> modified pages are given preference for replacement.
	<li> if <strong>all</strong> reference bits = 1, then the entire
		"queue" <strong>must</strong> be iterated
		through before a replacement page will be found.
	<li> if <strong>all</strong> modified bits = 1, then the entire "queue"
		<strong>must</strong> be iterated
		through before a replacement page will be found.
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm replaces the page that has gone unused
	for the longest period of time?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm can make effective use of a counter
	associated with each page frame, with the counter value set to the
	global clock tick counter each time the page is referenced?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm adds the value of the page frame's R bit
	to a counter for that page frame, each time <strong>all</strong>
	of the R bits are reset? The counter is reset to 0 whenever a new page
	is loaded into the frame.
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> Not Frequently Used (NFU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm can end up replacing useful pages (e.g.,
	very recently used) instead of pages that haven't been used for a long
	time?
	<ol class="answer_list">
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Not Recently Used (NRU) Page Replacement
	<li> Not Frequently Used (NFU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm improves upon the primary deficiency of
	the Not Frequently Used (NFU) page replacement algorithm?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Not Recently Used (NRU) Page Replacement
	<li> Least Recently Used (NRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which algorithm is similar to the Not Frequently Used (NFU) page
        replacement algorithm, but instead of simply adding the R bit to the
        page frame counter, it shifts the counter 1 bit to the right before
        the leftmost bit is set to the R value?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Not Recently Used (NRU) Page Replacement
	<li> Least Recently Used (NRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Paging algorithms that only load virtual pages that are the cause of a
	page fault are categorized as
	<ol class="answer_list">
	<li> lazy paging.
	<li> eager paging.
	<li> laissez faire paging.
	<li> demand paging.
	<li> None of the above
	</ol>
</li><br/>
<li> Locality of reference is a property exhibited by most programs in which
	<ol class="answer_list">
	<li> nearly <strong>all</strong> the variables are declared within
		functions rather than as global/static variables.
	<li> the vast majority of program statements are some type of loop.
	<li> the parts of the virtual address space needed are usually close
		to those most recently used. 
	<li> only a small part of the virtual address space of a process is
		ever loaded into a page frame.
	<li> None of the above
	</ol>
</li><br/>
<li> The set of virtual pages that a process is currently using are known
	as the
	<ol class="answer_list">
	<li> loaded pages.
	<li> process set.
	<li> working set.
	<li> recency list.
	<li> None of the above
	</ol>
</li><br/>
<li> Which category of page replacement algorithms tries to reduce the page
	fault rate by <em>prepaging</em>?
	<ol class="answer_list">
	<li> Working set model
	<li> Global allocation
	<li> Local allocation
	<li> Process model
	<li> None of the above
	</ol>
</li><br/>
<li> Thrashing occurs in a multi-tasking system when by the next time a process
	is chosen to run in the CPU
	<ol class="answer_list">
	<li> it's already been blocked by another process.
	<li> it's been terminated by the OS kernel.
	<li> most of its needed virtual pages are <strong>not</strong>
		in page frames.
	<li> most of its needed virtual pages are already loaded in page frames.
	<li> None of the above
	</ol>
</li><br/>
<li> Thrashing is almost certain to occur when
	<ol class="answer_list">
	<li> the size of working sets for <strong>all</strong> processes
		varies greatly from one another.
	<li> the combined working sets of <strong>all</strong> runnable
		processes excedes the size of physical memory.
	<li> the Translation Lookaside Buffer is smaller than largest process
		working set.
	<li> there are more processes than will fit in the process table.
	<li> None of the above
	</ol>
</li><br/>
<li> The amount of time that a process has spent running in the CPU since
	the process started is known as its
	<ol class="answer_list">
	<li> CPU time.
	<li> process time.
	<li> processor virtual time.
	<li> current virtual time.
	<li> None of the above
	</ol>
</li><br/>
<li> The working set of a process is the list of virtual pages the process
	has used
	<ol class="answer_list">
	<li> within the last T seconds of its current virtual time.
	<li> since the process started.
	<li> since the process started or since the last time process was
		blocked (whichever is most recent).
	<li> since it last generated a page fault.
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithms introduce an additional field for page
	table entries that holds the last (virtual) time of use for that
	virtual page?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Aging Page Replacement
	<li> Working Set Model Page Replacement
	<li> Working Set Clock Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> For Working Set Model Page Replacement, the virtual page in a page
	frame is evicted if the reference (R) bit
	<ol class="answer_list">
	<li> = 1 and the current virtual time minus the time of last use is
		greater than a predetermined cutoff.
	<li> = 0 (regardless of the time of last use).
	<li> = 0 and the modified bit = 0 (regardless of the time of last use).
	<li> = 0 and the current virtual time minus the time of last use is
		greater than a predetermined cutoff.
	<li> None of the above
	</ol>
</li><br/>
<li> For Working Set Model Page Replacement, the virtual page in a page
	frame is evicted if the reference (R) bit
	<ol class="answer_list">
	<li> = 0, <strong>all</strong> virtual pages in page frames have been
		referenced within the predetermined cutoff, but this page
		has been referenced least recently.
	<li> = 0, <strong>all</strong> virtual pages in page frames have been
		referenced within the predetermined cutoff, but this page has
		been modified.
	<li> = 0 (regardless of the time of last use).
	<li> = 0 and the modified bit = 0 (regardless of the time of last use).
	<li> None of the above
	</ol>
</li><br/>
<li> The major disadvantage of Working Set Model Page Replacement is that it
	requires
	<ol class="answer_list">
	<li> an additional field for the page table entries (to
		hold the time of last use).
	<li> maintaining the current virtual time of each process.
	<li> each page table entry to be examined (to determine if the page
		is in a page frame and if so what its time of last use is).
	<li> the page entry be updated for <em>every</em> access to the page.
	<li> None of the above
	</ol>
</li><br/>
<li> Working Set Clock Page Replacement addresses the short-coming(s) of
	Working Set Model Page Replacement by
	<ol class="answer_list">
	<li> associating the time of last use with the page frame, rather than
		the page table entries.
	<li> only setting the time of use when that page frame is being
		considered for reuse, rather than every time a page fault
		occurs.
	<li> considering each page frame in a "round robin" fashion, rather 
		than looking for virtual pages that have been in a page
		frame for a sufficiently long period of time.
	<li> using the modified (M) bit in deciding whether to immediately
		reuse the page frame or not, rather than ignoring the M bit
		value.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following page replacement algorithms is widely used in
	practice due to its relatively simple implementation and good
	performance?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Clock Page Replacement
	<li> Working Set Clock Page Replacement.
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following page replacement algorithms schedules a modified
	page frame to be written back to disk <em>in advance</em> of evicting
	the virtual page from the page frame?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Aging Page Replacement
	<li> Working Set Model Page Replacement.
	<li> Working Set Clock Page Replacement.
	<li> None of the above
	</ol>
</li><br/>

<li> A global allocation policy, with respect to page replacement, is one in
	which the page frames considered for eviction are associated with
	<ol class="answer_list">
	<li> the process that generated the page fault.
	<li> most (generally all) processes.
	<li> only those processes in the ready state.
	<li> the process that generated the page fault along with
		<strong>all</strong> of its child processes.
	<li> None of the above
	</ol>
</li><br/>
<li> An advantage that a global allocation policy (GAP) generally has over
	a local allocation policy (LAP) is that
	<ol class="answer_list">
	<li> GAP increases the likelihood of thrashing.
	<li> LAP increases the likelihood of thrashing.
	<li> LAP can easily increase/decrease the number of virtual pages in
		physical memory for a process.
	<li> GAP can easily increase/decrease the number of virtual pages in
		physical memory for a process.
	<li> None of the above
	</ol>
</li><br/>
<li> A global allocation policy can cause thrashing if
	<ol class="answer_list">
	<li> the combined virtual address space of <strong>all</strong>
		processes is 10x larger than physical memory.
	<li> the pages for a process are nearly always modified.
	<li> a process' pages are evicted by the time it acquires the CPU.
	<li> demand paging is also used.
	<li> None of the above
	</ol>
</li><br/>
<li> A local allocation policy can cause thrashing if
	<ol class="answer_list">
	<li> the combined virtual address space of <strong>all</strong>
		processes is 10x larger than physical memory.
	<li> the pages for a process are nearly always modified.
	<li> demand paging is also used.
	<li> a process' working set is too small.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> a way to effectively
	deal with thrashing while the computer is running?
	<ol class="answer_list">
	<li> Swapping a process out to disk and giving its page frames
		to one or more of the processes left.
	<li> Add additional physical memory to the computer system.
	<li> Temporarily "block" the creation of any new processes if the
		combined working sets of existing processes is close to
		or exceeds the size of physical memory.
	<li> Increase the working set of <strong>all</strong> processes to
		ensure the virtual pages they need will be in page frames
		when the process gets the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> On average, the last page of a "segment" containing code or data will
	be half full. This is a reason to choose
	<ol class="answer_list">
	<li> smaller page sizes.
	<li> larger page sizes.
	<li> page sizes that are <strong>always</strong> a power of 2.
	<li> half sized pages (so the last one will be closer to full).
	<li> None of the above
	</ol>
</li><br/>
<li> Because the page table grows as the number of pages grows, this is a
	reason to use
	<ol class="answer_list">
	<li> smaller page sizes.
	<li> larger page sizes.
	<li> any page size since the page table size doesn't matter.
	<li> None of the above
	</ol>
</li><br/>
<li> Although the 4KB page size remains the most commonly used page size,
	IEEE published results suggest that a more appropriate page size
	would be
	<ol class="answer_list">
	<li> 2KB
	<li> 8KB
	<li> 16KB
	<li> 32KB
	<li> None of the above
	</ol>
</li><br/>
<li> While large 32 and 64 bit virtual address spaces make this less
	necessary, having separate address spaces for code and data can
	still be useful
	<ol class="answer_list">
	<li> for page replacement, so that only virtual pages containing data
		could be loaded into a page frame already holding data (and
		similarly for code/instructions).
	<li> to reduce the working set size of processes.
	<li> to prevent thrashing.
	<li> for parts of the memory hierarch (e.g., caches) which are small
		in size.
	<li> None of the above
	</ol>
</li><br/>
<li> Apart from interprocess communication, it's possible for different
	processes to share the same memory page (i.e., page frame) if
	<ol class="answer_list">
	<li> the page is read only.
	<li> any attempted modification to the page causes a copy to be made
		(and modified) for the writing process.
	<li> the pages are part of a shared library.
	<li> when one of the sharing processes is swapped out (or finishes)
		that the shared pages aren't also evicted.
	<li> None of the above
	</ol>
</li><br/>
<li> When a change to a shared page causes a copy of the page to
	first be made, and then the change made to the copy, this is called
	<ol class="answer_list">
	<li> write through.
	<li> copy on write.
	<li> writable copying.
	<li> page duping.
	<li> None of the above
	</ol>
</li><br/>
<li> Compared to statically linked executables, shared libraries
	<ol class="answer_list">
	<li> decreases the demands on physical memory, allowing more
		processes to execute.
	<li> enable programs to use updated libraries <strong>without</strong>
		being recompiled.
	<li> often reduce the size of executable programs.
	<li> reduce the chance of thrashing.
	<li> None of the above
	</ol>
</li><br/>
<li> Shared libraries and shared memory pages are
	<ol class="answer_list">
	<li> related because the code corresponding to a shared library is
		often held in a shared memory page.
	<li> interdependent since shared memory pages only exist for
		implementing shared libraries.
	<li> completely different since the code for shared libraries is
		statically linked to each program separately at compile time
		while shared memory pages are assigned at run-time.
	<li> there is no relationship except that both can be shared by
		multiple processes.
	<li> None of the above
	</ol>
</li><br/>
<li> <em>Position independent-code</em> is used to solve the problem of using
	absolute addressing for shared libraries since
	<ol class="answer_list">
	<li> different processes could load the shared library at different
		locations in their virtual address spaces.
	<li> base offset addressing cannot be used because the offsets will
		be different for each process.
	<li> the page table entries of the sharing processes may each point to
		different page frames.
	<li> the combined size of the libraries and program code could be
		larger than physical memory.
	<li> None of the above
	</ol>
</li><br/>
<li> <em>Mapped files</em> enable processes to work with files as if they
	were large character arrays by 
	<ol class="answer_list">
	<li> copying the file contents to shared memory page frames.
	<li> redirecting the file contents as input to the process.
	<li> mapping the file to the virtual address space for the process.
	<li> using pipes to stream the data from the file to the process.
	<li> None of the above
	</ol>
</li><br/>
<li> Having multiple processes share the same mapped file, enables
	<ol class="answer_list">
	<li> the file to be larger than it would if only mapped by a single
		process.
	<li> a larger number of processes to be executing at once.
	<li> mutual exclusion on the critical sections of each process.
	<li> fast interprocess communication.
	<li> None of the above
	</ol>
</li><br/>
<li> Because page replacement algorithms <strong>must</strong> write modified
	page frames back to disk before loading in another virtual page, thus
	slowing down the resolution of a page fault,
	<ol class="answer_list">
	<li> many page replacement algorithms give preference to UNmodified
		pages over modified pages.
	<li> page modifications are often implemented as <em>write-through</em>
		so that the dirty page is immediately written out to disk after
		each change.
	<li> a <em>paging daemon</em> can be used as a background process to
		write dirty pages back to disk, reducing the number of dirty
		page frames.
	<li> the frequency of page modifications is reduced by translating
		writes to the page directly into writes out to the disk.
	<li> None of the above
	</ol>
</li><br/>

<li> When the OS creates a new process, and its corresponding entry in the
	process table, it <strong>must</strong> also
	<ol class="answer_list">
	<li> add it to the set of blocked processes.
	<li> create a page table for the process.
	<li> allocate a swap area (on disk) for the process.
	<li> pre-load its working set into page frames.
	<li> None of the above
	</ol>
</li><br/>
<li> When a context switch occurs to run a process,
	<ol class="answer_list">
	<li> reset <strong>all</strong> of the "present" bits in the process'
		page table to 0 (showing that they are <strong>not</strong>
		loaded into page frames).
	<li> the Memory Management Unit (MMU) <strong>must</strong> be reset.
	<li> restore the CPU registers to the values they had when the process
		was last running.
	<li> the Translation Lookaside Buffer (TLB) <strong>must</strong>
		be flushed.
	<li> None of the above
	</ol>
</li><br/>
<li> What is often one of the easiest (and often cheapest) ways to increase
	the speed of a computer system?
	<ol class="answer_list">
	<li> Upgrade to a faster processor.
	<li> Add more memory.
	<li> Add more hard disk space.
	<li> Add more processors.
	<li> None of the above
	</ol>
</li><br/>
<li> When a process terminates, the OS should
	<ol class="answer_list">
	<li> release the page frames it was using (unless they were shared
		and other processes are still using them).
	<li> release/deallocate the process' page table.
	<li> free the disk space assigned as the process' swap area.
	<li> remove its entry from the process table.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following steps are typically done to handle a page fault:
	<ol class="answer_list">
	<li> the hardware traps to the OS kernel
	<li> the program counter (and instruction information) is saved
	<li> general registers values are saved before calling the OS
	<li> the faulting process is swapped out to disk
	<li> the OS determines which virtual page is needed
	<li> ensure the virtual address is valid
	<li> Use the Translation Lookaside Buffer (TLB) to find a page frame
		to use
	<li> <strong>always</strong> schedule the chosen page frame to be
		written back to disk
	<li> update the page table after the page is loaded into the page frame
	<li> load the swapped out faulting process back into memory
	<li> set the program counter back to the instruction that caused the
		page fault
	<li> schedule the faulting process to run
	</ol>
</li><br/>
<li> Instruction backup is necessary because
	<ol class="answer_list">
	<li> while the first part of the instruction was in physical memory
		the last portion may not be - causing a page fault.
	<li> a context switch requires that the last instruction attempted
		by the process being evicted from the CPU <strong>must</strong>
		be reexecuted when the process runs again.
	<li> if the instruction causes a page fault, some or all of it will
		need to be reexecuted.
	<li> just like for files, you need to ensure that the instruction
		doesn't get removed accidentally.
	<li> None of the above
	</ol>
</li><br/>
<li> Locking a page in memory (i.e., pinning), so that the page replacement
	algorithm cannot select it for eviction, is necessary because
	<ol class="answer_list">
	<li> it reduces the likelihood of thrashing.
	<li> some operations load file data directly into a page frame, and
		reassigning the page could expose protected information to
		another process.
	<li> most page replacement algorithms would preferentially choose
		the most recently loaded page again for replacement.
	<li> if modified, it needs to be written back to disk by the
		paging daemon before it's reused.
	<li> None of the above
	</ol>
</li><br/>
<li> The swap area on disk associated with a process is
	<ol class="answer_list">
	<li> only needed if the virtual address space is larger than physical
		memory.
	<li> <strong>not</strong> necessary, but can help improve performance.
	<li> created when a process gets its first page fault.
	<li> used to store process information <strong>not</strong> currently
		in memory (e.g., a page frame).
	<li> None of the above
	</ol>
</li><br/>
<li> Basic approaches for allocating swap space include allocating space
	<ol class="answer_list">
	<li> for the entire process when the process is initially created.
	<li> for the entire process only after the process
		generates its first page fault.
	<li> only for pages <strong>not</strong> currently in physical memory,
		adding to the allocation as needed (e.g., when the run-time
		stack grows).
	<li> only when the run-time stack or heap grow beyond a certain
		pre-defined limit.
	<li> None of the above
	</ol>
</li><br/>
<li> A drawback of initially allocating <strong>all</strong> the swap space
	for a process is
	<ol class="answer_list">
	<li> that a larger than necessary page table <strong>must</strong>
		also be created.
	<li> the corresponding process table entry is larger.
	<li> as the process needs more space (e.g., for the run-time stack)
		it may need to copy the swap area to a larger chunk of disk
		space.
	<li> it can increase the chance of thrashing since there are more
		virtual pages that might need to be loaded into page frames.
	<li> None of the above
	</ol>
</li><br/>
<li> Allocating space in the swap area only for a process' pages
	<strong>not</strong> currently in physical memory
	<ol class="answer_list">
	<li> decreases the size of the page table.
	<li> often reduces the total amount of swap space needed.
	<li> reduces the chance of thrashing since there are fewer
		virtual pages that might need to be loaded into page frames.
	<li> easily handles the case when a process' address space
		<strong>must</strong> increase (e.g., for the run-time stack).
	<li> None of the above
	</ol>
</li><br/>
<li> The separation of policy and mechanism with respect to virtual memory
	and page replacement algorithms is
	<ol class="answer_list">
	<li> <strong>not</strong> attainable since page replacement algorithms
		need access to the page tables which are protected data within
		the OS kernel.
	<li> can be done by having the MMU and page fault handlers run within
		the OS kernel while a user space  page loader copies the
		virtual page to memory (the page fault handler remaps the page
		frame to the process afterwards). 
	<li> while theoretically possible, there are no operating systems that
		currently implement this capability.
	<li> is possible, though somewhat complicated, and is implemented
		by the Mach kernel.
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following are <strong>not</strong> essential qualities of
	files?
	<ol class="answer_list">
	<li> Multiple processes can access the same file simultaneously.
	<li> Are stored on either hard disk drives (HDDs) or solid-state
		disks (SSDs).
	<li> Ability to store LARGE amounts of information.
	<li> The lifetime of a file is not bound to any process.
	<li> None of the above
	</ol>
</li><br/>
<li> The file system provides an abstraction of how files are
	<ol class="answer_list">
	<li> manipulated.
	<li> read.
	<li> managed.
	<li> written.
	<li> None of the above
	</ol>
</li><br/>
<li> File names
	<ol class="answer_list">
	<li> are a sequence of (readable) characters for referring to the file.
	<li> may be of any length, and contain both upper and lower case
		characters.
	<li> <strong>must</strong> have a single extension
		(e.g., ".txt", ".exe") indicating the type of data they hold.
	<li> differ from system to system, depending upon the file system(s)
		the OS makes available.
	<li> None of the above
	</ol>
</li><br/>
<li> The extension (e.g.,  ".txt", ".exe") for a file name
	<ol class="answer_list">
	<li> is typically only meaningful to application programs.
	<li> indicates to the file system what type of data to restrict the
		file to holding (e.g., a ".txt" file may not hold a pdf
		document).
	<li> is a convenience to users to make it easier to discern what
		kind of data each file holds.
	<li> can be ignored by the OS (e.g., Unix/Linux).
	<li> None of the above
	</ol>
</li><br/>
<li> The logical organization of the information in a file is called its
	<ol class="answer_list">
	<li> file type.
	<li> file system.
	<li> file structure.
	<li> file attributes.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are the basic types of file structures?
	<ol class="answer_list">
	<li> Unstructured sequence of bytes.
	<li> Sequence of (structured) records.
	<li> List of object-oriented tables.
	<li> Tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> Regular files in Unix/Linux and Windows are organized as
	<ol class="answer_list">
	<li> an unstructured sequence of bytes.
	<li> a sequence of (structured) records.
	<li> a list of object-oriented tables.
	<li> a tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> Indexed Sequential Access Method (ISAM) files on mainframes are organized
	as
	<ol class="answer_list">
	<li> an unstructured sequence of bytes.
	<li> a sequence of (structured) records.
	<li> a list of object-oriented tables.
	<li> a tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> Indexed Virtual Storage Access Method (Indexed VSAM) files on mainframes
	are organized as
	<ol class="answer_list">
	<li> an unstructured sequence of bytes.
	<li> a sequence of (structured) records.
	<li> a list of object-oriented tables.
	<li> a tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> File types describe the broad categorization of the kinds of information
	a file represents/holds. Which of the following are common file types?
	<ol class="answer_list">
	<li> Regular (data) files.
	<li> Executable files.
	<li> Special (device) files.
	<li> Directories.
	<li> None of the above
	</ol>
</li><br/>
<li> Files that model I/O devices that work with one byte at time are called
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> Files that model I/O devices that work with arrays of bytes at a time
	are called
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> Devices such as keyboards, mice, and printers usually correspond to
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> Devices such as hard disk drives (HDDs) and solid-state disks (SSDs)
	usually correspond to
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> The two primary file access methods are
	<ol class="answer_list">
	<li> Linear access.
	<li> Sequential access.
	<li> Indexed access.
	<li> Random access.
	<li> None of the above
	</ol>
</li><br/>
<li> If accessing the Nth byte of a file requires first accessing byte N-1,
	then the file access type is
	<ol class="answer_list">
	<li> Linear access.
	<li> Sequential access.
	<li> Indexed access.
	<li> Random access.
	<li> None of the above
	</ol>
</li><br/>
<li> If accessing the Nth byte of a file can be done <strong>without</strong>
	first accessing byte N-1, then the file access type is
	<ol class="answer_list">
	<li> Linear access.
	<li> Sequential access.
	<li> Indexed access.
	<li> Random access.
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX system call can be used to skip to a particular byte
	location within a file (thus supporting random access)?
	<ol class="answer_list">
	<li> find
	<li> lseek
	<li> skip
	<li> rand
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file attributes are common to many systems?
	<ol class="answer_list">
	<li> File name.
	<li> The number of disk blocks the file occupies.
	<li> Size of the file in bytes.
	<li> The optimal block size for reading or writing this file
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to create a new file?
	<ol class="answer_list">
	<li> creat
	<li> mkfile
	<li> new
	<li> make
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to open an existing file (for reading
	or writing)?
	<ol class="answer_list">
	<li> stat
	<li> fopen
	<li> find
	<li> create
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to close an open file (ensuring that any
	buffers are written back disk)?
	<ol class="answer_list">
	<li> end
	<li> flush
	<li> fclose
	<li> done
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to delete an existing file?
	<ol class="answer_list">
	<li> delete
	<li> free
	<li> deallocate
	<li> remove
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to read data from a file?
	<ol class="answer_list">
	<li> read
	<li> read_byte
	<li> scan
	<li> get_byte
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to write data to a file?
	<ol class="answer_list">
	<li> print
	<li> put_char
	<li> write
	<li> write_byte
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to set the current position within an open file?
	<ol class="answer_list">
	<li> find
	<li> locate
	<li> seek
	<li> position
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to obtain information about a file?
	<ol class="answer_list">
	<li> get_info
	<li> finfo
	<li> fattr
	<li> stat
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the name of an existing file?
	<ol class="answer_list">
	<li> move
	<li> rename
	<li> chfile
	<li> touch
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the owner of a file?
	<ol class="answer_list">
	<li> finfo
	<li> fattr
	<li> chown
	<li> owner
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the permissions of a file?
	<ol class="answer_list">
	<li> perm
	<li> chmod
	<li> chperm
	<li> stat
	<li> None of the above
	</ol>
</li><br/>

<li> File systems that have only a single directory of files, with no
	sub-directory hierarchies
	<ol class="answer_list">
	<li> are called flat file systems.
	<li> can accommodate larger files than a hierarchical file system.
	<li> were being used until the mid-1980s.
	<li> are in common use today, typically for USB flash drives.
	<li> None of the above
	</ol>
</li><br/>
<li> The most common type of file system in use today are
	<ol class="answer_list">
	<li> flat file systems.
	<li> linear file systems.
	<li> indexed file systems.
	<li> hierarchical file systems.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links to files
	<ol class="answer_list">
	<li> require the file to be copied, with future changes to the
		original being propigated to the copy.
	<li> maintain a single copy of the file, but accessible from different
		places/directories within the file system.
	<li> use "copy on write" to maintain a single copy of the file until
		a change is made.
	<li> is the kind used when a file is first created.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links to a directory, from within the current directory,
	<ol class="answer_list">
	<li> can be created <strong>without</strong> any issues.
	<li> are only allowed when the directory being linked to is an
		ancestor (i.e., occurs in the path of the current location).
	<li> are only allowed when the directory being linked to is a
		decendant (e.g., child, grandchild) of the current directory.
	<li> are <strong>not</strong> allowed since this would create a
		circular structure that wouldn't be freeable later.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links can be used
	<ol class="answer_list">
	<li> to link to files on the same computer but in a different file
		system.
	<li> to link to remote files on different computer systems.
	<li> only to link to files on the same computer, either in the same
		or a different file system.
	<li> only to link to files within the same physical file system.
	<li> None of the above
	</ol>
</li><br/>
<li> Symbolic (soft) links to files and directories
	<ol class="answer_list">
	<li> can link to files and directories in different file
		systems as well as on different computers.
	<li> can link to non-existent files.
	<li> are allowed to create circular structures (e.g., a directory
		can have itself as its parent/child).
	<li> are automatically deleted when the orignal file/directory is
		removed.
	<li> None of the above
	</ol>
</li><br/>
<li> Absolute path names begin with a
	<ol class="answer_list">
	<li> "./" on both Unix/Linux and Windows systems.
	<li> "../" on both Unix/Linux and Windows systems.
	<li> slash (/) on Unix/Linux systems.
	<li> drive letter (e.g., A:) on a Windows system.
	<li> None of the above
	</ol>
</li><br/>
<li> Relative path names specify the location of a file or directory
	<ol class="answer_list">
	<li> starting from the current working directory.
	<li> with respect to the root directory of the file system.
	<li> relative to the user's home directory.
	<li> starting from the directory where the program requesting the
		file is located.
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to create a new directory?
	<ol class="answer_list">
	<li> new
	<li> mkdir
	<li> dir
	<li> create
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to delete an existing directory?
	<ol class="answer_list">
	<li> remove
	<li> delete
	<li> rmdir
	<li> free
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to open a directory for examination?
	<ol class="answer_list">
	<li> find
	<li> stat
	<li> examine
	<li> opendir
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to close a directory and ensure that any
	changes to it are written back to the disk?
	<ol class="answer_list">
	<li> closedir
	<li> flush
	<li> finish
	<li> done
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the name of a directory?
	<ol class="answer_list">
	<li> move
	<li> rename
	<li> chname
	<li> chmod
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to create a new directory entry for an existing
	file?
	<ol class="answer_list">
	<li> add2dir
	<li> direntry
	<li> link
	<li> new
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to remove the directory entry for a file?
	<ol class="answer_list">
	<li> rmfile
	<li> delete
	<li> free
	<li> unlink
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the current working directory?
	<ol class="answer_list">
	<li> pwd
	<li> chdir
	<li> cd
	<li> go2dir
	<li> None of the above
	</ol>
</li><br/>
<li> The key difference(s) between hard links and soft/symbolic links are that
	<ol class="answer_list">
	<li> soft links allow files to be accessed randomly while hard linked
		files are limited to sequential access. 
	<li> soft links are implemented by software but hard links require
		hardware support to be implemented.
	<li> hard links point to a physical (disk) location while soft links
		give the "directions" (i.e., path) to the linked file.
	<li> hard links provide copy on write semantics whereas symbolic links
		do <strong>not</strong>.
	<li> None of the above
	</ol>
</li><br/>
<li> Deleting a soft link
	<ol class="answer_list">
	<li> <strong>always</strong> deletes the file that the link pointed to.
	<li> will delete the file the link points to, but only if the file
		is located on the same file system as the link.
	<li> will delete the file the link points to, but only if this is
		the last soft link to the file.
	<li> <strong>never</strong> deletes the file that the link pointed to.
	<li> None of the above
	</ol>
</li><br/>
<li> Deleting a hard link
	<ol class="answer_list">
	<li> <strong>always</strong> deletes the file that the link pointed to.
	<li> will delete the file the link points to, but only if the file
		is located on the same file system as the link.
	<li> will delete the file the link points to, but only if this is
		the last hard link to the file.
	<li> <strong>never</strong> deletes the file that the link pointed to.
	<li> None of the above
	</ol>
</li><br/>
<li> Soft links can point to files
	<ol class="answer_list">
	<li> but only when there's <strong>not</strong> another soft link
		already pointing to them.
	<li> but only when there's <strong>not</strong> a hard link already
		pointing to them.
	<li> that don't actually exist.
	<li> on different file systems.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links can point to files
	<ol class="answer_list">
	<li> but only when there's <strong>not</strong> a soft link already
		pointing to them.
	<li> but only when there's <strong>not</strong> another hard link
		already pointing to them.
	<li> that don't actually exist.
	<li> on different file systems.
	<li> None of the above
	</ol>
</li><br/>

<li> File systems are
	<ol class="answer_list">
	<li> <strong>all</strong> very similar with the few differences
		between them of little importance.
	<li> nearly always stored on disk (either HDD or SSD).
	<li> dedicated to the OS, with each OS supporting only a single
		file system.
	<li> generally contained within a single disk partition (if stored on
		a disk).
	<li> None of the above
	</ol>
</li><br/>
<li> A disk (either HDD or SSD) has
	<ol class="answer_list">
	<li> a single Master Boot Record (MBR).
	<li> one or more partitions.
	<li> a boot block for each partition.
	<li> a partition table (stored at the end of the MBR).
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> steps in the boot process?
	<ol class="answer_list">
	<li> the BIOS identifies the boot device and ensures it's attached.
	<li> the program in the Master Boot Record (MBR) is loaded and run.
	<li> the MBR program loads and runs the code in the first block of the
		active partition.
	<li> the boot block program loads the OS from the active partition.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> part of every disk
	partition?
	<ol class="answer_list">
	<li> Root directory
	<li> Boot block
	<li> Superblock
	<li> Master Boot Record (MBR)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> a basic technique for
	implementing files?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique stores the file in consecutive disk
	blocks, so that only the last block has any wasted space?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique uses the first word of each block
	(or alternately a separate table representing those words) to indicate
	the disk block holding the next portion of the file?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique only requires the location of the
	first disk block and the number of disk blocks allocated for the file
	in order to access it?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique uses a single data structure that
	stores standard metadata along with direct and indirect pointers to
	the file blocks containing the file data?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file implementation techniques suffers from
	external fragmentation if files can be removed or modified?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file implementation techniques completely
	avoid any internal fragmentation?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> File Allocation Tables are an aspect of which of the following file
	implementation techniques?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file implementation techniques has the
	<strong>best</strong> support for random access?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file system implementation is suitable for smaller disks
	but is less suitable as the size of the disk grows larger?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> File Allocation Table (FAT)
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> An advantage that i-nodes have over FAT file systems is that
	<ol class="answer_list">
	<li> they have better performance for randomly accessing files.
	<li> they have less external fragmentation.
	<li> they have less internal fragmentation.
	<li> only direct and indirect links to the disk blocks for the desired
		file (and no other files) are needed in memory.
	<li> None of the above
	</ol>
</li><br/>
<li> ISO 9660 was developed for use by compact disks (for music) and later
	DVDs (for movies). Which file system implementation approach is
	ISO 9660 an example of?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> File Allocation Table (FAT)
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> a commonly used technique
	for storing file/directory names in directory entries?
	<ol class="answer_list">
	<li> Use a fixed amount of space for the name (e.g., 8.3 names).
	<li> Allocate the string for the name from heap storage and put the
		pointer in the directory entry.
	<li> Allow directory entries to be variable in length with the file
		name appearing at the end of the entry.
	<li> Each directory entire has a pointer into a shared string space
		for storing <strong>all</strong> the names in that directory.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are true about the root directory of a file
	system?
	<ol class="answer_list">
	<li> It's the only file/directory <strong>without</strong> a name.
	<li> Both hard and soft links to the root directory are
		<strong>not</strong> allowed.
	<li> The root is stored in the boot block of the file system partition.
	<li> A pointer to it <strong>must</strong> be kept in a known/standard
		location.
	<li> None of the above
	</ol>
</li><br/>
<li> The attributes associated with a file (or directory) are
	<ol class="answer_list">
	<li> <strong>always</strong> stored in its directory entry.
	<li> are stored in the directory entry for contiguous and linked list
		file allocations.
	<li> are stored in the file's (or directory's) i-node if index-nodes
		are used for file allocation.
	<li> <strong>never</strong> stored in its directory entry.
	<li> None of the above
	</ol>
</li><br/>
<li> As the number of directory entries increases (e.g., >= 100),
	<ol class="answer_list">
	<li> searching for a file (or directory) name may get slower if a
		hash table isn't used.
	<li> the i-nodes used (for an index-node implementation) increases
		faster than the number of files in the directory.
	<li> space within the directory (itself a special file) is likely
		to become exhausted.
	<li> the file system as a whole becomes slower to access.
	<li> None of the above
	</ol>
</li><br/>
<li> Soft links are slower to access a file than hard links because
	<ol class="answer_list">
	<li> every file system on the disk (in different partitions)
		<strong>must</strong> be checked for the file.
	<li> hard links point directly to the file (e.g., via its
		i-node number). 
	<li> the linked file is <strong>always</strong> specified as an
		absolute path.
	<li> they require visiting (multiple) other directories along the
		indicated file path to find the linked file.
	<li> None of the above
	</ol>
</li><br/>
<li> Copying soft links can be problematic because
	<ol class="answer_list">
	<li> there are two ways to copy them, making a copy of the link or
		making a copy of the file the link points to.
	<li> the link may point to another file system, and copies across
		file systems cannot be done.
	<li> the resulting copy will <strong>always</strong> be a soft link.
	<li> they can sometimes be mistaken for a hard link by the OS.
	<li> None of the above
	</ol>
</li><br/>
<li> Log structure files buffer writes, to a hard disk disk (HDD), in memory
	<ol class="answer_list">
	<li> improving the write efficiency to the disk while reducing wait
		time for processes writing to disk.
	<li> thus preventing file system problems if a system failure occurs.
	<li> but this increases the risk that information will be lost if a
		system failure occurs.
	<li> because file system operations generally require many small writes
		to the HDD, so bundling them together improves efficiency.
	<li> None of the above
	</ol>
</li><br/>
<li> Log structure files
	<ol class="answer_list">
	<li> keep a complete record of <strong>all</strong> writes that have
		ever been made to a disk drive.
	<li> are becoming increasingly important to have as solid state disks
		(SSDs) become more common.
	<li> are becoming less necessary as hard disk drives (HDDs) are replaced
		with solid state disks (SSDs).
	<li> have a special process that regularly "cleans" and compacts them
		(as some items in the log are no longer needed as time passes).
	<li> None of the above
	</ol>
</li><br/>
<li> Journaling file systems are used to
	<ol class="answer_list">
	<li> improve the write efficiency to the disk.
	<li> prevent file system problems if a system failure occurs.
	<li> enable access to remote file systems.
	<li> create an up-to-date backup of a file system, so that it can be
		restored in the case of a disk failure/crash.
	<li> None of the above
	</ol>
</li><br/>
<li> A journaling file system keeps a log of actions to be performed
	<ol class="answer_list">
	<li> to improve the write efficiency to the disk.
	<li> removing them only after their completion has been confirmed.
	<li> but each action <strong>must</strong> be <em>idempotent</em> in
		case there are multiple system crashes.
	<li> to create an up-to-date backup of a file system, so that it can be
		restored in the case of a disk failure/crash.
	<li> None of the above
	</ol>
</li><br/>
<li> An <em>idempotent</em> operation is one that
	<ol class="answer_list">
	<li> makes an atomic change to disk (i.e., either the entire operation
		completes or none of it does).
	<li> <strong>always</strong> runs from within a critical section.
	<li> is <strong>not</strong> critical, so that if it
		<strong>never</strong> gets performed it's okay.
	<li> <strong>must</strong> be executed <em>exactly</em> once
		(e.g., making a deposit to a bank account). 
	<li> None of the above
	</ol>
</li><br/>
<li> A virtual file system
	<ol class="answer_list">
	<li> implements both journaling and log file structures, improving
		both efficiency and safety.
	<li> enables multiple file systems to be seamless integrated so that
		they appear as a single file system.
	<li> provides access to file systems on remote computers.
	<li> ensures that both soft and hard links can be used across file
		systems.
	<li> None of the above
	</ol>
</li><br/>
<li> A virtual file system
	<ol class="answer_list">
	<li> does <strong>not</strong> actually store files itself, but
		interfaces with multiple other file systems.
	<li> stores files on disks that are shared among multiple computer
		systems.
	<li> provides access to file systems on remote computers.
	<li> ensures that both soft and hard links can be used across file
		systems.
	<li> None of the above
	</ol>
</li><br/>

<li> Most file systems do <strong>not</strong> store files in contiguous disk
	blocks because
	<ol class="answer_list">
	<li> this makes the file system design and implementation simpler.
	<li> of the delay that the rotational latency of a HDD requires when
		the disk blocks are next to one another.
	<li> it reduces the amount of internal fragmentation.
	<li> files tend to grow in size, requiring the disk blocks for the 
		file to be copied.
	<li> None of the above
	</ol>
</li><br/>
<li> For the same size disk, larger disk block sizes tend to
	<ol class="answer_list">
	<li> improve the data transfer rate to and from disk.
	<li> reduce internal fragmentation.
	<li> reduce the number of blocks needed to store a file.
	<li> decrease the amount of storage need to keep track of bad disk
		blocks.
	<li> None of the above
	</ol>
</li><br/>
<li> It's not uncommon, particularly for hard disk drives (HDDs), for disk
	blocks to become bad. To avoid using them, bad blocks are
	<ol class="answer_list">
	<li> tracked by the controller in a list stored in a pre-specified
		disk location.
	<li> filled with a special value to identify them.
	<li> moved to another location on the disk.
	<li> removed from the list of free blocks.
	<li> None of the above
	</ol>
</li><br/>
<li> The free (unused) blocks on a disk are often tracked by
	<ol class="answer_list">
	<li> moving the used blocks to the lower disk block numbers (i.e.,
		compacting) and keeping a single number which is the lowest
		disk number of the set of contiguous free blocks.
	<li> exchanging (copying) free blocks and used blocks (as a
		background process) to combine the free blocks into a small
		number of contiguous areas.
	<li> keeping a linked list of blocks, with each block in the list
		pointing to a large number of free blocks.
	<li> using a bit map contained in 1 or more blocks, with bits
		having either a value of 1 (used) or 0 (free).
	<li> None of the above
	</ol>
</li><br/>
<li> Disk quotas are a mechanism to prevent
	<ol class="answer_list">
	<li> account holders from using more than their "fair share"
		of the file system space.
	<li> disk failure due to overuse.
	<li> the inadvertent loss of files due to user error.
	<li> a disk from filling up.
	<li> None of the above
	</ol>
</li><br/>
<li> A disk quota can be used to limit the total
	<ol class="answer_list">
	<li> amount of space on the disk.
	<li> amount of disk space a user's files take up.
	<li> number of swap areas (and thus processes) that can exist. 
	<li> number of files a user has.
	<li> None of the above
	</ol>
</li><br/>
<li> A disk quota soft limit
	<ol class="answer_list">
	<li> warns the user when they are getting close to their hard limit.
	<li> prevents the creation of new files when exceeded, but allows
		existing files to be appended to.
	<li> restricts the number of executable files (software) that the
		user has.
	<li> indicates the maximum number of soft links that the user can
		have.
	<li> None of the above
	</ol>
</li><br/>
<li> A disk quota hard limit
	<ol class="answer_list">
	<li> is the maximum amount of space (or number of files) a user is
		permitted to have.
	<li> applies only to hard disk drives (HDDs).
	<li> can prevent a user from saving their work, if reached.
	<li> indicates the maximum number of hard links that the user can
		have.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary types of file system backups are
	<ol class="answer_list">
	<li> physical dump.
	<li> traditional dump.
	<li> logical dump.
	<li> virtual dump.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of file system dump is fast and simple to implement, but
	can't do incremental backups or restore select files?
	<ol class="answer_list">
	<li> physical dump.
	<li> traditional dump.
	<li> logical dump.
	<li> virtual dump.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of file system dump can restore select files and dump only
	changed files and directories, but is slower and more complex to
	implement?
	<ol class="answer_list">
	<li> physical dump.
	<li> traditional dump.
	<li> logical dump.
	<li> virtual dump.
	<li> None of the above
	</ol>
</li><br/>
<li> A <em>full backup</em> is
	<ol class="answer_list">
	<li> taken when a file system is full, so it can be stored off-site.
	<li> a complete copy of the current state of the file system.
	<li> done when each user has reached their disk quota soft limit.
	<li> done when each user has reached their disk quota hard limit.
	<li> None of the above
	</ol>
</li><br/>
<li> An <em>incremental backup</em> is
	<ol class="answer_list">
	<li> frequently used because it takes less space and finishes more
		quickly than a full backup.
	<li> created whenever a user reaches their disk quota soft limit.
	<li> used to make copies of only those files (and directories) that
		have changed since the last backup.
	<li> performed automatically by the file system on a periodic basis.
	<li> None of the above
	</ol>
</li><br/>
<li> Keeping file system backups on-site is
	<ol class="answer_list">
	<li> preferred as this makes it easier and faster to restore user files.
	<li> <strong>never</strong> a good idea since a single problem
		(e.g., tornado) can cause a loss of both the file system
		(on disks) and its backup.
	<li> no better or worse than keeping them off-site.
	<li> necessary only if the backup is made to other disks in near
		real-time.
	<li> None of the above
	</ol>
</li><br/>
<li> For an i-node based file system, which type of check recursively
	traverses a directory keeping a count for each i-node of the number
	of references to that i-node?
	<ol class="answer_list">
	<li> OS consistency check
	<li> File consistency check
	<li> Block consistency check
	<li> I-node check
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of check uses two counters per disk block to count the number
	of times they are pointed to by either an i-node (1st counter) or
	from the free list (2nd counter)?
	<ol class="answer_list">
	<li> OS consistency check
	<li> File consistency check
	<li> Block consistency check
	<li> I-node check
	<li> None of the above
	</ol>
</li><br/>
<li> The i-node counts created by a file consistency check should
	<ol class="answer_list">
	<li> equal the i-node reference counts.
	<li> sum to the total number of disk blocks.
	<li> equal the count of the number of free blocks.
	<li> <strong>never</strong> be greater than 1.
	<li> None of the above
	</ol>
</li><br/>
<li> After a block consistency check has created its counts corresponding to
	the number of times the block is used or appears in the free list
	respectively, a problem exists if
	<ol class="answer_list">
	<li> both counts are 0.
	<li> if the sum of the two counts = 1.
	<li> both counts are >= 1.
	<li> either count is > 1.
	<li> None of the above
	</ol>
</li><br/>
<li> To improve the performance of a file system, particularly those stored on
	HDDs,
	<ol class="answer_list">
	<li> the disk block size should be kept small (e.g., 1 KB) to reduce
		internal fragmentation.
	<li> a block cache should keep a number of disk blocks in memory to
		reduce read times.
	<li> changes to a file's disk block that's been loaded into memory,
		should <strong>not</strong> be written back to disk after
		every change.
	<li> Perform a regular incremental backup. 
	<li> None of the above
	</ol>
</li><br/>
<li> Pre-fetching the next few disk blocks for a file, can improve the
	performance for which type of file access (particularly on HDDs)?
	<ol class="answer_list">
	<li> Random access.
	<li> Spiral access.
	<li> Sequential access.
	<li> Tree access.
	<li> None of the above
	</ol>
</li><br/>
<li> Part of the advantage of caching disk blocks in memory is to reduce
	the total number of writes to disk (i.e., make several changes to the
	cache before writing the cached block back to disk), what if any
	advantage is there to having a cache that writes through
	to the disk every time the cache is changed?
	<ol class="answer_list">
	<li> In the event of a system failure, write-through-caches can reduce
		the amount of lost data.
	<li> All writes to disk <strong>must</strong> come from memory/cache
		anyway, so there is no difference in write performance.
	<li> The write-through-cache also provides the faster read access.
	<li> Using a write-through-cache lowers contention on the system bus
		since the disk block is written as soon as it's changed.
	<li> None of the above
	</ol>
</li><br/>
<li> When possible, in order to improve file read/write performance, the free
	blocks allocated to store the contents of a file should be
	<ol class="answer_list">
	<li> randomly distributed on the disk to avoid access contention.
	<li> in the same disk partition.
	<li> one after another (on HDDs) to reduce seek time.
	<li> of the same size.
	<li> None of the above
	</ol>
</li><br/>
<li> The Unix <em>sync</em> and Windows <em>FlushFileBuffers</em> processes
	<ol class="answer_list">
	<li> ensure that the contents of cached disk blocks are written to
		disk periodically when they've been modified. 
	<li> update the contents of any file disk blocks cached in memory
		that might have been altered on disk.
	<li> are unnecessary if write-through caches are
		<strong>always</strong> used.
	<li> only need to be used in combination with a virtual file system.
	<li> None of the above
	</ol>
</li><br/>
<li> Defragmenting a disk
	<ol class="answer_list">
	<li> compacts the file system, placing <strong>all</strong> of the
		free disk blocks at one end of the partition.
	<li> reduces the amount of internal fragmentation.
	<li> can place a file's disk blocks consecutively so as to increase
		read/write access speeds.
	<li> increases the number of free disk blocks available to the file
		system.
	<li> None of the above
	</ol>
</li><br/>
<li> Defragmenting a disk is <em>most</em> useful for which type of file system?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Linked List Allocation
	<li> Index Node
	<li> Virtual File System
	<li> None of the above
	</ol>
</li><br/>

<li> A kilobyte (KB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A gigabyte (GB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A megabyte (MB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A terabyte (TB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A petabyte (PB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> An exabyte (EB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> Which of the following are examples of a contiguous allocation file
	system?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660 with Joliet Extensions
	<li> ISO 9660 with Rock Ridge Extensions
	<li> ext2
	<li> ext4
	<li> Network File System (NFS)
	<li> Virtual File System (VFS)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are examples of a linked list allocation file 
	system?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660 with Joliet Extensions
	<li> ISO 9660 with Rock Ridge Extensions
	<li> ext2
	<li> ext4
	<li> Network File System (NFS)
	<li> Virtual File System (VFS)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are examples of an index-node allocation file 
	system?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660 with Joliet Extensions
	<li> ISO 9660 with Rock Ridge Extensions
	<li> ext2
	<li> ext4
	<li> Network File System (NFS)
	<li> Virtual File System (VFS)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following files systems provide journaling?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660
	<li> ext2
	<li> NTFS
	<li> ext4
	<li> ReFS
	<li> Btrfs
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following files systems support hard links?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660
	<li> ext2
	<li> NTFS
	<li> ext4
	<li> ReFS
	<li> Btrfs
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following files systems support soft links?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660
	<li> ext2
	<li> NTFS
	<li> ext4
	<li> ReFS
	<li> Btrfs
	<li> None of the above
	</ol>
</li><br/>

<li> The primary kinds of devices are
	<ol class="answer_list">
	<li> character devices.
	<li> linear devices.
	<li> parallel devices.
	<li> block devices.
	<li> None of the above
	</ol>
</li><br/>
<li> What kind of device works with information in fixed size blocks and often
	provides random access?
	<ol class="answer_list">
	<li> character devices.
	<li> linear devices.
	<li> parallel devices.
	<li> block devices.
	<li> None of the above
	</ol>
</li><br/>
<li> What kind of device works with information as a sequence of bytes and
	only provides sequentially access?
	<ol class="answer_list">
	<li> character devices.
	<li> linear devices.
	<li> parallel devices.
	<li> block devices.
	<li> None of the above
	</ol>
</li><br/>
<li> What software interacts with the device controller to enable the OS to
	utilize a device?
	<ol class="answer_list">
	<li> I/O interface
	<li> Device driver
	<li> Interrupt driver
	<li> Control bus
	<li> None of the above
	</ol>
</li><br/>
<li> The primary nature of an I/O device is
	<ol class="answer_list">
	<li> mechanical and based on material properties. 
	<li> electronic (circuits).
	<li> software.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary nature of an device controller is
	<ol class="answer_list">
	<li> mechanical and based on material properties. 
	<li> electronic (circuits).
	<li> software.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary nature of an device driver is
	<ol class="answer_list">
	<li> mechanical and based on material properties. 
	<li> electronic (circuits).
	<li> software.
	<li> None of the above
	</ol>
</li><br/>
<li> Each device controller
	<ol class="answer_list">
	<li> controls only a single device.
	<li> may control many devices.
	<li> communicates with its corresponding device driver.
	<li> <strong>must</strong> have its own dedicated bus to both the CPU
		and the Direct Memory Access (DMA) controller.
	<li> None of the above
	</ol>
</li><br/>
<li> Devices controllers have
	<ol class="answer_list">
	<li> support for <strong>all</strong> types of devices, so that any
		device can utilize any type of device controller.
	<li> data buffers that can be written to or read from.
	<li> control registers to communicate with the CPU.
	<li> their own instruction sets that <strong>must</strong> be
		supported by the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> Port I/O, used by early computers,
	<ol class="answer_list">
	<li> assigns each control register to its corresponding I/O port.
	<li> is very slow since large data transfers <strong>must</strong>
		be done by reading/writing data in many small chunks (using
		the control registers).
	<li> the I/O ports are separate from memory (requiring protected
		instructions to read/write the I/O ports).
	<li> requires some portion of the device drivers to be written in
		assembly.
	<li> cannot use device drivers as the OS kernel <strong>must</strong>
		directly control the device.
	<li> None of the above
	</ol>
</li><br/>
<li> The advantages of Memory-Mapped I/O are
	<ol class="answer_list">
	<li> reduces the number of CPU executed instructions to put information
		into control registers.
	<li> ease of protecting the control registers by <strong>not</strong>
		putting the mapped memory in a user accessible address space.
	<li> data can be read/written directly to the device since the device
		buffer is mapped to memory.
	<li> device drivers can be written in a higher-level language (e.g.,
		C) enabling them to be more portable.
	<li> it makes effective use of both cached memory and the memory bus
		between main memory and the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> The drawbacks of Port I/O include:
	<ol class="answer_list">
	<li> very slow transfers of large data amounts since they
		<strong>must</strong> read/write data in many small chunks
		(using the control registers).
	<li> the device controller data buffers cannot be utilized.
	<li> increases the number of CPU executed instructions to communicate
		with the device controller.
	<li> access to the control registers <strong>must</strong> be
		restricted/protected.
	<li> None of the above
	</ol>
</li><br/>
<li> The drawbacks of Memory-Mapped I/O include:
	<ol class="answer_list">
	<li> caching <strong>must</strong> be disabled for memory mapped
		control registers.
	<li> the device controller data buffers cannot be utilized.
	<li> increases the number of CPU executed instructions to communicate
		with the device controller.
	<li> the MMU <strong>must</strong> determine which bus to use
		(based on the address) if there's a dedicated bus between
		the CPU and main memory in addition to the system bus. 
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following uses the CPU to copy data into (or out of) memory
	from a device (e.g., HDD) using a tight read/write loop?
	<ol class="answer_list">
	<li> Programmed I/O
	<li> Memory-Mapped I/O
	<li> Device to Device copy (D2D)
	<li> Direct Memory Access (DMA)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following has the CPU setup and initiate the copying of
	data into (or out of) memory, but the CPU is free to do other actions
	while the copying occurs?
	<ol class="answer_list">
	<li> Programmed I/O
	<li> Memory-Mapped I/O
	<li> Device to Device copy (D2D)
	<li> Direct Memory Access (DMA)
	<li> None of the above
	</ol>
</li><br/>
<li> If a system has a Direct Memory Access (DMA) capability, the process of
	writing a particular set of data directly to memory (or a device),
	instead of going through the DMA, is called
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> When the Direct Memory Access (DMA) transfers a chunk of data a single
	word at a time, by grabbing the system bus for short periods of time,
	this is called
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> When the Direct Memory Access (DMA) transfers a chunk of data
	<strong>all</strong> at once, this is called
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following makes efficient use of the system bus when large
	amounts of data <strong>must</strong> be transferred by the
	Direct Memory Access (DMA) unit?
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following makes efficient use of both the CPU and system bus
        when a single word of data <strong>must</strong> be
        transferred by the Direct Memory Access (DMA) unit?
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> Device controllers generate interrupts by
	<ol class="answer_list">
	<li> writing specific values to the control registers.
	<li> having the CPU periodically check/ping each controller.
	<li> using the Direct Memory Access (DMA) unit to write a special
		value into a variable the OS kernel monitors.
	<li> putting a specific signal on the system bus.
	<li> None of the above
	</ol>
</li><br/>
<li> An interrupt is serviced only if
	<ol class="answer_list">
	<li> no other interrupts are currently being handled.
	<li> there's no process currently running in the CPU.
	<li> no higher-priority interrupts are simultaneously received.
	<li> the system bus is currently operating in direct mode.
	<li> None of the above
	</ol>
</li><br/>
<li> The value that the interrupt controller puts on the system bus address
	lines represents
	<ol class="answer_list">
	<li> an index into the interrupt vector.
	<li> the priority of the interrupt.
	<li> the time-stamp of when the interrupt occurred.
	<li> the beginning address of the interrupt handler.
	<li> None of the above
	</ol>
</li><br/>
<li> The interrupt vector is an array that holds
	<ol class="answer_list">
	<li> the priorities of the different kinds of interrupts (the
		interrupt number used as the array index).
	<li> a list of the currently pending interrupts as a queue.
	<li> references to the set of control registers associated with
		the device that generates that interrupt (the interrupt
		number is used as the array index). 
	<li> the beginning address of the interrupt handler for
		<strong>all</strong> possible interrupts (the interrupt number
		is used as the array index).
	<li> None of the above
	</ol>
</li><br/>
<li> When the interrupt controller handles an interrupt it 
	<ol class="answer_list">
	<li> interrupts the CPU.
	<li> prompts the CPU to save the state of the current process
		<em>before</em> running the interrupt handler.
	<li> restores the state of the previous process to the CPU
		<em>after</em> the interrupt handler finishes.
	<li> runs the next process from the ready "queue"
		<em>after</em> the interrupt handler finishes.
	<li> None of the above
	</ol>
</li><br/>
<li> Interrupts for which the instructions <em>before</em> the program counter
	(PC) have <strong>all</strong> been completed and those
	appearing <em>after</em> the PC have NOT been completed, are called
	<ol class="answer_list">
	<li> precision interrupts.
	<li> precise interrupts.
	<li> imprecise interrupts.
	<li> ambiguous interrupts.
	<li> None of the above
	</ol>
</li><br/>
<li> Interrupts for which some instructions <em>before</em> the PC may NOT
	have completed, while some instructions <em>after</em> the PC may
	been have completed, are called
	<ol class="answer_list">
	<li> precision interrupts.
	<li> precise interrupts.
	<li> imprecise interrupts.
	<li> ambiguous interrupts.
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following are <strong>not</strong> goals of I/O software?
	<ol class="answer_list">
	<li> Handling errors at the lowest level possible.
	<li> Making programs independent of the actual device(s) used.
	<li> Supporting device names that are independent of the actual
		device(s) used.
	<li> When practical, using buffering for block device communications.
	<li> None of the above
	</ol>
</li><br/>
<li> Asynchronous I/O 
	<ol class="answer_list">
	<li> can be made to look synchronous by the OS.
	<li> is often easier to program with.
	<li> is generally enabled by Direct Memory Access (DMA).
	<li> typically enables other actions to be performed while the I/O
		is occurring.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O uses the CPU to directly perform the reading/writing of
	data to/from devices?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O is the simplest in design, but prevents the CPU from
	doing other work while I/O is occurring?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O may require the copying of data from a user's address
	space to the kernel address space?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O often reads/writes data from/to a device a single
	byte at a time using a tight loop run by the CPU?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O software uses polling to determine whether or not
	a device is ready for the piece of data to be read/written?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O blocks the reading/writing process so that no time is
	spent busy waiting?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O makes the most efficient use of the CPU resource when
	large chunks of data <strong>must</strong> be read/written?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following are part of the 4 layers of I/O software?
	<ol class="answer_list">
	<li> Device controller firmware
	<li> Interrupt handlers
	<li> Device drivers
	<li> User level I/O software
	<li> None of the above
	</ol>
</li><br/>
<li> An easy and efficient way to deal with I/O interrupts from devices is to
	<ol class="answer_list">
	<li> <strong>always</strong> use Direct Memory Access (DMA) for I/O
		so that interrupts aren't generated.
	<li> have the device driver block when I/O is initiated, so the
		interrupt handler simply unblocks the driver when the interrupt
		is received.
	<li> let the device driver run as part of the OS so that a full
		context switch isn't necessary when an interrupt unblocks a
		device driver.
	<li> combine the interrupt handler and device driver into a single
		user level system call so that <strong>all</strong> parts of
		the I/O software stack are run as a single unit.
	<li> None of the above
	</ol>
</li><br/>
<li> Device driver code, particularly in the consumer market, is most commonly
	<ol class="answer_list">
	<li> installed on the device controller.
	<li> compiled into the OS.
	<li> dynamically loaded into the OS.
	<li> no longer needed as all device manufacturers are moving to a
		single standard API.
	<li> None of the above
	</ol>
</li><br/>
<li> The device dependent code for performing I/O resides in which I/O software
	layer(s)?
	<ol class="answer_list">
	<li> Device controller firmware
	<li> Interrupt handlers
	<li> Device drivers
	<li> User level I/O software
	<li> None of the above
	</ol>
</li><br/>
<li> Devices drivers are
	<ol class="answer_list">
	<li> normally provided by the device manufacturer, but usually only
		for the most popular OSs.
	<li> <strong>always</strong> written to block during an I/O operation.
	<li> often run as part of the OS kernel, to avoid the overhead of a
		full context switch.
	<li> coded using static variables to reduce the size of the run-time
		stack, since the device driver only services one request at
		a time.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following help make I/O software independent of the specific
	device being used?
	<ol class="answer_list">
	<li> Using file names as the names for devices.
	<li> Controlling access to devices through file ownership and access
		permissions.
	<li> Adherence to a common and uniform Application Programming
		Interface (API).
	<li> Enable user programs, via system calls, to access specialized
		features of devices via manufacturer specific control codes.
	<li> None of the above
	</ol>
</li><br/>
<li> Device independent capabilities generally include mechanisms to control:
	<ol class="answer_list">
	<li> interrupt delay and timeouts.
	<li> buffering.
	<li> error reporting.
	<li> device acquisition and release.
	<li> the device data block size.
	<li> None of the above
	</ol>
</li><br/>
<li> Spooling (simultaneous peripheral operations on-line) is a technique that
	<ol class="answer_list">
	<li> uses buffering to prevent slow devices (e.g., printers) from
		making the CPU busy wait.
	<li> allows non-shareable devices to be used serial, but appear to
		user software as if they are being shared.
	<li> is only used in conjunction with printing devices.
	<li> uses a single program to operate a non-shareable device.
	<li> None of the above
	</ol>
</li><br/>
<li> System calls (e.g., read, write) and library routines (e.g., fprintf)
	are provided by which I/O software layer.
	<ol class="answer_list">
	<li> Device controller firmware
	<li> Interrupt handlers
	<li> Device drivers
	<li> User level I/O software
	<li> None of the above
	</ol>
</li><br/>

<li> On a keyboard, an interrupt is generated
	<ol class="answer_list">
	<li> only when a key is pressed.
	<li> only when a key is released.
	<li> every N milliseconds (as configured by the device driver) for as
		long as the key is held down.
	<li> once when the key is pressed, and once when it is released.
	<li> None of the above
	</ol>
</li><br/>
<li> A device driver for supporting keyboards that passes along every typed
	character (including backspacing) supports input in
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> None of the above
	</ol>
</li><br/>
<li> Which device driver mode for supporting keyboards works
	<strong>best</strong> for full screen editors (e.g., vi, emacs)?
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> None of the above
	</ol>
</li><br/>
<li> Which device driver mode for supporting keyboards works
	<strong>best</strong> for command line programs (e.g., shell)?
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> None of the above
	</ol>
</li><br/>
<li> The device driver approach for supporting keyboards that is character
	oriented is also called
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> raw mode.
	<li> cooked mode.
	<li> None of the above
	</ol>
</li><br/>
<li> The device driver approach for supporting keyboards that is line
	oriented is also called
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> raw mode.
	<li> cooked mode.
	<li> None of the above
	</ol>
</li><br/>
<li> For a mouse, an interrupt is generated
	<ol class="answer_list">
	<li> each time a button is pressed.
	<li> each time a button is released.
	<li> every 40 milliseconds (as configured by the device driver)
		regardless of what the user does with the mouse.
	<li> whenever the mouse has traveled a predetermined minimum distance.
	<li> None of the above
	</ol>
</li><br/>
<li> Mouse input, unlike keyboard input, 
	<ol class="answer_list">
	<li> only supports raw mode.
	<li> only supports cooked mode.
	<li> supports both raw and cooked modes.
	<li> doesn't support either raw or cooked modes, but uses echoing
		instead. 
	<li> None of the above
	</ol>
</li><br/>
<li> While touch screens operate much the same way that mice do, a notable
	difference is that
	<ol class="answer_list">
	<li> mice have button(s) that can be pressed and released, whereas
		touch screens do <strong>not</strong> have a comparable
		capability.
	<li> mice suffer fromm the ghosting problem, whereas touch screens
		do <strong>not</strong>.
	<li> touch screens supply the absolute position of a touch instead of
		the relative position which mice provide.
	<li> touch screens can support multitouch whereas mice do
		<strong>not</strong> have a comparable capability.
	<li> None of the above
	</ol>
</li><br/>
<li> In order to support multitouch, touch screens should provide a continuous
	stream of position data 
	<ol class="answer_list">
	<li> in order to create the relative position data that it needs. 
	<li> to avoid the ghosting problem (i.e., the touch position is
		ambiguous).
	<li> otherwise data reported at discrete time increments will be
		understood as multiple separate touches (e.g., mouse clicks).
	<li> to prevent echoing, in which a single touch point may look like
		multiple touches.
	<li> None of the above
	</ol>
</li><br/>
<li> Text (or terminal) windows use
	<ol class="answer_list">
	<li> special character sequences to position the cursor and perform
		text insertion and deletion.
	<li> mixed sized text and different font styles to support document
		processing (e.g., Microsoft Word).
	<li> terminal capability (termcap) libraries to provide device
		independent support.
	<li> the raw scan codes from the keyboard, which is why they were
		commonly used on early computers.
	<li> None of the above
	</ol>
</li><br/>
<li> X11 is a windowing system
	<ol class="answer_list">
	<li> commonly used by Linux based systems.
	<li> allows programs to be run on one computer, with the display and
		interaction occurring on another computer.
	<li> uses a client-server model to separate the program's GUI operation
		from the rest of the program.
	<li> that is event driven. 
	<li> None of the above
	</ol>
</li><br/>
<li> Microsoft Windows and X11 differ in that
	<ol class="answer_list">
	<li> X11 is implemented as part of the OS kernel.
	<li> X11 user programs <strong>must</strong> explicitly coordinate the
		communication between the client and server components.
	<li> Microsoft Windows is portable and relatively easy to maintain.
	<li> Microsoft Windows combines the windowing and GUI elements together
		within the OS.
	<li> None of the above
	</ol>
</li><br/>
<li> Graphical User Interfaces (GUIs) are characterized by their use of
	<ol class="answer_list">
	<li> Windows
	<li> Icons
	<li> Menus
	<li> Pointing devices
	<li> None of the above
	</ol>
</li><br/>
<li> Unlike text windows, graphical user interfaces (GUIs)
	<ol class="answer_list">
	<li> are slower since they <strong>must</strong> use Programmed I/O.
	<li> require a graphics processing unit (GPU) be part of the hardware.
	<li> leverage a common graphical API (e.g., OpenGL) to make the
		software more portable.
	<li> <strong>must</strong> use the integerated graphics provided by
		the computer hardware (on the motherboard).
	<li> None of the above
	</ol>
</li><br/>

<li> Computer clocks and timers controlled by the OS are used to
	<ol class="answer_list">
	<li> support preemptive process/thread scheduling.
	<li> control the speed at which the CPU performs instructions.
	<li> time order independent (serializable) events.
	<li> prevent any simultaneous actions occurring within the computer.
	<li> None of the above
	</ol>
</li><br/>
<li> The computer clock hardware uses a crystal (tuned to a specific frequency) 
	to
	<ol class="answer_list">
	<li> cause a special register to count down to 0, which then
		generates an interrupt.
	<li> cause a special register to count the number of ticks since the
		epoch.
	<li> directly generate timing interrupts for the computer.
	<li> None of the above
	</ol>
</li><br/>
<li> Programmable clocks
	<ol class="answer_list">
	<li> can be used as a complete replacement for clock hardware.
	<li> are able to generate periodic clock interrupts.
	<li> read the special clock register value, and perform specific
		actions when particular values are reached.
	<li> alter the starting value of the special clock register to
		control the interval between clock generated interrupts.
	<li> None of the above
	</ol>
</li><br/>
<li> The calendar date and "wall" clock time are calculated
	<ol class="answer_list">
	<li> based on the number of clock ticks (usually in microseconds)
		since a specific starting date and time.
	<li> by keeping track of the years, days (0-365), hours (0-24),
		minutes (0-60), and seconds (0-60)
		that have elapsed based on regular clock interrupts. 
	<li> on a daily (24 hour clock) basis at midnight, with the time each
		day kept as a count of the microseconds since the last day.
	<li> by contacting an internet based time keeping service whenever
		the current date and time is needed.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> a usual responsibility
	of a clock (device) driver?
	<ol class="answer_list">
	<li> preventing processes from running too long.
	<li> collecting profiling and statistics information on processes.
	<li> maintaining the time of day.
	<li> providing watchdog timers.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are functionality often supported by
	the clock (device) driver?
	<ol class="answer_list">
	<li> Polling of some input devices (e.g., mice, touch screens).
	<li> CPU accounting.
	<li> Software profiling.
	<li> Watchdog timers.
	<li> None of the above
	</ol>
</li><br/>
<li> To keep track of the time of day, the OS typically
	<ol class="answer_list">
	<li> keeps track of the year, the day within the year, and
		the number of milliseconds within the current day.
	<li> keeps track of the year and counts the number of microseconds
		 within the current year.
	<li> keeps track of the year and counts the number of clock ticks
		 within the current year.
	<li> counts the number of clock ticks since the epoch.
	<li> None of the above
	</ol>
</li><br/>
<li> Watchdog timers often use a direct procedure call rather than causing a
	signal because
	<ol class="answer_list">
	<li> they are just another type of clock, and usually call an alarm
		procedure that in turn generates the signal.
	<li> as a special type of alarm, they are only used within the same
		process.
	<li> for user processes, it reduces the lag between the timer firing
		and the associated work being performed.
	<li> it's faster and the call is for kernel processes so the watchdog
		doesn't need to do a context switch.
	<li> None of the above
	</ol>
</li><br/>
<li> Alarms are set using a system call and are usually implemented as a
	<ol class="answer_list">
	<li> sorted queue of times when an interrupt should be generated.
	<li> special register that holds the next alarm time. However, only
		one alarm can be set/active at a time.
	<li> separate process that the clock (device) driver signals on a
		periodic basis.
	<li> set of count down registers, with a separate register
		corresponding to each alarm.
	<li> None of the above
	</ol>
</li><br/>
<li> Alarms can be implemented using either absolute or relative times.
	<ol class="answer_list">
	<li> Absolute times are more accurate since using relative times allows
		small inaccuracies in alarm activations to grow over time.
	<li> Relative times are preferred since even the 64 bit registers of
		modern computers are <strong>not always</strong> large enough
		to hold the appropriate absolute time relative to the epoch.
	<li> Relative times provide greater precision and accuracy than
		absolute times.
	<li> The are no advantages of using either absolute or relative times
		over the other for implementing alarms.
	<li> None of the above
	</ol>
</li><br/>
<li> A simple but less accurate way to implement CPU accounting for processes
	is to have a single counter associated with each process in the
	proc_table, incrementing the counter for the currently running process
	whenever
	<ol class="answer_list">
	<li> an interrupt handler is started. The counter value divided by the
		sum of <strong>all</strong> such values, is the proportion of
		the CPU the process has used.
	<li> the process uses its full time quantum. Charging the process 1.5
		times the counter value.
	<li> the process becomes blocked. Charging the process 0.5 times the
		counter value.
	<li> a clock tick occurs.  Charging the currently running process for
		the full clock tick.
	<li> None of the above
	</ol>
</li><br/>
<li> If a timer with an additional, but different, frequency than the main
	system timer is needed, and accuracy to within 20 microseconds is
	sufficient, which of the following is an efficient solution?
	<ol class="answer_list">
	<li> Use an ALARM system call that resets every time it is triggered. 
	<li> Have a separate process poll the system clock, triggering an
		event when the desired (recurring) time interval is reached.
	<li> Use a "soft timer" based on the frequent running of the OS
		kernel to check for the desired time interval.
	<li> Adjust the starting value of the programmable clock to correspond
		to the alternate frequency.
	<li> None of the above
	</ol>
</li><br/>


<li> In the context of a computer system, the following are considered
	resources:
	<ol class="answer_list">
	<li> I/O devices
	<li> CPU
	<li> Memory
	<li> Software
	<li> None of the above
	</ol>
</li><br/>
<li> A preemptable resource is one that when temporarily taken away from a
	process
	<ol class="answer_list">
	<li> will <strong>not</strong> cause a problem for the preempted
		process.
	<li> may sometimes cause a problem for the preempted process,
		including possible process failure.
	<li> <strong>always</strong> results in failure of the preempted
		process.
	<li> None of the above
	</ol>
</li><br/>
<li> A non-preemptable resource is one that when taken away (even if only
	temporarily) from a process
	<ol class="answer_list">
	<li> will <strong>not</strong> cause a problem for the preempted
		process.
	<li> may sometimes cause a problem for the preempted process,
		including possible process failure.
	<li> <strong>always</strong> results in failure of the preempted
		process.
	<li> None of the above
	</ol>
</li><br/>
<li> The typical interaction pattern between a process and a resource is
	<ol class="answer_list">
	<li> detected, requested, used, released.
	<li> requested, used, released.
	<li> requested, granted, used, released.
	<li> granted, used, released.
	<li> None of the above
	</ol>
</li><br/>
<li> Software (e.g., blocks of code) can be viewed as a non-premeptable resource
	<ol class="answer_list">
	<li> because they in turn use resources (e.g., CPU, memory).
	<li> when mutex semaphores are used to controlled access.
	<li> since it can access the system bus.
	<li> if it is part of a user process that the OS schedules to run
		in the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following conditions <strong>must</strong> hold in order for
	deadlock to exist?
	<ol class="answer_list">
	<li> Only one instance of each type of resource exists.
	<li> Mutually exclusive use of resources.
	<li> Resources are controlled and allocated only by the OS.
	<li> Processes can hold resources while requesting additional resources.
	<li> Process scheduling <strong>must</strong> be non-preemptive.
	<li> Granted resources cannot be preempted.
	<li> All resources within the system have been allocated.
	<li> Circular wait condition.
	<li> All processes within the system are in the blocked state.
	<li> None of the above
	</ol>
</li><br/>
<li> A set of processes is deadlocked when
	<ol class="answer_list">
	<li> <strong>all</strong> of the processes in the set are in the
		blocked state.
	<li> every resource in the system has been granted to a process in
		the set.
	<li> each process in the set is waiting for an event that only another
		process in the set can cause.
	<li> no process in the set has been granted a preemptable resource. 
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> a strategy for dealing
	with deadlocks?
	<ol class="answer_list">
	<li> Prevention
	<li> Dynamic avoidance
	<li> Detection and recovery
	<li> Ignore the problem
	<li> None of the above
	</ol>
</li><br/>
<li> Deadlock modeling represents resources (squares) and processes (circles)
	as a graph with
	<ol class="answer_list">
	<li> arrows pointing from a process to a resource represent an
		(ungranted) resource request.
	<li> arrows pointing from a resource to a process represent a
		granted resource.
	<li> arrows pointing in both directions between a process and a
		resource represent a granted dedicated non-preemptable
		resource.
	<li> undirected lines (no arrows) between a process and a resource
		represent a granted preemptable resource.
	<li> None of the above
	</ol>
</li><br/>
<li> In a deadlock model graph, a deadlock exists when
	<ol class="answer_list">
	<li> at least one process has more than two (2) arrows pointing to it.
	<li> at least one resource has more than two (2) arrows pointing to it.
	<li> there is a directed cycle in the graph.
	<li> the graph forms a tree.
	<li> None of the above
	</ol>
</li><br/>
<li> The following resource graph indicates that:<br/>
	<img src="/eckart/classes/cpsc3125/questions/ResourceGraph_1.png" width="406" height="384" alt="Resource Graph" />
	<ol class="answer_list">
	<li> No deadlock exists.
	<li> No deadlock exists, but there is a livelock on "T".
	<li> A deadlock exists involving the processes and resources
		denoted by: B, T, C, S.
	<li> A deadlock exists involving the processes and resources
		denoted by: D, R, B, T.
	<li> None of the above
	</ol>
</li><br/>
<li> The following resource graph indicates that:<br/>
	<img src="/eckart/classes/cpsc3125/questions/ResourceGraph_2.png" width="383" height="365" alt="Resource Graph" />
	<ol class="answer_list">
	<li> No deadlock exists.
	<li> No deadlock exists, but there is a livelock on "T".
	<li> A deadlock exists involving the processes and resources
		denoted by: A, T, D, U.
	<li> A deadlock exists involving the processes and resources
		denoted by: A, R, B, S, C, T.
	<li> None of the above
	</ol>
</li><br/>

<li> Which strategy for dealing with deadlock is used by most systems (e.g.,
	Linux, Mac OS X, Windows)?
	<ol class="answer_list">
	<li> Prevention
	<li> Dynamic avoidance
	<li> Detection and recovery
	<li> Ignore the problem
	<li> None of the above
	</ol>
</li><br/>
<li> Determining whether or not a deadlock <em>actually</em> exists in the
	system requires
	<ol class="answer_list">
	<li> building the deadlock model graph and checking for cycles.
	<li> checking whether or not <strong>all</strong> processes are in
		the blocked state.
	<li> periodically checking how long blocked processes have been blocked.
	<li> periodically checking whether there are any processes in the ready
		state.
	<li> None of the above
	</ol>
</li><br/>
<li> Deadlock detection is
	<ol class="answer_list">
	<li> fast and easy to run, so it should be done every time a resource is
		allocated.
	<li> fast and easy to run, so it should be done every time a new process
		is created.
	<li> rather slow and costly to run, so it should be run only when a
		process has been blocked for a long time (assuming there's no
		urgent need to detect a possible deadlock).
	<li> rather slow and costly to run, so it should be run only when
		there is no user process in the ready state. That is, it
		should be run as the idle process.
	<li> None of the above
	</ol>
</li><br/>
<li> If a deadlock has been detected, recovery can be accomplished by
	<ol class="answer_list">
	<li> waiting until a process in the deadlock releases
		<strong>all</strong> its resources.
	<li> rolling back a process in the deadlock to a checkpoint before it
		requested a resource participating in the deadlock.
	<li> terminating a process in the deadlock (thus releasing
		<strong>all</strong> of its granted resources).
	<li> change <strong>all</strong> of the processes in the deadlock
		to the ready state.
	<li> None of the above
	</ol>
</li><br/>
<li> When recovering from a deadlock by terminating a process that was
	participating in a deadlock
	<ol class="answer_list">
	<li> give preference to processes with the least amount of
		accumulated CPU time is often <strong>best</strong>.
	<li> change <strong>all</strong> remaining blocked processes to the
		ready state after terminating the offending process.
	<li> recheck to determine if any additional deadlocks still exist.
	<li> do <strong>not</strong> allow any other processes in the deadlock
		to acquire the resources released by the terminating process.
	<li> None of the above
	</ol>
</li><br/>

<li> Dynamic deadlock avoidance assumes that
	<ol class="answer_list">
	<li> it is possible to preempt an otherwise non-preemptable resource
		if deadlock would otherwise occur.
	<li> the resource needs of a process can be changed by the OS.
	<li> processes can be terminated if their resource request would 
		cause a deadlock.
	<li> there exists a resource allocation that would allow
		<strong>all</strong> current processes to complete.
	<li> None of the above
	</ol>
</li><br/>
<li> An <em>UNsafe state</em> with respect to dynamic avoidance of deadlock is
	one in which
	<ol class="answer_list">
	<li> there exists one or more resource allocation scenarios that
		allow some (but not all) processes to complete.
	<li> there exists at least one resource allocation scenario that
		would prevent <strong>all</strong> processes from completing.
	<li> no resource allocation scenario guarantees <strong>all</strong>
		processes will complete.
	<li> None of the above
	</ol>
</li><br/>
<li> A <em>safe state</em> with respect to dynamic avoidance of deadlock is
	one in which
	<ol class="answer_list">
	<li> <strong>all</strong> resource allocation scenarios allow
		<strong>all</strong> processes to complete.
	<li> there exists one or more resource allocation scenarios that
		allow some (but not all) processes to complete.
	<li> there exists at least one resource allocation scenario that
		would allow <strong>all</strong> processes to complete.
	<li> None of the above
	</ol>
</li><br/>
<li> If a set of processes and resources is in an <em>UNsafe state</em> with
	respect to deadlock, then deadlock
	<ol class="answer_list">
	<li> is guaranteed to occur eventually.
	<li> will occur if <strong>all</strong> processes use their maximum
		required resources.
	<li> may still be avoided if some processes use less than their
		maximum required resources.
	<li> can <strong>always</strong> be avoided by withholding additional
		resources from one or more processes.
	<li> None of the above
	</ol>
</li><br/>
<li> The Banker's algorithm for dynamic deadlock avoidance requires that
	<ol class="answer_list">
	<li> there <strong>always</strong> be sufficient
		resources available to meet <strong>all</strong> processes'
		maximum requests simultaneously.
	<li> there <strong>always</strong> be sufficient
		resources available to meet at least one process' maximum
		request.
	<li> the minimum resource needs of <strong>all</strong>
		processes be known beforehand.
	<li> the maximum resource needs of <strong>all</strong>
		processes be known beforehand.
	<li> None of the above
	</ol>
</li><br/>
<li> The Banker's algorithm for dynamic deadlock avoidance is most applicable
	to batch processing because
	<ol class="answer_list">
	<li> preemptive scheduling is <strong>not</strong> generally used.
	<li> virtual memory is <strong>never</strong> used.
	<li> the running time for each process is known from previous
		executions.
	<li> the processes and their maximum resource needs are typically
		known beforehand.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to the Banker's algorithm, assuming the bank started with
	100 units of resource, what is true about the system given the
	following situation?
	<blockquote>
	<table style="text-align: center">
	<tr><th></th><th colspan="2">Allocation</th></tr>
	<tr><th>Process</th><th>Maximum<br/>Possible</th><th>Current</th></tr>
	<tr><td>A</td><td>10</td><td>5</td></tr>
	<tr><td>B</td><td>20</td><td>10</td></tr>
	<tr><td>C</td><td>30</td><td>15</td></tr>
	<tr><td>D</td><td>40</td><td>20</td></tr>
	</table>
	</blockquote>
	<ol class="answer_list">
	<li> The system cannot become deadlocked.
	<li> The system is in a safe state.
	<li> The system is in an UNsafe state.
	<li> The system is deadlocked if <strong>all</strong>
		processes need even one additional resource.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to the Banker's algorithm, assuming the bank started with
	60 units of resource, what is true about the system given the
	following situation?
	<blockquote>
	<table style="text-align: center">
	<tr><th></th><th colspan="2">Allocation</th></tr>
	<tr><th>Process</th><th>Maximum<br/>Possible</th><th>Current</th></tr>
	<tr><td>A</td><td>10</td><td>5</td></tr>
	<tr><td>B</td><td>20</td><td>10</td></tr>
	<tr><td>C</td><td>30</td><td>15</td></tr>
	<tr><td>D</td><td>40</td><td>20</td></tr>
	</table>
	</blockquote>
	<ol class="answer_list">
	<li> The system cannot become deadlocked.
	<li> The system is in a safe state.
	<li> The system is in an UNsafe state.
	<li> The system is deadlocked if <strong>all</strong>
		processes need even one additional resource.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to the Banker's algorithm, assuming the bank started with
	50 units of resource, what is true about the system given the
	following situation?
	<blockquote>
	<table style="text-align: center">
	<tr><th></th><th colspan="2">Allocation</th></tr>
	<tr><th>Process</th><th>Maximum<br/>Possible</th><th>Current</th></tr>
	<tr><td>A</td><td>10</td><td>5</td></tr>
	<tr><td>B</td><td>20</td><td>10</td></tr>
	<tr><td>C</td><td>30</td><td>15</td></tr>
	<tr><td>D</td><td>40</td><td>20</td></tr>
	</table>
	</blockquote>
	<ol class="answer_list">
	<li> The system cannot become deadlocked.
	<li> The system is in a safe state.
	<li> The system is in an UNsafe state.
	<li> The system is deadlocked if <strong>all</strong>
		processes need even one additional resource.
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following prevents deadlock by negating the exclusive use
	of resources?
	<ol class="answer_list">
	<li> The use of two-phase locking.
	<li> Use spooling and a spool daemon, with the spool daemon using only
		a single resource.
	<li> Allow a process to hold only one resource at a time.
	<li> Requiring that new resource requests by a process occur in
		increasing resource priority order.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following prevents deadlock by negating the holding of
	resource while making additional requests?
	<ol class="answer_list">
	<li> Requiring that new resource requests by a process occur in
		increasing resource priority order.
	<li> Allow a process to hold only one resource at a time.
	<li> Use spooling and a spool daemon, with the spool daemon using only
		a single resource.
	<li> The use of two-phase locking.
	<li> None of the above
	</ol>
</li><br/>
<li> Preventing deadlock by negating the non-preemptability of resources
	works for resources
	<ol class="answer_list">
	<li> that can be spooled, thus ensuring that the resource
		<strong>never</strong> needs to be preempted.
	<li> which are only assigned using two-phase locking.
	<li> like the CPU, but <strong>not</strong> for <strong>all</strong>
		types of resources.
	<li> assigned in strictly decreasing order resource priority order.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following prevents deadlock by negating the circular
	wait condition?
	<ol class="answer_list">
	<li> Use spooling and a spool daemon, with the spool daemon using only
		a single resource.
	<li> Allow a process to hold only one resource at a time.
	<li> Requiring that new resource requests by a process occur in
		increasing resource priority order.
	<li> The use of two-phase locking.
	<li> None of the above
	</ol>
</li><br/>

<li> Starvation occurs when a process is <strong>not</strong> deadlocked,
	<ol class="answer_list">
	<li> but is consistently unable to obtain a needed resource, often
		because the resource keeps being assigned to other processes.
	<li> and is assigned the needed resource, but the resource is
		continually preempted.
	<li> but continually acquires and returns the same resource over and
		over.
	<li> but waits for a signal from another process which
		<strong>never</strong> comes.
	<li> None of the above
	</ol>
</li><br/>
<li> Livelock occurs when a set of two or more processes
	<ol class="answer_list">
	<li> experience a combination of both deadlock and starvation.
	<li> are unable to get <strong>all</strong> their needed resources,
		and continually give back those resources that were granted
		and retry getting <strong>all</strong> of them
		<strong>without</strong> success.
	<li> are waiting for signals from each other before continuing
		their remaining computations.
	<li> is only missing one of the 4 conditions necessary for deadlock.
	<li> None of the above
	</ol>
</li><br/>
<li> A communication deadlock can occur when
	<ol class="answer_list">
	<li> messages are lost in transit.
	<li> a process is starved for a communication channel. 
	<li> <strong>all</strong> the processes that are trying to
		communicate are in livelock.
	<li> two-phase locking is used to allocate communicate channels.
	<li> None of the above
	</ol>
</li><br/>
<li> Communication deadlocks can often (though <strong>not always</strong>)
	be avoid by using
	<ol class="answer_list">
	<li> multiple communication channels.
	<li> a single message packet that is passed between the processes.
	<li> two-phase locking.
	<li> message acknowledgements in combination with timeouts (when
		acknowledgements are <strong>not</strong> promptly received).
	<li> None of the above
	</ol>
</li><br/>
<li> Two-phase locking is characterized by
	<ol class="answer_list">
	<li> assigning resources priorities and requiring processes to request
		resources in increasing priority order.
	<li> requiring that <strong>all</strong> resources be preemptable.
	<li> repeatedly trying to get <strong>all</strong> needed resources,
		returning those granted if some requests went unsatisfied,
		until <strong>all</strong> the resources are finally acquired.
	<li> having processes make two requests (in quick succession)
		to acquire a resource.
	<li> None of the above
	</ol>
</li><br/>

<li> The OS mechanisms used to provide security are called
	<ol class="answer_list">
	<li> threats.
	<li> shields.
	<li> security perimeter.
	<li> protection mechanisms.
	<li> None of the above
	</ol>
</li><br/>
<li> Any set of actions taken to gain unauthorized access to a system is
	called a (an)
	<ol class="answer_list">
	<li> vulnerability.
	<li> exploit.
	<li> 0-day attack.
	<li> script.
	<li> None of the above
	</ol>
</li><br/>
<li> Someone who enjoys the creativity and challenge of solving problems is
	called a
	<ol class="answer_list">
	<li> maker.
	<li> hacker.
	<li> cracker.
	<li> white hat.
	<li> None of the above
	</ol>
</li><br/>
<li> Someone who attempts to gain unauthorized access to a system is called a
	<ol class="answer_list">
	<li> black hat.
	<li> cracker.
	<li> script kiddie.
	<li> hacker.
	<li> None of the above
	</ol>
</li><br/>
<li> A software bug that can be used to subvert the security of a system is
	called a
	<ol class="answer_list">
	<li> security hole.
	<li> vulnerability.
	<li> exploit.
	<li> threat.
	<li> None of the above
	</ol>
</li><br/>
<li> The difference(s) between active and passive intruders are that
	<ol class="answer_list">
	<li> passive intruders use an existing users credentials for access
		while active intruders use vulnerabilities to break in.
	<li> passive intruders rely on social engineering whereas active
		intruders use technical exploits.
	<li> active intruders use acquired data for personal gain while
		passive intruders use the data to expose the illegal
		activities of others.
	<li> active intruders write/change data whereas passive intruders
		only read data.
	<li> None of the above
	</ol>
</li><br/>
<li> A passive intruder <strong>must</strong> have
	<ol class="answer_list">
	<li> the credentials of an authorized user to access data.
	<li> electronic access to the computer system.
	<li> physical access to the computer system.
	<li> an exploit for a known vulnerability.
	<li> None of the above
	</ol>
</li><br/>
<li> An active intruder <strong>must</strong> have
	<ol class="answer_list">
	<li> the credentials of an authorized user to access data.
	<li> electronic access to the computer system.
	<li> physical access to the computer system.
	<li> an exploit for a known vulnerability.
	<li> None of the above
	</ol>
</li><br/>
<li> Determining who can see what data (e.g., privacy) is known as information
	<ol class="answer_list">
	<li> availability.
	<li> accountability.
	<li> confidentiality.
	<li> integrity.
	<li> None of the above
	</ol>
</li><br/>
<li> Preventing the change or removal of data by unauthorized people is
	information
	<ol class="answer_list">
	<li> availability.
	<li> accountability.
	<li> confidentiality.
	<li> integrity.
	<li> None of the above
	</ol>
</li><br/>
<li> Ensuring that unauthorized people are <strong>not</strong> able to make
	a system unusable or reduce its performance is called information
	<ol class="answer_list">
	<li> availability.
	<li> accountability.
	<li> confidentiality.
	<li> integrity.
	<li> None of the above
	</ol>
</li><br/>
<li> The loss of data availability requires
	<ol class="answer_list">
	<li> the loss of data accountability.
	<li> the loss of data integrity.
	<li> a loss of data confidentiality.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of attack would be the hardest to detect and defend against?
	<ol class="answer_list">
	<li> A passive attack by an outsider.
	<li> A passive attack by an insider.
	<li> An active attack by an outsider.
	<li> An active attack by an insider.
	<li> None of the above
	</ol>
</li><br/>
<li> What term is used to describe unskilled persons that use software
	developed by others to gain unauthorized access to computer systems
	and data?
	<ol class="answer_list">
	<li> Script-kiddie
	<li> Black Hat
	<li> Cracker
	<li> Hacker
	<li> None of the above
	</ol>
</li><br/>
<li> A group of networked and compromised computers that are used to conduct
	illegal activities on a massive scale is called
	<ol class="answer_list">
	<li> cyberwarfare.
	<li> a botnet.
	<li> port scanning.
	<li> a script-kiddie.
	<li> None of the above
	</ol>
</li><br/>
<li> Port scanning is a common method used to
	<ol class="answer_list">
	<li> discover computer systems and their potential vulnerabilities.
	<li> form a group of networked computers into a botnet.
	<li> exploit the known vulnerabilities of a system.
	<li> conduct a passive insider attack on a system.
	<li> None of the above
	</ol>
</li><br/>
<li> A computer system that meets a formally stated set of security requirements
	is called a
	<ol class="answer_list">
	<li> secure system.
	<li> trusted computer base.
	<li> trusted system.
	<li> validated system.
	<li> None of the above
	</ol>
</li><br/>
<li> The set of hardware and software that provides the basis for a system
	that meets a formally stated set of security requirements is called a
	<ol class="answer_list">
	<li> secure system.
	<li> trusted computer base.
	<li> trusted system.
	<li> validated system.
	<li> None of the above
	</ol>
</li><br/>
<li> A trusted computing base (TCB) is comprised of
	<ol class="answer_list">
	<li> most (but not necessarily all) of the computer hardware.
	<li> <strong>all</strong> the hardware and software of a computer
		system.
	<li> the human processes and procedures used to operate the computer
		system.
	<li> the core part of the OS (e.g., microkernel).
	<li> None of the above
	</ol>
</li><br/>

<li> A domain is a set of object-right pairs, in which the
	<ol class="answer_list">
	<li> object represents a resource (e.g., file, cpu, disk, software).
	<li> object represents users and groups of users.
	<li> right represents the permission to perform a specific operation.
	<li> right represents one of ADD, DELETE, MODIFY.
	<li> None of the above
	</ol>
</li><br/>
<li> When users (and processes) only have access to the resources (and
	operations) necessary to complete a task, this is known as the
	<ol class="answer_list">
	<li> lowest access protocol.
	<li> least common denominator.
	<li> principle of necessary privilege.
	<li> principle of least authority.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to file objects in a POSIX system, the rights are the
	<ol class="answer_list">
	<li> add, remove, modify operations allowed for the file owner.
	<li> add, remove, modify operations allowed for the file owner
		and everyone else.
	<li> read, write, and execute operations allowed for the file owner.
	<li> read, write, and execute operations allowed for the file owner,
		the file's group, and everyone else.
	<li> None of the above
	</ol>
</li><br/>
<li> The SETUID bit associated with files on a POSIX system are used to
	<ol class="answer_list">
	<li> execute the program file with the identity of the file's owner,
		regardless of who executes the program file.
	<li> ensure that the file is owned by the file's creator.
	<li> enable the owner of a file to execute the program it holds.
	<li> enable anyone to execute the program file.
	<li> None of the above
	</ol>
</li><br/>
<li> The SETUID bit associated with files on a POSIX system can create a
	secruity risk
	<ol class="answer_list">
	<li> because it enables someone other than the owner of a file to
		delete or change the file.
	<li> if the file owner has the same privileges as the superuser
		(e.g., root or administrator accounts).
	<li> since it allows users to change their identity whenever they
		wish.
	<li> when the file contains non-executable, but sensitive data.
	<li> None of the above
	</ol>
</li><br/>
<li> If the protection matrix is drawn like the below, what information is
	stored within the matrix locations? 
<table border="1">
<tr>
	<th colspan="2" rowspan="2"></th>
	<th colspan="8">Objects</th>
</tr>
<tr>
	<th>File 1</th>
	<th>File 2</th>
	<th>...</th>
	<th>File N</th>
	<th>Domain 1</th>
	<th>Domain 2</th>
	<th>...</th>
	<th>Domain D</th>
</tr>
<tr>
	<th rowspan="4" style="vertical-align: middle">Subjects</th>
	<th>Domain 1</th>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
</tr>
<tr>
	<th>Domain 2</th>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
</tr>
<tr>
	<th>...</th>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
</tr>
<tr>
	<th>Domain D</th>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
</tr>
</table>
	<ol class="answer_list">
	<li> Usernames that are the owners of the object within the subject
		domain.
	<li> 1 if the object is owned by the subject, and 0 otherwise.
	<li> Operations the subject is allowed to perform on the object.
	<li> Group names that contain both the (user) subject and which are
		group owners of the object.
	<li> None of the above
	</ol>
</li><br/>
<li> The objects within the protection matrix are most often associated with
	<ol class="answer_list">
	<li> users.
	<li> groups of users.
	<li> processes.
	<li> files.
	<li> None of the above
	</ol>
</li><br/>
<li> The subjects within the protection matrix are most often associated with
	<ol class="answer_list">
	<li> users.
	<li> groups of users.
	<li> processes.
	<li> files.
	<li> None of the above
	</ol>
</li><br/>
<li> Domains can appear both as objects and subjects within the protection
	matrix in order to
	<ol class="answer_list">
	<li> allow domains to add, remove, or modify themselves.
	<li> allow domains to add, remove, or modify other domains.
	<li> support switching from one domain to another domain.
	<li> enable domains to create new domains. 
	<li> None of the above
	</ol>
</li><br/>
<li> Because the protection matrix can be quite large, most systems don't
	store it as a full matrix. When the matrix is stored as sparse
	rows, it is called
	<ol class="answer_list">
	<li> an Object Permissions List.
	<li> an Access Control List.
	<li> a Capability List.
	<li> a Subject Permissions List.
	<li> None of the above
	</ol>
</li><br/>
<li> Because the protection matrix can be quite large, most systems don't
	store it as a full matrix. When the matrix is stored as sparse
	columns, it is called
	<ol class="answer_list">
	<li> an Object Permissions List.
	<li> an Access Control List.
	<li> a Capability List.
	<li> a Subject Permissions List.
	<li> None of the above
	</ol>
</li><br/>
<li> POSIX systems typically store the protection matrix (using 9 bits to
	store the permissions for 3 domain categories) as a version of
	<ol class="answer_list">
	<li> an Object Permissions List.
	<li> an Access Control List.
	<li> a Capability List.
	<li> a Subject Permissions List.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following corresponds most closely to the storage of a
	protection matrix using a Capability List?
	<ol class="answer_list">
	<li>
<table border="1">
<tr>
<th>Write</th>
<td>File 2: Domain 3, Domain 4</td>
<td>File 5: Domain 7</td>
</tr>
</table>
	<li>
<table border="1">
<tr>
<th>File 2</th>
<td>Domain 2: Write</td>
<td>Domain D: Read/Write</td>
</tr>
</table>
	<li>
<table border="1">
<tr>
<th>Domain 2</th>
<td>File 2: Write</td>
<td>File N: Execute</td>
<td>Domain D: Enter</td>
</tr>
</table>
	<li>
<table border="1">
<tr>
<th>File 3</th>
<td>Read: Domain 4, Domain 7</td>
<td>Write: Domain 5</td>
</tr>
</table>
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following corresponds most closely to the storage of a
	protection matrix using an Access Control List?
	<ol class="answer_list">
	<li>
<table border="1">
<tr>
<th>Write</th>
<td>File 2: Domain 3, Domain 4</td>
<td>File 5: Domain 7</td>
</tr>
</table>
	<li>
<table border="1">
<tr>
<th>File 2</th>
<td>Domain 2: Write</td>
<td>Domain D: Read/Write</td>
</tr>
</table>
	<li>
<table border="1">
<tr>
<th>Domain 2</th>
<td>File 2: Write</td>
<td>File N: Execute</td>
<td>Domain D: Enter</td>
</tr>
</table>
	<li>
<table border="1">
<tr>
<th>File 3</th>
<td>Read: Domain 4, Domain 7</td>
<td>Write: Domain 5</td>
</tr>
</table>
	<li> None of the above
	</ol>
</li><br/>
<li> Additional advantage(s) that Capability Lists have over Access Control
	Lists is that they are
	<ol class="answer_list">
	<li> themselves objects and can thus be referenced by other
		Capability Lists.
	<li> able to more easily add, delete, or change the rights to an
		object by a specific subject.
	<li> more efficient in allowing a process to exercise a specific right.
	<li> able to revoke <strong>all</strong> rights to an object (by
		<strong>all</strong> subjects) more quickly and easily.
	<li> None of the above
	</ol>
</li><br/>
<li> Since Capability Lists are associated with (and "owned" by) subjects
	(i.e., users), unlike Access Control Lists, they <strong>must</strong>
	be protected from tampering otherwise
	<ol class="answer_list">
	<li> the subject of that Capability List could grant themselves
		additional capabilities.
	<li> anyone on the system could remove capabilities from other users.
	<li> anyone on the system could remove subjects, even those they
		didn't own.
	<li> Capability Lists wouldn't be able to reference other Capability
		Lists.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following ways in which Capability Lists are protected from
	tampering?
	<ol class="answer_list">
	<li> Each user's login shell prevents that user from accessing their
		own Capability List, even though they own it.
	<li> Special hardware tag bits in memory to indicate which data are
		part of a capability list.
	<li> The Capability Lists are kept in the OS with no direct access by
		subjects.
	<li> A one-way hash function is used to prevent alteration, enabling
		the Capability lists to be stored in user space.
	<li> None of the above
	</ol>
</li><br/>
<li> If groups of subjects/users are <strong>not</strong> supported,
	then Access Control Lists
	<ol class="answer_list">
	<li> can become very large if rights are granted to every user.
	<li> <strong>must</strong> collect objects together into groups instead.
	<li> are associated with each subject (to make access faster) rather
		than with the corresponding object. 
	<li> become extremely slow to use, so Capability Lists should be used
		instead.
	<li> None of the above
	</ol>
</li><br/>
<li> Access Control Lists enable rights to an object by a specific subject to
	be easily
	<ol class="answer_list">
	<li> added.
	<li> modified.
	<li> deleted.
	<li> None of the above
	</ol>
</li><br/>

<li> The protection matrix indicates what subjects <em>can</em> do,
	<strong>not</strong> what they are authorized to do. Authorization is
	<ol class="answer_list">
	<li> determined in combination with the password file.
	<li> enforced by the OS kernel.
	<li> enforced by the file system.
	<li> a management policy, <strong>not</strong> part of the OS.
	<li> None of the above
	</ol>
</li><br/>
<li> Protection commands are used by processes to
	<ol class="answer_list">
	<li> enforce the rights recorded in the protection matrix.
	<li> prevent changes to the protection matrix.
	<li> change the protection matrix.
	<li> create the Access Control List or Capability List that
		corresponds to the protection matrix.
	<li> None of the above
	</ol>
</li><br/>
<li> The protection commands for "Create Subject" and "Delete Subject"
	<ol class="answer_list">
	<li> add/remove a row from the protection matrix.
	<li> add/remove a column from the protection matrix.
	<li> modify an entry in the protection matrix.
	<li> None of the above
	</ol>
</li><br/>
<li> The protection commands for "Create Object" and "Delete Object"
	<ol class="answer_list">
	<li> add/remove a row from the protection matrix.
	<li> add/remove a column from the protection matrix.
	<li> modify an entry in the protection matrix.
	<li> None of the above
	</ol>
</li><br/>
<li> The protection commands for "Insert Right" and "Remove Right"
	<ol class="answer_list">
	<li> add/remove a row from the protection matrix.
	<li> add/remove a column from the protection matrix.
	<li> modify an entry in the protection matrix.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of access control allows the owner of an object to determine
	who should have access to it?
	<ol class="answer_list">
	<li> Selective access control
	<li> Discretionary access control
	<li> Proscribed access control
	<li> Mandatory access control
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of access control uses organizational rules to determine which
	subjects have rights to various objects?
	<ol class="answer_list">
	<li> Selective access control
	<li> Discretionary access control
	<li> Proscribed access control
	<li> Mandatory access control
	<li> None of the above
	</ol>
</li><br/>
<li> Within an organizational structure in which <strong>all</strong>
	objects and subjects are assigned "security levels", the
	Biba Model of mandatory access control
	<ol class="answer_list">
	<li> restricts subjects to read only files which have an equal or
		higher security level than they do.
	<li> restricts subjects to read only files which have an equal or
		lower security level than they do.
	<li> restricts subjects to write only to files which have an equal or
		higher security level than they do.
	<li> restricts subjects to write only to files which have an equal or
		lower security level than they do.
	<li> None of the above
	</ol>
</li><br/>
<li> Within an organizational structure in which <strong>all</strong>
	objects and subjects are assigned "security levels", the
	Bell-LaPadula Model of mandatory access control
	<ol class="answer_list">
	<li> restricts subjects to read only files which have an equal or
		higher security level than they do.
	<li> restricts subjects to read only files which have an equal or
		lower security level than they do.
	<li> restricts subjects to write only to files which have an equal or
		higher security level than they do.
	<li> restricts subjects to write only to files which have an equal or
		lower security level than they do.
	<li> None of the above
	</ol>
</li><br/>
<li> Which security model is designed to allow managers to actively direct
	their subordinates?
	<ol class="answer_list">
	<li> Bell-LaPadula Model
	<li> Biba Model
	<li> None of the above
	</ol>
</li><br/>
<li> Which security model is designed to keep (military) secrets?
	<ol class="answer_list">
	<li> Bell-LaPadula Model
	<li> Biba Model
	<li> None of the above
	</ol>
</li><br/>
<li> The question of how to keep information that a server process gets from
	a client process from being passed on to a third party is known as
	<ol class="answer_list">
	<li> steganography.
	<li> the encryption conundrum.
	<li> the confinement problem.
	<li> a security sieve.
	<li> None of the above
	</ol>
</li><br/>
<li> Covert channels are
	<ol class="answer_list">
	<li> difficult to stop simply because they use subtle and "underhanded"
		ways to pass along information.
	<li> frequently used to allow remote systems to communicate.
	<li> noisy but enable information to be reliable sent.
	<li> designed to ensure the integrity of transmitted data.
	<li> None of the above
	</ol>
</li><br/>
<li> Hiding information within other unrelated information is called
	<ol class="answer_list">
	<li> semiology.
	<li> steganography.
	<li> cryptography.
	<li> cartography.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are design principles for security?
	<ol class="answer_list">
	<li> System designs should be private.
	<li> The default should be <strong>no</strong> access.
	<li> Check for the current rights to a resource upon each use,
		<strong>not</strong> just those it had when the resource
		was acquired.
	<li> Only give new processes the privileges of their parent.
	<li> Protection mechanisms should be built into the OS.
	<li> Security schemes <strong>must</strong> be psychologically
		acceptable.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are design principles for security?
	<ol class="answer_list">
	<li> System designs should be public.
	<li> The default read/write access to files should be given only for
		those owned by the process owner.
	<li> Check for the current rights to a resource upon each use,
		<strong>not</strong> just those it had when the resource
		was acquired.
	<li> Give each process the least privilege possible.
	<li> Protection mechanisms belong in a single process, separate from
		the OS, to ensure it isn't compromised if the OS is.
	<li> Security schemes <strong>must</strong> be psychologically
		acceptable.
	<li> None of the above
	</ol>
</li><br/>

<li> With respect to cryptography, the idea that encryption algorithms should
	be public, so that the key is the sole means for ensuring secrecy,
	is called
	<ol class="answer_list">
	<li> security by obscurity.
	<li> saltiness.
	<li> Kerckhoffs' principle.
	<li> algorithmic strength.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to cryptography, the computational effort needed to convert
	encrypted text back into its original form <strong>without</strong>
	knowing the encryption key(s) is known as
	<ol class="answer_list">
	<li> security by obscurity.
	<li> the an algorithm's saltiness.
	<li> Kerckhoffs' principle.
	<li> the encryption algorithm's strength.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to cryptography, the encrypted version of the text (or data)
	is called
	<ol class="answer_list">
	<li> the encryption key.
	<li> plaintext.
	<li> ciphertext.
	<li> salt.
	<li> None of the above
	</ol>
</li><br/>
<li> With respect to cryptography, the original text (or data) that was intended
	for direct consumption by a human (or computer program) is called
	<ol class="answer_list">
	<li> the encryption key.
	<li> plaintext.
	<li> ciphertext.
	<li> salt.
	<li> None of the above
	</ol>
</li><br/>
<li> When the key to encrypt text/data is <em>different</em> from the key
	to decrypt the encrypted text/data, this is called
	<ol class="answer_list">
	<li> symmetric key cryptography.
	<li> asymmetric key cryptography.
	<li> secret key cryptography.
	<li> one-way hash function cryptography. 
	<li> None of the above
	</ol>
</li><br/>
<li> When the key to encrypt text/data is the <em>same</em> as the key
	to decrypt the encrypted text/data, this is called
	<ol class="answer_list">
	<li> symmetric key cryptography.
	<li> asymmetric key cryptography.
	<li> secret key cryptography.
	<li> one-way hash function cryptography. 
	<li> None of the above
	</ol>
</li><br/>
<li> Advantage(s) of secret key over public key cryptography are
	<ol class="answer_list">
	<li> the algorithms are generally quite fast, handling large amounts
		of text/data efficiently.
	<li> it can be used as the basis for digital signatures.
	<li> it requires the secure exchange of keys.
	<li> that it's harder to break since the algorithms are kept secret.
	<li> None of the above
	</ol>
</li><br/>
<li> Disadvantage(s) of secret key over public key cryptography are
	<ol class="answer_list">
	<li> the algorithms are generally quite slow.
	<li> it can be used as the basis for digital signatures.
	<li> it requires the secure exchange of keys.
	<li> that it's easier to break since the algorithms are kept secret.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are secret key cryptography algorithms currently
	recommended for use by the National Institute for Standards
	and Technology (NIST)?
	<ol class="answer_list">
	<li> Twofish
	<li> RSA
	<li> Triple DES
	<li> Advanced Encryption Standard (AES)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are secret key cryptography algorithms currently
	recommended for use by the National Institute for Standards
	and Technology (NIST) for protecting US government TOP SECRECT
	documents?
	<ol class="answer_list">
	<li> Twofish
	<li> RSA
	<li> Triple DES
	<li> Advanced Encryption Standard (AES)
	<li> None of the above
	</ol>
</li><br/>
<li> For public key cryptography, the 2 keys required are
	<ol class="answer_list">
	<li> are randomly chosen by the person send and the person receiving
		the message.
	<li> the same key.
	<li> bit-wise palindromes of one another.
	<li> related to one another by a mathematical property.
	<li> None of the above
	</ol>
</li><br/>
<li> For Alice and Bob to have a two-way communication with one another using
	public key cryptography, how many separate keys <strong>must</strong>
	be created and used?
	<ol class="answer_list">
	<li> 2 keys created, and both keys are used.
	<li> 2 keys created, but only one key is used.
	<li> 4 keys created, but only two keys are used.
	<li> 4 keys created, and <strong>all</strong> keys are used.
	<li> None of the above
	</ol>
</li><br/>
<li> Advantage(s) of public key over secret key cryptography are
	<ol class="answer_list">
	<li> the algorithms are generally quite fast, handling large amounts
		of text/data efficiently.
	<li> it can be used as the basis for digital signatures.
	<li> it requires the secure exchange of keys.
	<li> that it's harder to break since the algorithms are kept secret.
	<li> None of the above
	</ol>
</li><br/>
<li> Disadvantage(s) of public key over secret key cryptography are
	<ol class="answer_list">
	<li> the algorithms are generally quite slow.
	<li> it can be used as the basis for digital signatures.
	<li> it requires the confidential exchange of keys.
	<li> that it's harder to break since the algorithms are kept secret.
	<li> None of the above
	</ol>
</li><br/>
<li> For Bob to send confidential messages to Alice, match the correct
	choice of person, action, and information in the following sequence
	of steps. You should restrict your choice to one of the two options
	following each blank.
	[Note: Some options may be used more than once, or not at all.]
	<ul class="bullet_list">
	<li> ___A___ [ Alice | Bob ] creates a public-private key pair.
	<li> ___B___ [ Alice | Bob ] publishes the ___C___ [ public | private ]
		key to the world.
	<li> ___D___ [ Alice | Bob ] uses ___E___'s [ Alice | Bob ]
		___F___ [ public | private ] key to
		___G___ [ encrypt | decrypt ] a message.
	<li> ___H___ [ Alice | Bob ] sends the ___I___ed [ encrypt | decrypt ]
		message to ___J___ [ Alice | Bob ].
	<li> ___K___ [ Alice | Bob ] receives the
		___L___ed [ encrypt | decrypt ] message from
		___M___ [ Alice | Bob ].
	<li> ___N___ [ Alice | Bob ] ___O___s [ encrypt | decrypt ]
		the message using the ___P___ [ public | private ] key.
	<li> Alice reads the message.
	</ul>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> Alice
		<li> Bob
		<li> public
		<li> private
		<li> encrypt
		<li> decrypt
		</ol>
	</td></tr></table>
</li><br/>
<li> Many available cryptographically secured communication systems (e.g.,
	PGP, GPG) use both secret key and public-private key algorithms because 
	<ol class="answer_list">
	<li> the public-private keys are used to exchange the secret keys since
		secret key algorithms are used to provide secrecy for the
		actual text/data (due to their greater speed and efficiency).
	<li> the secret keys are used to exchange the public-private keys since
		public-private key algorithms are used to provide secrecy for
		the actual text/data (due to their greater speed and
		efficiency).
	<li> the public-private keys are used to encrypt data for sending
		while the secret keys are used to decrypt data for reading.
	<li> the secret keys are used to encrypt data for sending while the
		public-private keys are used to decrypt data for reading.
	<li> None of the above
	</ol>
</li><br/>
<li> One-Way hash functions
	<ol class="answer_list">
	<li> encrypt their input, using only a secret key algorithm.
	<li> encrypt their input, using only a public key algorithm.
	<li> encrypt their input, using either a secret or public key algorithm.
	<li> create a digest of their input which is often shorter than
		the original text.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary difference(s) between encryption algorithms and one-way
	hash functions are
	<ol class="answer_list">
	<li> encryption algorithms are faster and more efficient.
	<li> encryption algorithms are reversible.
	<li> one-way hash functions <strong>must</strong> use a non-secret salt.
	<li> different inputs to one-way hash functions <strong>always</strong>
		provide different results.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are one-way hash functions are that currently
	recommended for use by the National Institute for Standards
	and Technology (NIST)?
	<ol class="answer_list">
	<li> RSA
	<li> SHA512
	<li> MD5
	<li> Twofish
	<li> None of the above
	</ol>
</li><br/>
<li> Which technologies (in combination) are used to provide non-repudiation
	for public communications (i.e., digital signatures)?
	<ol class="answer_list">
	<li> Symmetric key cryptography
	<li> Asymmetric key cryptography
	<li> One-way hash functions
	<li> Salt values.
	<li> None of the above
	</ol>
</li><br/>
<li> For Alice to digitally sign a document, and for Bob to subsequently
        confirm that signature for the given document, match the correct
	choice of person, action, and information in the following sequence
	of steps.  You should restrict your choice to one of the two options
	following each blank.
	[Note: Some options may be used more than once, or not at all.]
	<ul class="bullet_list">
	<li> ___A___ [ Alice | Bob ] creates a public-private key pair,
		publishing the public key to the world.
	<li> ___B___ [ Alice | Bob ] uses a one-way hash to create a
		message digest of the document.
	<li> ___C___ [ Alice | Bob ] uses their ___D___ [ public | private ]
		key to ___E___ [ encrypt | decrypt ] the
		___F___ [ message digest | document ], creating the
		signature block.
	<li> The signature block is then appended to the
		___G___ [ message digest | document ].
	<li> ___H___ [ Alice | Bob ] obtains ___I___'s [ Alice | Bob ]
		___J___ [ public | private ] key.
	<li> ___K___ [ Alice | Bob ] strips the signature block from the
		signed document.
	<li> ___L___ [ Alice | Bob ] ___M___s [ encrypt | decrypt ] the
		signature block to obtain a message digest (MDsigned) using
		___N___'s [ Alice | Bob ] ___O___ [ public | private ] key.
	<li> ___P___ [ Alice | Bob ] creates a second message digest (MDdoc).
	<li> ___Q___ [ Alice | Bob ] compares MDsigned with MDdoc,
		and if they are then this document was signed by Alice.
	</ul>
	<table><tr><td>
		<ol class="match_list">
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		<li> __________________
		</ol>
	</td><td>
		<ol class="answer_list">
		<li> Alice
		<li> Bob
		<li> public
		<li> private
		<li> encrypt
		<li> decrypt
		<li> message digest
		<li> document
		</ol>
	</td></tr></table>
</li><br/>
<li> For the purpose of non-repudiation, keeping a document and signature
	block together is
	<ol class="answer_list">
	<li> unnecessary since the document can <strong>always</strong> be
		regenerated from the signature block.
	<li> helpful, but <strong>not</strong> necessary since the signature
		block can be recreated from the document.
	<li> necessary since the document <strong>must</strong> be used to
		create the message digest needed for confirmation.
	<li> necessary since the message digest for the document
		<strong>must</strong> be created using the salt from
		the signature block.
	<li> None of the above
	</ol>
</li><br/>
<li> An important aspect of public key cryptography that allows Alice to use
	the same public-private key pair to create digital signatures
	<em>and</em> to allow anyone else (e.g., Bob) to send her secure
	communications that no one else can read is due to which of the
	following characteristics of asymmetric algorithms like RSA?
	<ol class="answer_list">
	<li> the private key can be used to decrypt information encrypted using
		the private key.
	<li> the public key can be used to decrypt information encrypted using
		the public key.
	<li> the private key can be used to decrypt information encrypted using
		the public key.
	<li> the public key can be used to decrypt information encrypted using
		the private key.
	<li> None of the above
	</ol>
</li><br/>
<li> While retaining their non-repudiability characteristic, digital
	signatures can
	<ol class="answer_list">
	<li> be used to sign a document, but only by one person.
	<li> be used to sign multiple documents, but only by one person.
	<li> be used to have multiple people sign a document, by having
		each sign the previous combined document and signature
		block in succession (so long as the signing order is
		communicated).
	<li> be used to have muiltiple people sign a document, by having
		the primary signer use the private keys of the other signers
		to encrypt the message digest once with each key to create
		the signature block.
	<li> None of the above
	</ol>
</li><br/>
<li> Why is Alice's publishing of her public key on an unsecured web site
	insufficient to ensure confidentiality?
	<ol class="answer_list">
	<li> Because anyone could use her public key to read encrypted messages
		that others are sending to Alice.
	<li> Because anyone could digitally sign documents using Alice's
		public key, and thus could pretend to be Alice
		<strong>without</strong> anyone finding out.
	<li> Because a third party, Mallory, could make a random change to her
		published key making sure that Alice was unable to read
		any messages sent to her (encrypted with the altered public
		key).
	<li> Because a third party, Mallory, could change her published key
		to be that of his own public key, thus enabling a
		man-in-the-middle attack for encrypted communications sent
		to Alice.
	<li> None of the above
	</ol>
</li><br/>
<li> How does using a trusted third party certificate authority (CA) when
	publishing a public key help to ensure the secrecy of communications?
	<ol class="answer_list">
	<li> The digital signature of the CA provides assurance that the
		public key is unaltered.
	<li> The CA hosts a well secured and trusted web site to which the
		public key is published - thus avoiding the problems of using
		an unsecured web site.
	<li> The CA serves as an intermediary for <strong>all</strong>
		encrypted messages sent to Alice, and the CA decrypts the
		message on Alice's behalf to ensure that her public key
		was used to encrypt it.
	<li> The CA vouches for the authenticity of the public key (i.e., it
		belongs to the claimed owner).
	<li> None of the above
	</ol>
</li><br/>
<li> Key storage is an important consideration for secret keys when using
	symmetric cryptography because
	<ol class="answer_list">
	<li> if the one copy of the secret key is altered or lost, then any
		information encrypted using that key will be lost.
	<li> knowing one secret key from the key store compromises
		<strong>all</strong> other secret keys in the key store.
	<li> if a third party discovers the secret key, than anything encrypted
		using it can be compromised.
	<li> if a third party discovers the public key (of the key pair),
		they could "fake" perfect digital signatures on documents.
	<li> None of the above
	</ol>
</li><br/>
<li> Key storage is an important consideration for private keys when using
	asymmetric cryptography because
	<ol class="answer_list">
	<li> if the one copy of the private key is altered or lost, then any
		information encrypted using the corresponding public key will
		be lost.
	<li> knowing one private key from the key store compromises
		<strong>all</strong> other private keys in the key store.
	<li> if a third party discovers the private key, than anything
		encrypted using the corresponding public key can be compromised.
	<li> if a third party discovers the private key,
		they could "fake" legitimate digital signatures on documents.
	<li> None of the above
	</ol>
</li><br/>
<li> The purpose of a Hardware Security Module (HSM) with respect to
	cryptography is to
	<ol class="answer_list">
	<li> render the stored keys unusable upon detection of tampering.
	<li> prevent unauthorized users from accessing the stored keys.
	<li> verify the digital signatures of the stored keys.
	<li> create public-private key pairs for asymmetric algorithms.
	<li> None of the above
	</ol>
</li><br/>
<li> The advantage of using a Trusted Platform Module (TPM) over using only
	a Hardware Security Module (HSM) is that
	<ol class="answer_list">
	<li> because the TPM verifies the Certificate Authority's digital
		signatures, <strong>all</strong> stored keys can be trusted.
	<li> the TPM only allows authorized users to read stored keys back
		to their programs.
	<li> the TPM renders the stored keys unusable upon detection of
		tampering.
	<li> the TPM performs the encrypt/decrypt operations so that keys
		<strong>never</strong> leave the module.
	<li> None of the above
	</ol>
</li><br/>
<li> The advantage(s) of using a Trusted Platform Module (TPM) that is fully
	integrated into the hardware and OS include
	<ol class="answer_list">
	<li> the ability to securely encrypt <strong>all</strong> data stored
		on installed HDDs and SSDs.
	<li> the inability to install unauthorized (e.g., unsigned) software.
	<li> a guarantee that any encrypted data on the system can
		<strong>always</strong> be accessed.
	<li> attestation to verify that the computer is currently
		authorized to run a particular software (or access specific
		data).
	<li> None of the above
	</ol>
</li><br/>

<li> The process and policies for enabling users to prove who they are is
	called
	<ol class="answer_list">
	<li> authorization.
	<li> attestation.
	<li> authentication.
	<li> dispensation.
	<li> None of the above
	</ol>
</li><br/>
<li> The types of factors typically used to identify users are
	<ol class="answer_list">
	<li> human factors.
	<li> knowledge factors.
	<li> possession factors.
	<li> inherence factors.
	<li> None of the above
	</ol>
</li><br/>
<li> Passwords and challenge-response mechanisms are examples of which type(s)
	of factor(s) used for user identification?
	<ol class="answer_list">
	<li> human factors.
	<li> knowledge factors.
	<li> possession factors.
	<li> inherence factors.
	<li> None of the above
	</ol>
</li><br/>
<li> Credit cards and USB security dongles are examples of which type(s) of
	factor(s) used for user identification?
	<ol class="answer_list">
	<li> human factors.
	<li> knowledge factors.
	<li> possession factors.
	<li> inherence factors.
	<li> None of the above
	</ol>
</li><br/>
<li> Fingerprints and retina scans are examples of which type(s) of factor(s)
	used for user identification?
	<ol class="answer_list">
	<li> human factors.
	<li> knowledge factors.
	<li> possession factors.
	<li> inherence factors.
	<li> None of the above
	</ol>
</li><br/>
<li> To preserve the confidentiality of user passwords,
	<ol class="answer_list">
	<li> only their one-way hash values should be stored.
	<li> they should be stored as encrypted values.
	<li> they should be stored as two separate parts, each part
		encrypted using a different key.
	<li> storing them as cleartext is okay, provided the password
		file is readable only by the superuser.
	<li> None of the above
	</ol>
</li><br/>
<li> Many users pick passwords that are (or are similar to) real words. A
	common mechanism to reduce the chances of a successful dictionary
	attack on passwords,
	<ol class="answer_list">
	<li> encrypts each password using a common symmetric key.
	<li> stores passwords in two or more pieces, making it harder for
		attackers to get the full password.
	<li> encrypts the password using itself as the symmetric key.
	<li> adds random "salt" characters to the password before it is hashed.
	<li> None of the above
	</ol>
</li><br/>
<li> While password schemes are easy to understand and implement, they
	are made less secure due to people's
	<ol class="answer_list">
	<li> using their password too often by repeatedly logging out and
		back in again.
	<li> writing down their passwords or storing them as plaintext
		in a computer file.
	<li> using passwords that are very similar to natural language words,
		making them vulnerable to dictionary attacks.
	<li> using shorter passwords that are easier to remember.
	<li> None of the above
	</ol>
</li><br/>
<li> One-time passwords are more secure
	<ol class="answer_list">
	<li> because <strong>all</strong> of the unused passwords
		<strong>must</strong> be stored so that both the system
		and the user know which password should be used next.
	<li> since easedropping on communications for passwords won't
		enable the easedropper to login using them.
	<li> because the entire set of passwords <strong>must</strong> be
		agreed upon (and shared) in advance.
	<li> since they are created only as/when they are needed.
	<li> None of the above
	</ol>
</li><br/>
<li> One-way hash chains which create one-time passwords for transmission over
	communication networks are based on:
	<ol class="answer_list">
	<li> the repeated application of a non-invertible function.
	<li> having a maximum number of one-time passwords needed.
	<li> a secret seed/password value known only to the user.
	<li> the number of times to chain is specified by the server.
	<li> None of the above
	</ol>
</li><br/>
<li> One-way hash chains create
	<ol class="answer_list">
	<li> a fixed (but potentially large) number of one-time passwords that
		both the server and user <strong>must</strong> store/remember.
	<li> an unlimited number of one-time passwords used by the server,
		but the user only has to remember a single "base" password.
	<li> a new one-time password each time they are used. The user's
		public key is used by the server to transmit the new password
		for each login attempt.
	<li> a fixed (but potentially large) number of one-time passwords
		used by the server, but the user only has to remember a
		single "base" password.
	<li> None of the above
	</ol>
</li><br/>
<li> In order to ensure effectiveness, one-way hash chains for passwords require the
	<ol class="answer_list">
	<li> server to calculate the last value in the hash chain before
		the user can login the first time.
	<li> user to know the one-way hash function so that they can
		apply it to the server's challenge to calculate their response.
	<li> user to enter their password directly into the server.
	<li> user to enter their password into a trusted client that
		can apply the hash function to the user's password.
	<li> None of the above
	</ol>
</li><br/>
<li> When users setup a mathematical equation (e.g., f(x) = x + 4 ) as the
	basis for the computer to identify them by giving the user an
	(probably random) input (e.g., 5) and checking the user's answer
	against what the computer calculated for the same input (e.g., 9),
	this is called
	<ol class="answer_list">
	<li> Computed Authentication.
	<li> Challenge-Response.
	<li> Formula Identification.
	<li> One-way Hash Chain.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> general rules for
	securing login/password information?
	<ol class="answer_list">
	<li> Restrict read access to saved (and hashed) passwords.
	<li> Deny access as soon as an incorrect character in a password is
		typed.
	<li> Wait until <strong>all</strong> passwords and security questions
		are answered before granting/denying access.
	<li> Immediately deny access if an incorrect user name is given.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are general rules for securing login/password
	information?
	<ol class="answer_list">
	<li> Restrict read access to saved (and hashed) passwords.
	<li> Deny access as soon as an incorrect character in a password is
		typed.
	<li> Wait until <strong>all</strong> passwords and security questions
		are answered before granting/denying access.
	<li> Immediately deny access if an incorrect user name is given.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following factors for identifying users is a poor choice
	if only one factor is used due to its susceptibility to theft?
	<ol class="answer_list">
	<li> human factors.
	<li> knowledge factors.
	<li> possession factors.
	<li> inherence factors.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following factors for identifying users has the worst
	reliability due to variability of accurately acquiring the
	factor data? 
	<ol class="answer_list">
	<li> human factors.
	<li> knowledge factors.
	<li> possession factors.
	<li> inherence factors.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following would <strong>not</strong> be useful countermeasures
	to guard against compromises in user identification?
	<ol class="answer_list">
	<li> Only allow users to login from specific locations.
	<li> Ensure handprint being scanned is the correct body temperature.
	<li> Use random phrases for voiceprint verification (perhaps picked
		from a large set of saved phrases).
	<li> Require the physical use of a credit card rather than entering
		the number on a web form.
	<li> None of the above
	</ol>
</li><br/>
<li> Using multiple factors when identifying users
	<ol class="answer_list">
	<li> increases the confidence of a correct identification.
	<li> <strong>never</strong> works in practice since users reject
		it as taking too long.
	<li> provides lower confidence of a correct identification than if
		only one factor were used.
	<li> <strong>always</strong> prevents unauthorized access.
	<li> None of the above
	</ol>
</li><br/>

<li> A <em>buffer overflow</em> software bug enables an attacker to
	<ol class="answer_list">
	<li> read information outside the boundary of a data structure.
	<li> write information outside the boundary of a data structure.
	<li> calculate values that are too large to hold within a register.
	<li> load in values from memory too large to hold within a register.
	<li> None of the above
	</ol>
</li><br/>
<li> A <em>buffer overflow</em> software bug is only possible when
	<ol class="answer_list">
	<li> the program code is compiled directly into machine code.
	<li> the compiled code is part of the OS kernel.
	<li> the programming language run-time doesn't check variable
		boundaries (e.g., array bounds).
	<li> the computer system uses Direct Memory Access (DMA), which
		can copy large blocks of data.
	<li> None of the above
	</ol>
</li><br/>
<li> <em>Buffer overflow</em> bugs are <strong>not</strong> possible in code
	<ol class="answer_list">
	<li> run on a POSIX compliant system.
	<li> that doesn't use arrays.
	<li> written in Java and run on a compliant JVM.
	<li> that avoids using OS system calls.
	<li> None of the above
	</ol>
</li><br/>
<li> The <em>Heartbleed</em> attack, in the OpenSSL library, exploits which
	type of software bug?
	<ol class="answer_list">
	<li> Buffer Overflow
	<li> Format String
	<li> Dangling Reference
	<li> Integer Overflow
	<li> Command Injection
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> a helpful technique for
	avoiding/defending against a <em>buffer overflow</em> bug?
	<ol class="answer_list">
	<li> Stack Canary
	<li> Address Space Layout Randomization
	<li> Data Execution Prevention
	<li> Using strong run-time checked programming languages like Java.
	<li> None of the above
	</ol>
</li><br/>
<li> Writing a random (but known) value just below the return address in a
	function's run-time stack entry and checking it for changes before
	returning from the function describes which buffer overflow
	prevention/detection technique?
	<ol class="answer_list">
	<li> Stack Canary
	<li> Address Space Layout Randomization
	<li> Data Execution Prevention
	<li> Using strong run-time checked programming languages like Java.
	<li> None of the above
	</ol>
</li><br/>
<li> Preventing the execution of code stored in either the heap of the run-time
	stack of a running process/thread, describes which buffer overflow
	prevention/detection technique?
	<ol class="answer_list">
	<li> Stack Canary
	<li> Address Space Layout Randomization
	<li> Data Execution Prevention
	<li> Using strong run-time checked programming languages like Java.
	<li> None of the above
	</ol>
</li><br/>
<li> Locating the stack, heap, libraries, and other portions of the process
	layout in different parts of the address space each time the program
	is run, is an example which buffer overflow prevention/detection
	technique?
	<ol class="answer_list">
	<li> Stack Canary
	<li> Address Space Layout Randomization
	<li> Data Execution Prevention
	<li> Using strong run-time checked programming languages like Java.
	<li> None of the above
	</ol>
</li><br/>
<li> Format string bugs enable attacks that
	<ol class="answer_list">
	<li> are a special kind of null reference attack.
	<li> typically leverage unchecked user input.
	<li> can disclose unauthorized data by printing beyond the bounds
		of an array.
	<li> are based on a software bug peculiar to C, which enables a
		printf statement to change variable values.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is a helpful technique for
	avoiding/defending against a <em>format string</em> bug?
	<ol class="answer_list">
	<li> Stack Canary
	<li> Address Space Layout Randomization
	<li> Data Execution Prevention
	<li> Using strong run-time checked programming languages like Java.
	<li> None of the above
	</ol>
</li><br/>
<li> Dangling references are created when
	<ol class="answer_list">
	<li> a function returns a pointer to one of its local variables as
		its result.
	<li> the language run-time does <strong>not</strong> provide
		garbage collection.
	<li> dynamic (heap) allocated memory is <strong>not</strong> freed
		when it's no longer needed.
	<li> a pointer to a deallocated heap object is retained.
	<li> None of the above
	</ol>
</li><br/>
<li> Dangling references occur whenever
	<ol class="answer_list">
	<li> dynamic (heap) allocated memory is used.
	<li> a variable holds the address of unallocated memory.
	<li> dynamic (heap) allocated memory is <strong>not</strong> freed
		when it's no longer needed.
	<li> the language run-time does <strong>not</strong> provide
		garbage collection.
	<li> None of the above
	</ol>
</li><br/>
<li> A dangling reference bug can be exploited by
	<ol class="answer_list">
	<li> exhausting the amount of dynamic (heap) storage available.
	<li> simply writing to the deallocated storage at any time.
	<li> writing the dangling reference address to the storage it points
		to, thus creating a circular structure.
	<li> by changing an unrelated data structure when the deallocated
		storage pointed to by the dangling reference is part of
		a new dynamic (heap) allocation.
	<li> None of the above
	</ol>
</li><br/>
<li> The <strong>best</strong> defense(s) against dangling reference bugs is to
	<ol class="answer_list">
	<li> <strong>always</strong> fill newly allocated dynamic
		(heap) memory with zeros.
	<li> use automatic garbage collection.
	<li> disable the free/deallocate routine so that memory cannot be
		reused.
	<li> limit each object referenced by a pointer to be assigned at most
		twice.
	<li> None of the above
	</ol>
</li><br/>
<li> (De)referencing a null pointer as a function to call usually causes an
	error since there is no code at address 0 to run, but
	<ol class="answer_list">
	<li> if code is mapped to address 0 (e.g., by the <em>mmap</em> system
		call), then the mapped code will be run instead of crashing.
	<li> using garbage collection prevents dereferencing null pointers.
	<li> it is <strong>not</strong> possible to use a pointer as a
		function to call, except in assembly language, so this is
		seldom a problem.
	<li> this can be avoided by using a special (e.g., negative) value
		to mark uninitialized pointers.
	<li> None of the above
	</ol>
</li><br/>
<li> Integer Overflow bugs occur when
	<ol class="answer_list">
	<li> a number that is too large is loaded from memory into a register.
	<li> a number that is too large is stored from a register into memory.
	<li> the result of an integer operation (e.g., multiplication)
		is larger than can be stored in a register, and
		<strong>no</strong> error is generated.
	<li> the result of an integer operation (e.g., multiplication)
		is too large, writing beyond the intended variable space
		(a specific form of the buffer overflow bug).
	<li> None of the above
	</ol>
</li><br/>
<li> Command Injection occurs when
	<ol class="answer_list">
	<li> the input buffer overflows and writes new commands into the
		program code.
	<li> a null pointer is dereferenced and the 0th address has been mapped
		to unauthorized code.
	<li> a function call is passed a dangling reference as one of its
		parameters.
	<li> unsanitized user input is used as part of an executed action.
	<li> None of the above
	</ol>
</li><br/>
<li> SQL injection is one of the most common forms of command injection. For
	the following SQL code, which value of <em>$input_name</em> would
	cause a command injection <strong>without</strong> causing a SQL error?
<pre>
	SELECT BirthDate FROM PersonTable WHERE Name = '$input_name';
</pre>
	<ol class="answer_list">
	<li> TRUNCATE TABLE PersonTable;
	<li> 'TRUNCATE TABLE PersonTable'; --
	<li> Joe TRUNCATE TABLE PersonTable;
	<li> Joe'; TRUNCATE TABLE PersonTable; --
	<li> None of the above
	</ol>
</li><br/>
<li> Time of Check to Time of Use (TOCTOU) attacks
	<ol class="answer_list">
	<li> exploit the lack of semaphore use in most programs.
	<li> leverage the race condition between checking that a use will be
		valid and the actual use.
	<li> are impossible to prevent since there will
		<strong>always</strong> be a delay between checking the
		legality of something and then actually doing it.
	<li> None of the above
	</ol>
</li><br/>
<li> Time of Check to Time of Use (TOCTOU) attacks are enabled by
	<ol class="answer_list">
	<li> processing delays in the underlying file system(s).
	<li> the use of preemptive scheduling.
	<li> poor program design and coding.
	<li> improperly designed application programming interfaces (APIs).
	<li> None of the above
	</ol>
</li><br/>

<li> Insider attacks differ from attacks by outsiders in that the attacker has
	<ol class="answer_list">
	<li> superuser rights on the computer systems.
	<li> access to the environment.
	<li> unrestricted access to the network.
	<li> specific knowledge of the environment (both computer and human).
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is a type of insider attack?
	<ol class="answer_list">
	<li> Logic Bomb
	<li> Rootkit
	<li> Spoofing
	<li> Denial of Service
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is a type of insider attack?
	<ol class="answer_list">
	<li> Logic Bomb
	<li> Back Door
	<li> Worm
	<li> Denial of Service
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> true of a logic bomb?
	<ol class="answer_list">
	<li> They can be set to activate at a particular time or when an event
		happens (or fails to happen).
	<li> It is immediately obvious when a logic bomb has "exploded".
	<li> Bombs can remove files or change encryption/decryption keys.
	<li> They are nearly always installed after an employee has
		left the organization (usually for revenge).
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> true of a back door attack?
	<ol class="answer_list">
	<li> All back door attacks provide login access to the computer system
		or network.
	<li> Are crafted to allow privileged access to data or the computer
		system.
	<li> Some degree of special privilege or access is required to install
		a back door attack.
	<li> Back doors don't necessarily guarantee access, but may offer only
		a greater chance of gaining access.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> true of a spoofing attack?
	<ol class="answer_list">
	<li> Spoofing attacks require some degree of privileged access to data
		or the computer system.
	<li> Are based on mimicking an existing interface in order to trick
		users into providing secret information.
	<li> Spoofing attacks are the most difficult attack to defend against.
	<li> Are a specialized form of back door attacks.
	<li> None of the above
	</ol>
</li><br/>
<li> Phishing attacks are a special type of spoofing attack that
	<ol class="answer_list">
	<li> can have success rates as high as 70%.
	<li> depend upon specialized and confidential information in order to
		convince others to provide computer access.
	<li> leverage a back door to gain credibility, leveraging that trust
		into more elevated access.
	<li> use social engineering techniques to gain information that leads
		to computer and data access.
	<li> None of the above
	</ol>
</li><br/>
<li> Defending against insider attacks
	<ol class="answer_list">
	<li> uses exactly the same techniques as defending against outside
		attacks.
	<li> involves separation of duties so that one person doesn't have
		too much control.
	<li> often uses code reviews so that it is harder to sneak in an
		obvious weakness/attack.
	<li> benefit from keeping personnel in the same position for
		many years to reduce social engineering opportunities.
	<li> None of the above
	</ol>
</li><br/>

<li> The types of vectors for conducting an outside attack are
	<ol class="answer_list">
	<li> Worm
	<li> Smurfing
	<li> Trojan Horse
	<li> Virus
	<li> None of the above
	</ol>
</li><br/>
<li> Non-replicating malware that is embedded in a (usually) useful program
	is called a
	<ol class="answer_list">
	<li> Worm
	<li> Rootkit
	<li> Trojan Horse
	<li> Virus
	<li> None of the above
	</ol>
</li><br/>
<li> Malware that replicates and spreads by attaching itself to other programs
	is called a
	<ol class="answer_list">
	<li> Worm
	<li> Rootkit
	<li> Trojan Horse
	<li> Virus
	<li> None of the above
	</ol>
</li><br/>
<li> Malware in the form of a self-replicating standalone program is called a
	<ol class="answer_list">
	<li> Worm
	<li> Rootkit
	<li> Trojan Horse
	<li> Virus
	<li> None of the above
	</ol>
</li><br/>
<li> Which types of viruses generally try to hide themselves within the
	interrupt vector?
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Macro virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> Microkernels provide more protection than monolithic kernels against which
	type of virus?
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Macro virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of virus is perhaps the most dangerous to have a compiler
	infected with?
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Macro virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> A Macro virus is a special type of what kind of virus?
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> The virus that modifies the program that loads the OS and ultimately
	becomes memory-resident after the system is up and running, is a
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Macro virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> A virus that infects processes but <strong>not</strong> program files is a
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Macro virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> A virus that adds a copy of itself to an existing program, leaving the
	rest of the program untouched, is a
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Macro virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> A virus that replaces code in an existing program with new code is a
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Companion virus.
	<li> Overwriting virus.
	<li> Boot Sector virus.
	<li> Parasitic virus.
	<li> Device Driver virus.
	<li> Macro virus.
	<li> Source Code virus.
	<li> None of the above
	</ol>
</li><br/>
<li> Malware that is particularly effective in concealing its existence, that
	strongly resists removal, and provides superuser access to the system
	is a
	<ol class="answer_list">
	<li> Memory-Resident virus.
	<li> Parasitic virus.
	<li> Rootkit.
	<li> Boot Sector virus.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of malware doesn't directly impact or provide access to
	the infected system but has these characteristics:
	hides to avoid detection; collects info from the infected
	host; communicates collected info to a remote server; and
	is difficult to remove?
	<ol class="answer_list">
	<li> Rootkit
	<li> Spyware
	<li> Botnet
	<li> Smurfer
	<li> None of the above
	</ol>
</li><br/>
<li> A keylogger is an example of (a)
	<ol class="answer_list">
	<li> Rootkit.
	<li> Spyware.
	<li> Botnet.
	<li> Smurfer.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is the most common type of rootkit?
	<ol class="answer_list">
	<li> Application
	<li> Library
	<li> Hypervisor
	<li> Firmware
	<li> None of the above
	</ol>
</li><br/>
<li> Attempts to make a targeted system/network unusable by flooding it with
	service requests is called a
	<ol class="answer_list">
	<li> Network sniffing attack.
	<li> Worm Armageddon.
	<li> Denial of Service (DoS) attack.
	<li> Trojan stampede.
	<li> None of the above
	</ol>
</li><br/>
<li> When the requests for a Denial of Service (DoS) attack come from multiple
	sources, this is an example of
	<ol class="answer_list">
	<li> Snooping.
	<li> Network sniffing attack.
	<li> Worm Armageddon.
	<li> Trojan stampede.
	<li> None of the above
	</ol>
</li><br/>
<li> Smurfing is an example of a
	<ol class="answer_list">
	<li> Network sniffing attack.
	<li> Worm Armageddon.
	<li> Distributed Denial of Service (DDoS) attack.
	<li> Trojan stampede.
	<li> None of the above
	</ol>
</li><br/>
<li> A Distributed Denial of Service (DDoS) attack can be conducted by 
	<ol class="answer_list">
	<li> network sniffing from a single host.
	<li> having bots in a large botnet target a single system.
	<li> smurfing.
	<li> a trojan stampede.
	<li> None of the above
	</ol>
</li><br/>
<li> A Distributed Denial of Service attach that uses faked sender IP
	addresses (of the targeted system) on requests sent to a large set of
	unsuspecting intermediary systems is called
	<ol class="answer_list">
	<li> smurfing.
	<li> a trojan stampede.
	<li> network sniffing.
	<li> a botnet flood.
	<li> None of the above
	</ol>
</li><br/>
<li> Most systems today are <strong>not</strong> vulnerable to smurfing
	attacks because of these common measures:
	<ol class="answer_list">
	<li> do <strong>not</strong> respond to broadcast messages.
	<li> use in-bound filtering to prevent spoofing the source IP address.
	<li> do <strong>not</strong> forward broadcast messages.
	<li> only respond to messages from white-listed source IP addresses.
	<li> None of the above
	</ol>
</li><br/>
<li> Passively listening in on traffic, particularly on unencrypted wireless
	networks, using a packet analyzer is called
	<ol class="answer_list">
	<li> smurfing.
	<li> keylogging.
	<li> sporking.
	<li> network sniffing.
	<li> None of the above
	</ol>
</li><br/>
<li> The risk of a successful communication attack can be greatly reduced
	by using
	<ol class="answer_list">
	<li> digital signatures.
	<li> one-way hash functions.
	<li> symmetric-key encryption between systems (e.g., SSL).
	<li> free public (and anonymous) WiFi services.
	<li> None of the above
	</ol>
</li><br/>
<li> If Mallory conducts a man-in-the-middle attack on the communications
	between Alice and Bob, Mallory's existence will likely go unnoticed
	for the longest period of time if
	<ol class="answer_list">
	<li> Alice and Bob use a variety of communication methods.
	<li> either Alice or Bob (but <strong>not</strong> both) digitally
		signs their communications.
	<li> Mallory is able to intercept <strong>all</strong> of the traffic
		coming from either Alice or Bob (but <strong>not</strong> both).
	<li> Mallory intercepts <strong>all</strong> traffic/messages between
		Alice and Bob. 
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following <strong>ensures</strong> confidentiality when
	using public WiFi services?
	<ol class="answer_list">
	<li> Only use those that have a password, often issued when a
		purchase is made (e.g., Starbucks).
	<li> Make sure that the majority of web communications are
		conducted using https (e.g., http with Secure Sockets Layer
		encryption).
	<li> Disconnect and reconnect to the network every 15 minutes or less.
	<li> Run your own network sniffer to see if anyone else is snooping
		on the WiFi communications.
	<li> None of the above
	</ol>
</li><br/>

<li> Using multiple layers of defenses, so that if one layer is breached there
	are others behind it to prevent the attack from progressing, is
	known as
	<ol class="answer_list">
	<li> layered defense.
	<li> defense in depth.
	<li> castle walls.
	<li> ringed fortifications.
	<li> None of the above
	</ol>
</li><br/>
<li> Requiring approval for software installation or changes to the Windows
	registry, and informing the user of outbound communications are
	examples of what type of security defense?
	<ol class="answer_list">
	<li> Informed consent
	<li> Administrator authorization
	<li> User/Administrator confirmation
	<li> Permissioned protection
	<li> None of the above
	</ol>
</li><br/>
<li> The weakness of user confirmation as a means of defense is that
	<ol class="answer_list">
	<li> users may not know enough to determine the appropriate action to
		take.
	<li> users seldom have the necessary system permissions to accomplish
		the desired action.
	<li> pop-up confirmation screens are so common in software that most
		users turn them off.
	<li> they annoy users, who after answer randomly after reading the
		information note.
	<li> None of the above
	</ol>
</li><br/>
<li> As a security defense layer, firewalls are used to
	<ol class="answer_list">
	<li> transform message traffic so that its contents are guaranteed
		to be safe.
	<li> route inbound network message traffic to the correct computer
		system.
	<li> convert messages from one network protocol into another so as
		to avoid errors caused by using the wrong protocol on a
		network segment.
	<li> serve as gatekeepers, determining which messages are passed
		along (both into and out of the system/network).
	<li> None of the above
	</ol>
</li><br/>
<li> Data Loss Prevention (DLP) examines the contents of outbound message
	packets to ensure that
	<ol class="answer_list">
	<li> no unencrypted personal identifying or financial information is
		sent out.
	<li> <strong>all</strong> data in the packet
		(except header information) is encrypted.
	<li> only data sent by authorized users is sent out.
	<li> no corporate trade secrets or intellectual property is
		inadvertently sent out.
	<li> None of the above
	</ol>
</li><br/>
<li> What type of firewall inspects the full contents of messages
	(<strong>not</strong> just their header information) in determining
	whether or not to ACCEPT or DENY message packets?
	<ol class="answer_list">
	<li> Standalone firewall
	<li> Stateless firewall
	<li> Stateful firewall
	<li> Intrusion Detection System (IDS)
	<li> None of the above
	</ol>
</li><br/>
<li> What type of firewall uses information from previous messages in addition
	to the current message in determining whether or not
	to ACCEPT or DENY the current message?
	<ol class="answer_list">
	<li> Standalone firewall
	<li> Stateless firewall
	<li> Stateful firewall
	<li> Intrusion Detection System (IDS)
	<li> None of the above
	</ol>
</li><br/>
<li> What type of firewall only uses the information within the message
	packet for making decisions about whether or not to ACCEPT or
	DENY the message?
	<ol class="answer_list">
	<li> Standalone firewall
	<li> Stateless firewall
	<li> Stateful firewall
	<li> Intrusion Detection System (IDS)
	<li> None of the above
	</ol>
</li><br/>
<li> Anti-virus scanners identify files potentially infected by a virus.
	Which of the following limit the utility of this approach to
	securing a system?
	<ol class="answer_list">
	<li> Polymorphic viruses change their code when infecting new files
		to avoid detection.
	<li> False positive matches can cause users to delete uninfected files.
	<li> False negative matches give users a false sense of security,
		enabling the virus to continue replicating.
	<li> Signatures for a zero-day virus are <strong>not</strong>
		in the scanner's database, and thus cannot be detected.
	<li> None of the above
	</ol>
</li><br/>
<li> Calculating the hash value of every file in a system known
	<strong>not</strong> to be infected with any viruses and keeping them
	for later comparison, is the basis for what anti-virus technique?
	<ol class="answer_list">
	<li> Jailers
	<li> Code Signers
	<li> Behavioral Checkers
	<li> Integrity Checkers
	<li> None of the above
	</ol>
</li><br/>
<li> For integrity checking to be effective in detecting the existence of virus
	infected files, the hash values it creates <strong>must</strong> be
	<ol class="answer_list">
	<li> periodically recalculated and compared to the original stored
		values.
	<li> calculated on infected files.
	<li> kept in a secure location (or digitally signed) so that they
		cannot be altered (<strong>without</strong> detection).
	<li> created using the running process if the file is a program.
	<li> None of the above
	</ol>
</li><br/>
<li> Examining the actions of processes to catch questionable behavior,
	is used by which anti-virus technique?
	<ol class="answer_list">
	<li> Code Signers
	<li> Behavioral Checkers
	<li> Integrity Checkers
	<li> Sandboxing
	<li> None of the above
	</ol>
</li><br/>
<li> The difficulty in distinguishing legitimate actions from actions due
	to malware reduces the effectiveness of which anti-virus technique?
	<ol class="answer_list">
	<li> Code Signers
	<li> Behavioral Checkers
	<li> Integrity Checkers
	<li> Sandboxing
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are good ways to <em>avoid</em> infection by a
	virus?
	<ol class="answer_list">
	<li> Only install software from reputable sources.
	<li> Run regular anti-virus scans of the file system.
	<li> Configure a personal firewall to only ACCEPT messages in
		response to out-going requests.
	<li> Keep frequent (and multiple version/generation) file backups.
	<li> Avoid opening email attachments that haven't passed a virus
		scan.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are good ways to <em>limit</em> the damage done
	by a virus infection should one occur?
	<ol class="answer_list">
	<li> Only install software from reputable sources.
	<li> Use a microkernel OS with the remaining non-kernel software
		running with non-superuser privileges.
	<li> Avoid opening email attachments that haven't passed a virus
		scan.
	<li> Keep frequent (and multiple version/generation) file backups.
	<li> None of the above
	</ol>
</li><br/>
<li> To ensure that downloaded software has been unchanged and is what it
	claims to be and really comes from the indicated source, use
	<ol class="answer_list">
	<li> Digital Signatures (aka Code Signing).
	<li> a white-list of reputable web URLs from which to download software.
	<li> a black-list of web URLs to avoid.
	<li> Jailing.
	<li> None of the above
	</ol>
</li><br/>
<li> When (new) software is run within a container and <strong>all</strong>
	system calls are passed through an examiner that determines whether
	or not to pass the call along to the kernel or abort the running
	program (as a hazard and probable malware), this is an example of
	<ol class="answer_list">
	<li> Jailing.
	<li> Sandboxing.
	<li> Smurfing.
	<li> Code Signing.
	<li> None of the above
	</ol>
</li><br/>
<li> Running new software within its own virtual machine (until the software
	is fully trusted) is an example of
	<ol class="answer_list">
	<li> Jailing.
	<li> Sandboxing.
	<li> Quarantining.
	<li> Code Signing.
	<li> None of the above
	</ol>
</li><br/>
<li> When a program is limited to a range of addresses within its address
	space as holding executable code, with data residing in another
	limited range of addresses in the address space, and no code or
	data outside the address space can be used, this is called
	<ol class="answer_list">
	<li> Jailing.
	<li> Sandboxing.
	<li> Quarantining.
	<li> Segregation.
	<li> None of the above
	</ol>
</li><br/>
<li> Java applets use which techniques to ensure safe execution?
	<ol class="answer_list">
	<li> Sandboxing.
	<li> Segregation.
	<li> Compilation.
	<li> Interpretation.
	<li> None of the above
	</ol>
</li><br/>
<li> Some of the actions performed by an interpreter to improve the safety
	of execution (e.g., passing resource requests to a security manager)
	are similar to those used in
	<ol class="answer_list">
	<li> Jailing.
	<li> Sandboxing.
	<li> Quarantining.
	<li> Segregation.
	<li> None of the above
	</ol>
</li><br/>

</ol>

<hr/>
<em>
<a href="mailto:eckart_dana@columbusstate.edu?subject=web_pages" style="float: left">eckart_dana@columbusstate.edu</a>
<a href="/eckart/classes/cpsc3125" style="float: right">CPSC 3125</a>
</em>

</body>
</html>

