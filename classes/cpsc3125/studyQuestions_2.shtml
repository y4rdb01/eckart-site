<!doctype HTML public "-//W3C//DTD HTML 3.2//EN">
<html lang="en">
<head>
<title>Dr. J Dana Eckart</title>
<link rev="mail" href="mailto:eckart_dana@columbusstate.edu">
</head>
<body>

<!--
	This is the primary overall style for the web site.
-->
<style>
	A:link    { color: #007a00; text-decoration: underline }
	A:visited { color: #7a0000; text-decoration: none }
	A:hover   { text-decoration: none }
	A:active  { color: #ff0000; text-decoration: none }
	Body	{ background-color: #ffffe5; color: #000000 }
	Body	{ font-size: 12pt }
	Address	{ font-size: 10pt }
	Table	{ font-size: 12pt }
	Th, Td	{ vertical-align: top }
	Th, Td	{ padding: 5px }
</style>

<p style="text-align: center; margin: auto; font-size: 150%">
	<strong>Dr. J Dana Eckart</strong>: Operating Systems (CPSC 3125)
	- Study Questions for Test #2
</p>

<style type="text/css">
	ol.question_list {list-style-type: none;}
	ol.question_list li:before {content: counter(question, decimal) ") ";}
	ol.question_list li { counter-increment: question;}

	ol.answer_list {list-style-type: none;}
	ol.answer_list li:before {content: counter(answer, lower-latin) ") ";}
	ol.answer_list li { counter-increment: answer;}

	ol.match_list {list-style-type: none;}
	ol.match_list li:before {content: counter(match, upper-latin) ") ";}
	ol.match_list li { counter-increment: match;}

	ul.bullet_list {list-style-type: disc;}
	ul.bullet_list li:before {content: "";}
	ul.bullet_list li { counter-increment: bogus;}
</style>

<p>
The following list of exam study questions are provided as a means to help you
assess your understanding of the topics presented in class. While every
reasonable attempt has been made to create a comprehensive list of questions,
they should <strong>not</strong> be the only means by which you assess your
own understanding of the course materials. While many of these questions
may appear on your exam, be aware that the exam may include questions
that do not appear below. However, it is unlikely you will perform well on
the exam if you have difficulty answering these questions correctly.
</p>


<ol class="question_list">
<li> The technique that allows data that flows from one "program piece" to
	the next "program piece" to remain in memory is known as
	<ol class="answer_list">
	<li> overflows.
	<li> overlays.
	<li> piecewise communication.
	<li> memory mapping.
	<li> None of the above
	</ol>
</li><br/>
<li> When the OS automatically breaks a process into multiple pieces of the
	same size, thus enabling processes otherwise too large to run within
	a smaller amount of memory, this is called
	<ol class="answer_list">
	<li> overlays.
	<li> memory mapping.
	<li> break out.
	<li> virtual memory.
	<li> None of the above
	</ol>
</li><br/>
<li> What is the most common virtual memory technique?
	<ol class="answer_list">
	<li> Overlays
	<li> Paging
	<li> Memory Mapping.
	<li> Swapping.
	<li> None of the above
	</ol>
</li><br/>
<li> The virtual address space of a process is
	<ol class="answer_list">
	<li> composed of those parts of main memory (e.g., RAM) holding
		parts of the process (e.g., code, run-time stack).
	<li> exactly the same size as the main memory (e.g., RAM) of the
		computer system.
	<li> larger than the maximum number of addressable bytes (e.g.,
		more than 2^32 bytes on a 32 bit architecture).
	<li> the address space the process would exist in if main memory
		(e.g., RAM) were big enough to hold the process, and the
		process was loaded into memory starting at address 0.
	<li> None of the above
	</ol>
</li><br/>
<li> Page frames are the
	<ol class="answer_list">
	<li> blocks in physical memory that hold virtual address space pages.
	<li> uniformly sized chunks that the virtual address space is divided
		into.
	<li> disk blocks that hold the virtual address space pages.
	<li> entries in the Memory Management Unit (MMU) that indicate which
		virtual address space page holds a desired address.
	<li> None of the above
	</ol>
</li><br/>
<li> What part of the computer system is responsible for converting a virtual
	address into a physical memory address?
	<ol class="answer_list">
	<li> Virtual Address Translation (VAT)
	<li> Memory Management Unit (MMU)
	<li> Arithmetic Logic Unit (ALU)
	<li> System Bus
	<li> None of the above
	</ol>
</li><br/>
<li> The standard implementation for a page (map) table of a process has an
	entry for each
	<ol class="answer_list">
	<li> page in the process' virtual address space.
	<li> page frame in physical (main) memory.
	<li> and only those virtual address space pages currently residing in
		a page frame.
	<li> and only those virtual address space pages currently
		<strong>not</strong> residing in a page frame.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> part of the page (map)
	table entries?
	<ol class="answer_list">
	<li> Referenced bit
	<li> Modified bit
	<li> Present/Absent bit
	<li> Page Frame number
	<li> None of the above
	</ol>
</li><br/>
<li> The higher order bits of a big-endian virtual address normally
	<ol class="answer_list">
	<li> are used as the index into the page table when translating
		a virtual address into a physical address.
	<li> represent the page in the virtual address space.
	<li> indicates which page frame the virtual address resides in.
	<li> provide the offset into the page frame for the virtual address.
	<li> None of the above
	</ol>
</li><br/>
<li> The lower order bits of a big-endian virtual address normally
	<ol class="answer_list">
	<li> are used as the index into the page table when translating
		a virtual address into a physical address.
	<li> represent the page in the virtual address space.
	<li> indicates which page frame the virtual address resides in.
	<li> provide the offset into the page frame for the virtual address.
	<li> None of the above
	</ol>
</li><br/>
<li> The page size for paged virtual memory is <strong>always</strong> a
	power of 2 because
	<ol class="answer_list">
	<li> it allows a fixed number of bits of the virtual address to be used
		as the page offset.
	<li> that's the convention often used when using binary computers.
	<li> adding the page offset to the page frame base can be done more
		quickly using "bit-wise or" rather than addition. 
	<li> the arrays (used to implement page tables) <strong>must</strong>
		have a power of 2 size.
	<li> None of the above
	</ol>
</li><br/>
<li> If, during virtual address translation, the entry in the page table for
	the virtual address has a 0 for the "present" bit, then 
	<ol class="answer_list">
	<li> the 0 page frame is used in calculating the physical address.
	<li> a page fault is generated.
	<li> the "present" bit is set to 1.
	<li> the "modified" bit is set to 1.
	<li> None of the above
	</ol>
</li><br/>
<li> The page table associated with a process is used when
	<ol class="answer_list">
	<li> the process transitions from the blocked to the ready state.
	<li> the next instruction in the process <strong>must</strong> be
		loaded.
	<li> a global page replacement algorithm is determining which page
		frame to reuse.
	<li> a value is stored into a variable (in memory).
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> normally part of the
	page table entry?
	<ol class="answer_list">
	<li> Caching disabled flag
	<li> Referenced bit
	<li> Modified bit
	<li> Present/Absent bit
	<li> Protection bit(s)
	<li> Page frame number
	<li> None of the above
	</ol>
</li><br/>
<li> Virtual address translation <strong>must</strong> be <em>very</em> fast
	since it
	<ol class="answer_list">
	<li> can happen many times for every instruction, depending upon the
		machine instructions provided by that computer system.
	<li> prevents the CPU from doing any other work while it is happening.
	<li> happens at least once for every instruction (to retrieve it).
	<li> ties up the system bus while it is happening.
	<li> None of the above
	</ol>
</li><br/>
<li> Assuming that page sizes remain the same, as virtual memories get bigger,
	so does the size of the
	<ol class="answer_list">
	<li> process table.
	<li> page frames.
	<li> page table.
	<li> Memory Management Unit (MMU).
	<li> None of the above
	</ol>
</li><br/>
<li> The Translation Lookaside Buffer (TLB) is part of the
	<ol class="answer_list">
	<li> System Bus.
	<li> Memory Management Unit (MMU).
	<li> Page Table.
	<li> Arithmetic Logic Unit (ALU).
	<li> None of the above
	</ol>
</li><br/>
<li> The Translation Lookaside Buffer (TLB) holds
	<ol class="answer_list">
	<li> the entire page table for a process.
	<li> many of the most recent virtual address translation results
		(since they're likely to be seen again - e.g., loops).
	<li> the process table entries for processes in the ready state.
	<li> a small number of (recently used) page table entries.
	<li> None of the above
	</ol>
</li><br/>
<li> Entries in the Translation Lookaside Buffer (TLB) <strong>must</strong>
	add this item as a field since it cannot be used as an index.
	<ol class="answer_list">
	<li> Page frame number.
	<li> Virtual address page number.
	<li> Present/absent bit.
	<li> Page offset.
	<li> None of the above
	</ol>
</li><br/>
<li> Finding the desired entry in a Translation Lookaside Buffer (TLB)
	<strong>must</strong> be very fast, so this is done by using a(n)
	<ol class="answer_list">
	<li> linear search.
	<li> binary search.
	<li> hash table.
	<li> associative memory.
	<li> None of the above
	</ol>
</li><br/>
<li> If a virtual address doesn't correspond to one of the rows in the
	Translation Lookaside Buffer (TLB), then
	<ol class="answer_list">
	<li> a page fault is generated.
	<li> the MMU updates the TLB immediately.
	<li> the TLB is purged and reloaded.
	<li> a lookup is performed using the full page table.
	<li> None of the above
	</ol>
</li><br/>
<li> If a Translation Lookaside Buffer (TLB) is larger, it can be effectively
	managed by software instead of by the Memory Management Unit (MMU).
	If a page entry is <strong>not</strong> in the TLB, but is in memory,
	this is called a
	<ol class="answer_list">
	<li> cache miss.
	<li> soft miss.
	<li> hard miss.
	<li> page entry fault.
	<li> None of the above
	</ol>
</li><br/>
<li> If a Translation Lookaside Buffer (TLB) is larger, it can be effectively
	managed by software instead of by the Memory Management Unit (MMU).
	If a page entry is <strong>not</strong> in the TLB, and is also
	<strong>not</strong> in memory, this is called a
	<ol class="answer_list">
	<li> cache miss.
	<li> soft miss.
	<li> hard miss.
	<li> page entry fault.
	<li> None of the above
	</ol>
</li><br/>
<li> As the size of the virtual address space increases, so to does the
	size of the page table (provided page size remains the same). 
	Techniques for dealing with very large page tables include
	<ol class="answer_list">
	<li> Multi-level Page Tables.
	<li> Hashed Page Tables.
	<li> Memory Mapped Page Tables.
	<li> Inverted Page Tables.
	<li> None of the above
	</ol>
</li><br/>
<li> Multi-level Page Tables divide the page table up into segments based on
	<ol class="answer_list">
	<li> which pages of the page table are referenced most frequently,
		reducing the number of page entries which need to be kept in
		memory.
	<li> how many processes are in the process table.
	<li> the higher order bits that index the page table (e.g., the top
		10 bits of the 32 bit virtual address indicates which group
		of 1024 pages to use - for 4K sized pages).
	<li> the size of a software managed Translation Lookaside Buffer (TLB),
		with each segment reflecting the TLB size.
	<li> None of the above
	</ol>
</li><br/>
<li> Instead of keeping a page table for each process, Inverted Page Tables
	have an entry for each
	<ol class="answer_list">
	<li> process, keeping track of which page frames are being used by
		that process.
	<li> virtual page, keeping track of which process the virtual page
		belongs to.
	<li> page frame, keeping track of which virtual page from which
		process is loaded in the corresponding page frame.
	<li> virtual page and process pairing, keeping track of which page
		frame corresponds to the pairing.
	<li> None of the above
	</ol>
</li><br/>
<li> In order to speed access to an Inverted Page Table, while still
	conserving space, they are often implemented using
	<ol class="answer_list">
	<li> content addressable memories.
	<li> hash tables.
	<li> 2 dimensional arrays.
	<li> balance B-trees.
	<li> None of the above
	</ol>
</li><br/>

<li> After <strong>all</strong> page frames in a system are occupied,
	page replacement in a virtual memory system is the process
	<ol class="answer_list">
	<li> of choosing a virtual page to load into a given page frame.
	<li> of choosing both a virtual page and a page frame in which to
		load the chosen virtual page.
	<li> of choosing a page frame and loading a given virtual page into that
		page frame.
	<li> that's performed in response to a page fault.
	<li> None of the above
	</ol>
</li><br/>
<li> The essentially unobtainable aspect of optimal page replacement which sets
	it apart from <strong>all</strong> other page replacement algorithms is
	<ol class="answer_list">
	<li> only loading virtual pages that will be used immediately (or in
		the very near future).
	<li> ensuring that no process ever thrashes.
	<li> ensuring that no page frame is replaced before
		<strong>all</strong> other frames have already been replaced.
	<li> only replacing page frames whose resident virtual page wont be
		used for the longest period of time.
	<li> None of the above
	</ol>
</li><br/>
<li> Nearly <strong>all</strong> page replacement algorithms make use of the
	following flag(s) which are associated with each page frame:
	<ol class="answer_list">
	<li> reference bit
	<li> cached bit
	<li> present bit
	<li> modified bit
	<li> None of the above
	</ol>
</li><br/>
<li> The reference bit associated with a page frame is set to
	<ol class="answer_list">
	<li> 0 whenever a virtual page is loaded into the frame. 
	<li> 0 only the first time a virtual page is loaded from the
		virtual address space.
	<li> 1 whenever a virtual page is loaded into a new page frame.
	<li> 1 whenever the page frame contents are changed.
	<li> None of the above
	</ol>
</li><br/>
<li> The modified bit associated with a page frame is set to
	<ol class="answer_list">
	<li> 0 whenever a virtual page is loaded into the frame. 
	<li> 0 only the first time a virtual page is loaded from the
		virtual address space.
	<li> 1 whenever a virtual page is loaded into a new page frame.
	<li> 1 whenever the page frame contents are changed.
	<li> None of the above
	</ol>
</li><br/>
<li> The Not-Recently-Used (NRU) page replacement algorithm replaces pages
	based on the values of their reference and modified bits. What is
	the preference ordering (most prefered replacement listed first) given
	the following combinations?
<pre>
	1 -> referenced, <strong>not</strong> modified
	2 -> <strong>not</strong> referenced, <strong>not</strong> modified
	3 -> referenced, modified
	4 -> <strong>not</strong> referenced, modified
</pre>
	<ol class="answer_list">
	<li> 1, 2, 3, 4
	<li> 2, 4, 1, 3
	<li> 3, 1, 2, 4
	<li> 4, 3, 2, 1
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm <strong>always</strong> replaces the
	oldest page, regardless of the value of the referenced and modified
	bits, is
	<ol class="answer_list">
	<li> First-in First-out Page Replacement
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm is the easiest to implement and often
	performs adequately?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Not Frequently Used (NFU) Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm is a variation of First-in First-out
	page replacement that uses the reference (R) bit. If the page frame
	being considered has R = 0, the page is replaced. Otherwise, if R = 1,
	then R is set to 0 and the page frame is put at the end of the queue
	to be considered again later.
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm cycles through the set of page frames
	in order (starting after where it left off last time) looking for one
	with R = 0, which it replaces when found. If R = 1, then R is set to
	0 and the next page frame is considered (until a suitable one is found).
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> A disadvantage of both Second-Chance and Clock page replacement algorithms
	is that
	<ol class="answer_list">
	<li> they can immediately (re)load the exact same virtual page already
		in the page frame.
	<li> modified pages are given preference for replacement.
	<li> if <strong>all</strong> reference bits = 1, then the entire
		"queue" <strong>must</strong> be iterated
		through before a replacement page will be found.
	<li> if <strong>all</strong> modified bits = 1, then the entire "queue"
		<strong>must</strong> be iterated
		through before a replacement page will be found.
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm replaces the page that has gone unused
	for the longest period of time?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm can make effective use of a counter
	associated with each page frame, with the counter value set to the
	global clock tick counter each time the page is referenced?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Clock Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm adds the value of the page frame's R bit
	to a counter for that page frame, each time <strong>all</strong>
	of the R bits are reset? The counter is reset to 0 whenever a new page
	is loaded into the frame.
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Least Recently Used (LRU) Page Replacement
	<li> Not Frequently Used (NFU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm can end up replacing useful pages (e.g.,
	very recently used) instead of pages that haven't been used for a long
	time?
	<ol class="answer_list">
	<li> Second-Chance Page Replacement
	<li> Clock Page Replacement
	<li> Not Recently Used (NRU) Page Replacement
	<li> Not Frequently Used (NFU) Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithm improves upon the primary deficiency of
	the Not Frequently Used (NFU) page replacement algorithm?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Not Recently Used (NRU) Page Replacement
	<li> Least Recently Used (NRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which algorithm is similar to the Not Frequently Used (NFU) page
        replacement algorithm, but instead of simply adding the R bit to the
        page frame counter, it shifts the counter 1 bit to the right before
        the leftmost bit is set to the R value?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Not Recently Used (NRU) Page Replacement
	<li> Least Recently Used (NRU) Page Replacement
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Paging algorithms that only load virtual pages that are the cause of a
	page fault are categorized as
	<ol class="answer_list">
	<li> lazy paging.
	<li> eager paging.
	<li> laissez faire paging.
	<li> demand paging.
	<li> None of the above
	</ol>
</li><br/>
<li> Locality of reference is a property exhibited by most programs in which
	<ol class="answer_list">
	<li> nearly <strong>all</strong> the variables are declared within
		functions rather than as global/static variables.
	<li> the vast majority of program statements are some type of loop.
	<li> the parts of the virtual address space needed are usually close
		to those most recently used. 
	<li> only a small part of the virtual address space of a process is
		ever loaded into a page frame.
	<li> None of the above
	</ol>
</li><br/>
<li> The set of virtual pages that a process is currently using are known
	as the
	<ol class="answer_list">
	<li> loaded pages.
	<li> process set.
	<li> working set.
	<li> recency list.
	<li> None of the above
	</ol>
</li><br/>
<li> Which category of page replacement algorithms tries to reduce the page
	fault rate by <em>prepaging</em>?
	<ol class="answer_list">
	<li> Working set model
	<li> Global allocation
	<li> Local allocation
	<li> Process model
	<li> None of the above
	</ol>
</li><br/>
<li> Thrashing occurs in a multi-tasking system when by the next time a process
	is chosen to run in the CPU
	<ol class="answer_list">
	<li> it's already been blocked by another process.
	<li> it's been terminated by the OS kernel.
	<li> most of its needed virtual pages are <strong>not</strong>
		in page frames.
	<li> most of its needed virtual pages are already loaded in page frames.
	<li> None of the above
	</ol>
</li><br/>
<li> Thrashing is almost certain to occur when
	<ol class="answer_list">
	<li> the size of working sets for <strong>all</strong> processes
		varies greatly from one another.
	<li> the combined working sets of <strong>all</strong> runnable
		processes excedes the size of physical memory.
	<li> the Translation Lookaside Buffer is smaller than largest process
		working set.
	<li> there are more processes than will fit in the process table.
	<li> None of the above
	</ol>
</li><br/>
<li> The amount of time that a process has spent running in the CPU since
	the process started is known as its
	<ol class="answer_list">
	<li> CPU time.
	<li> process time.
	<li> processor virtual time.
	<li> current virtual time.
	<li> None of the above
	</ol>
</li><br/>
<li> The working set of a process is the list of virtual pages the process
	has used
	<ol class="answer_list">
	<li> within the last T seconds of its current virtual time.
	<li> since the process started.
	<li> since the process started or since the last time process was
		blocked (whichever is most recent).
	<li> since it last generated a page fault.
	<li> None of the above
	</ol>
</li><br/>
<li> Which page replacement algorithms introduce an additional field for page
	table entries that holds the last (virtual) time of use for that
	virtual page?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Aging Page Replacement
	<li> Working Set Model Page Replacement
	<li> Working Set Clock Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> For Working Set Model Page Replacement, the virtual page in a page
	frame is evicted if the reference (R) bit
	<ol class="answer_list">
	<li> = 1 and the current virtual time minus the time of last use is
		greater than a predetermined cutoff.
	<li> = 0 (regardless of the time of last use).
	<li> = 0 and the modified bit = 0 (regardless of the time of last use).
	<li> = 0 and the current virtual time minus the time of last use is
		greater than a predetermined cutoff.
	<li> None of the above
	</ol>
</li><br/>
<li> For Working Set Model Page Replacement, the virtual page in a page
	frame is evicted if the reference (R) bit
	<ol class="answer_list">
	<li> = 0, <strong>all</strong> virtual pages in page frames have been
		referenced within the predetermined cutoff, but this page
		has been referenced least recently.
	<li> = 0, <strong>all</strong> virtual pages in page frames have been
		referenced within the predetermined cutoff, but this page has
		been modified.
	<li> = 0 (regardless of the time of last use).
	<li> = 0 and the modified bit = 0 (regardless of the time of last use).
	<li> None of the above
	</ol>
</li><br/>
<li> The major disadvantage of Working Set Model Page Replacement is that it
	requires
	<ol class="answer_list">
	<li> an additional field for the page table entries (to
		hold the time of last use).
	<li> maintaining the current virtual time of each process.
	<li> each page table entry to be examined (to determine if the page
		is in a page frame and if so what its time of last use is).
	<li> the page entry be updated for <em>every</em> access to the page.
	<li> None of the above
	</ol>
</li><br/>
<li> Working Set Clock Page Replacement addresses the short-coming(s) of
	Working Set Model Page Replacement by
	<ol class="answer_list">
	<li> associating the time of last use with the page frame, rather than
		the page table entries.
	<li> only setting the time of use when that page frame is being
		considered for reuse, rather than every time a page fault
		occurs.
	<li> considering each page frame in a "round robin" fashion, rather 
		than looking for virtual pages that have been in a page
		frame for a sufficiently long period of time.
	<li> using the modified (M) bit in deciding whether to immediately
		reuse the page frame or not, rather than ignoring the M bit
		value.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following page replacement algorithms is widely used in
	practice due to its relatively simple implementation and good
	performance?
	<ol class="answer_list">
	<li> Not Recently Used (NRU) Page Replacement
	<li> Clock Page Replacement
	<li> Working Set Clock Page Replacement.
	<li> Aging Page Replacement
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following page replacement algorithms schedules a modified
	page frame to be written back to disk <em>in advance</em> of evicting
	the virtual page from the page frame?
	<ol class="answer_list">
	<li> Clock Page Replacement
	<li> Aging Page Replacement
	<li> Working Set Model Page Replacement.
	<li> Working Set Clock Page Replacement.
	<li> None of the above
	</ol>
</li><br/>

<li> A global allocation policy, with respect to page replacement, is one in
	which the page frames considered for eviction are associated with
	<ol class="answer_list">
	<li> the process that generated the page fault.
	<li> most (generally all) processes.
	<li> only those processes in the ready state.
	<li> the process that generated the page fault along with
		<strong>all</strong> of its child processes.
	<li> None of the above
	</ol>
</li><br/>
<li> An advantage that a global allocation policy (GAP) generally has over
	a local allocation policy (LAP) is that
	<ol class="answer_list">
	<li> GAP increases the likelihood of thrashing.
	<li> LAP increases the likelihood of thrashing.
	<li> LAP can easily increase/decrease the number of virtual pages in
		physical memory for a process.
	<li> GAP can easily increase/decrease the number of virtual pages in
		physical memory for a process.
	<li> None of the above
	</ol>
</li><br/>
<li> A global allocation policy can cause thrashing if
	<ol class="answer_list">
	<li> the combined virtual address space of <strong>all</strong>
		processes is 10x larger than physical memory.
	<li> the pages for a process are nearly always modified.
	<li> a process' pages are evicted by the time it acquires the CPU.
	<li> demand paging is also used.
	<li> None of the above
	</ol>
</li><br/>
<li> A local allocation policy can cause thrashing if
	<ol class="answer_list">
	<li> the combined virtual address space of <strong>all</strong>
		processes is 10x larger than physical memory.
	<li> the pages for a process are nearly always modified.
	<li> demand paging is also used.
	<li> a process' working set is too small.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following is <strong>not</strong> a way to effectively
	deal with thrashing while the computer is running?
	<ol class="answer_list">
	<li> Swapping a process out to disk and giving its page frames
		to one or more of the processes left.
	<li> Add additional physical memory to the computer system.
	<li> Temporarily "block" the creation of any new processes if the
		combined working sets of existing processes is close to
		or exceeds the size of physical memory.
	<li> Increase the working set of <strong>all</strong> processes to
		ensure the virtual pages they need will be in page frames
		when the process gets the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> On average, the last page of a "segment" containing code or data will
	be half full. This is a reason to choose
	<ol class="answer_list">
	<li> smaller page sizes.
	<li> larger page sizes.
	<li> page sizes that are <strong>always</strong> a power of 2.
	<li> half sized pages (so the last one will be closer to full).
	<li> None of the above
	</ol>
</li><br/>
<li> Because the page table grows as the number of pages grows, this is a
	reason to use
	<ol class="answer_list">
	<li> smaller page sizes.
	<li> larger page sizes.
	<li> any page size since the page table size doesn't matter.
	<li> None of the above
	</ol>
</li><br/>
<li> Although the 4KB page size remains the most commonly used page size,
	IEEE published results suggest that a more appropriate page size
	would be
	<ol class="answer_list">
	<li> 2KB
	<li> 8KB
	<li> 16KB
	<li> 32KB
	<li> None of the above
	</ol>
</li><br/>
<li> While large 32 and 64 bit virtual address spaces make this less
	necessary, having separate address spaces for code and data can
	still be useful
	<ol class="answer_list">
	<li> for page replacement, so that only virtual pages containing data
		could be loaded into a page frame already holding data (and
		similarly for code/instructions).
	<li> to reduce the working set size of processes.
	<li> to prevent thrashing.
	<li> for parts of the memory hierarch (e.g., caches) which are small
		in size.
	<li> None of the above
	</ol>
</li><br/>
<li> Apart from interprocess communication, it's possible for different
	processes to share the same memory page (i.e., page frame) if
	<ol class="answer_list">
	<li> the page is read only.
	<li> any attempted modification to the page causes a copy to be made
		(and modified) for the writing process.
	<li> the pages are part of a shared library.
	<li> when one of the sharing processes is swapped out (or finishes)
		that the shared pages aren't also evicted.
	<li> None of the above
	</ol>
</li><br/>
<li> When a change to a shared page causes a copy of the page to
	first be made, and then the change made to the copy, this is called
	<ol class="answer_list">
	<li> write through.
	<li> copy on write.
	<li> writable copying.
	<li> page duping.
	<li> None of the above
	</ol>
</li><br/>
<li> Compared to statically linked executables, shared libraries
	<ol class="answer_list">
	<li> decreases the demands on physical memory, allowing more
		processes to execute.
	<li> enable programs to use updated libraries <strong>without</strong>
		being recompiled.
	<li> often reduce the size of executable programs.
	<li> reduce the chance of thrashing.
	<li> None of the above
	</ol>
</li><br/>
<li> Shared libraries and shared memory pages are
	<ol class="answer_list">
	<li> related because the code corresponding to a shared library is
		often held in a shared memory page.
	<li> interdependent since shared memory pages only exist for
		implementing shared libraries.
	<li> completely different since the code for shared libraries is
		statically linked to each program separately at compile time
		while shared memory pages are assigned at run-time.
	<li> there is no relationship except that both can be shared by
		multiple processes.
	<li> None of the above
	</ol>
</li><br/>
<li> <em>Position independent-code</em> is used to solve the problem of using
	absolute addressing for shared libraries since
	<ol class="answer_list">
	<li> different processes could load the shared library at different
		locations in their virtual address spaces.
	<li> base offset addressing cannot be used because the offsets will
		be different for each process.
	<li> the page table entries of the sharing processes may each point to
		different page frames.
	<li> the combined size of the libraries and program code could be
		larger than physical memory.
	<li> None of the above
	</ol>
</li><br/>
<li> <em>Mapped files</em> enable processes to work with files as if they
	were large character arrays by 
	<ol class="answer_list">
	<li> copying the file contents to shared memory page frames.
	<li> redirecting the file contents as input to the process.
	<li> mapping the file to the virtual address space for the process.
	<li> using pipes to stream the data from the file to the process.
	<li> None of the above
	</ol>
</li><br/>
<li> Having multiple processes share the same mapped file, enables
	<ol class="answer_list">
	<li> the file to be larger than it would if only mapped by a single
		process.
	<li> a larger number of processes to be executing at once.
	<li> mutual exclusion on the critical sections of each process.
	<li> fast interprocess communication.
	<li> None of the above
	</ol>
</li><br/>
<li> Because page replacement algorithms <strong>must</strong> write modified
	page frames back to disk before loading in another virtual page, thus
	slowing down the resolution of a page fault,
	<ol class="answer_list">
	<li> many page replacement algorithms give preference to UNmodified
		pages over modified pages.
	<li> page modifications are often implemented as <em>write-through</em>
		so that the dirty page is immediately written out to disk after
		each change.
	<li> a <em>paging daemon</em> can be used as a background process to
		write dirty pages back to disk, reducing the number of dirty
		page frames.
	<li> the frequency of page modifications is reduced by translating
		writes to the page directly into writes out to the disk.
	<li> None of the above
	</ol>
</li><br/>

<li> When the OS creates a new process, and its corresponding entry in the
	process table, it <strong>must</strong> also
	<ol class="answer_list">
	<li> add it to the set of blocked processes.
	<li> create a page table for the process.
	<li> allocate a swap area (on disk) for the process.
	<li> pre-load its working set into page frames.
	<li> None of the above
	</ol>
</li><br/>
<li> When a context switch occurs to run a process,
	<ol class="answer_list">
	<li> reset <strong>all</strong> of the "present" bits in the process'
		page table to 0 (showing that they are <strong>not</strong>
		loaded into page frames).
	<li> the Memory Management Unit (MMU) <strong>must</strong> be reset.
	<li> restore the CPU registers to the values they had when the process
		was last running.
	<li> the Translation Lookaside Buffer (TLB) <strong>must</strong>
		be flushed.
	<li> None of the above
	</ol>
</li><br/>
<li> What is often one of the easiest (and often cheapest) ways to increase
	the speed of a computer system?
	<ol class="answer_list">
	<li> Upgrade to a faster processor.
	<li> Add more memory.
	<li> Add more hard disk space.
	<li> Add more processors.
	<li> None of the above
	</ol>
</li><br/>
<li> When a process terminates, the OS should
	<ol class="answer_list">
	<li> release the page frames it was using (unless they were shared
		and other processes are still using them).
	<li> release/deallocate the process' page table.
	<li> free the disk space assigned as the process' swap area.
	<li> remove its entry from the process table.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following steps are typically done to handle a page fault:
	<ol class="answer_list">
	<li> the hardware traps to the OS kernel
	<li> the program counter (and instruction information) is saved
	<li> general registers values are saved before calling the OS
	<li> the faulting process is swapped out to disk
	<li> the OS determines which virtual page is needed
	<li> ensure the virtual address is valid
	<li> Use the Translation Lookaside Buffer (TLB) to find a page frame
		to use
	<li> <strong>always</strong> schedule the chosen page frame to be
		written back to disk
	<li> update the page table after the page is loaded into the page frame
	<li> load the swapped out faulting process back into memory
	<li> set the program counter back to the instruction that caused the
		page fault
	<li> schedule the faulting process to run
	</ol>
</li><br/>
<li> Instruction backup is necessary because
	<ol class="answer_list">
	<li> while the first part of the instruction was in physical memory
		the last portion may not be - causing a page fault.
	<li> a context switch requires that the last instruction attempted
		by the process being evicted from the CPU <strong>must</strong>
		be reexecuted when the process runs again.
	<li> if the instruction causes a page fault, some or all of it will
		need to be reexecuted.
	<li> just like for files, you need to ensure that the instruction
		doesn't get removed accidentally.
	<li> None of the above
	</ol>
</li><br/>
<li> Locking a page in memory (i.e., pinning), so that the page replacement
	algorithm cannot select it for eviction, is necessary because
	<ol class="answer_list">
	<li> it reduces the likelihood of thrashing.
	<li> some operations load file data directly into a page frame, and
		reassigning the page could expose protected information to
		another process.
	<li> most page replacement algorithms would preferentially choose
		the most recently loaded page again for replacement.
	<li> if modified, it needs to be written back to disk by the
		paging daemon before it's reused.
	<li> None of the above
	</ol>
</li><br/>
<li> The swap area on disk associated with a process is
	<ol class="answer_list">
	<li> only needed if the virtual address space is larger than physical
		memory.
	<li> <strong>not</strong> necessary, but can help improve performance.
	<li> created when a process gets its first page fault.
	<li> used to store process information <strong>not</strong> currently
		in memory (e.g., a page frame).
	<li> None of the above
	</ol>
</li><br/>
<li> Basic approaches for allocating swap space include allocating space
	<ol class="answer_list">
	<li> for the entire process when the process is initially created.
	<li> for the entire process only after the process
		generates its first page fault.
	<li> only for pages <strong>not</strong> currently in physical memory,
		adding to the allocation as needed (e.g., when the run-time
		stack grows).
	<li> only when the run-time stack or heap grow beyond a certain
		pre-defined limit.
	<li> None of the above
	</ol>
</li><br/>
<li> A drawback of initially allocating <strong>all</strong> the swap space
	for a process is
	<ol class="answer_list">
	<li> that a larger than necessary page table <strong>must</strong>
		also be created.
	<li> the corresponding process table entry is larger.
	<li> as the process needs more space (e.g., for the run-time stack)
		it may need to copy the swap area to a larger chunk of disk
		space.
	<li> it can increase the chance of thrashing since there are more
		virtual pages that might need to be loaded into page frames.
	<li> None of the above
	</ol>
</li><br/>
<li> Allocating space in the swap area only for a process' pages
	<strong>not</strong> currently in physical memory
	<ol class="answer_list">
	<li> decreases the size of the page table.
	<li> often reduces the total amount of swap space needed.
	<li> reduces the chance of thrashing since there are fewer
		virtual pages that might need to be loaded into page frames.
	<li> easily handles the case when a process' address space
		<strong>must</strong> increase (e.g., for the run-time stack).
	<li> None of the above
	</ol>
</li><br/>
<li> The separation of policy and mechanism with respect to virtual memory
	and page replacement algorithms is
	<ol class="answer_list">
	<li> <strong>not</strong> attainable since page replacement algorithms
		need access to the page tables which are protected data within
		the OS kernel.
	<li> can be done by having the MMU and page fault handlers run within
		the OS kernel while a user space  page loader copies the
		virtual page to memory (the page fault handler remaps the page
		frame to the process afterwards). 
	<li> while theoretically possible, there are no operating systems that
		currently implement this capability.
	<li> is possible, though somewhat complicated, and is implemented
		by the Mach kernel.
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following are <strong>not</strong> essential qualities of
	files?
	<ol class="answer_list">
	<li> Multiple processes can access the same file simultaneously.
	<li> Are stored on either hard disk drives (HDDs) or solid-state
		disks (SSDs).
	<li> Ability to store LARGE amounts of information.
	<li> The lifetime of a file is not bound to any process.
	<li> None of the above
	</ol>
</li><br/>
<li> The file system provides an abstraction of how files are
	<ol class="answer_list">
	<li> manipulated.
	<li> read.
	<li> managed.
	<li> written.
	<li> None of the above
	</ol>
</li><br/>
<li> File names
	<ol class="answer_list">
	<li> are a sequence of (readable) characters for referring to the file.
	<li> may be of any length, and contain both upper and lower case
		characters.
	<li> <strong>must</strong> have a single extension
		(e.g., ".txt", ".exe") indicating the type of data they hold.
	<li> differ from system to system, depending upon the file system(s)
		the OS makes available.
	<li> None of the above
	</ol>
</li><br/>
<li> The extension (e.g.,  ".txt", ".exe") for a file name
	<ol class="answer_list">
	<li> is typically only meaningful to application programs.
	<li> indicates to the file system what type of data to restrict the
		file to holding (e.g., a ".txt" file may not hold a pdf
		document).
	<li> is a convenience to users to make it easier to discern what
		kind of data each file holds.
	<li> can be ignored by the OS (e.g., Unix/Linux).
	<li> None of the above
	</ol>
</li><br/>
<li> The logical organization of the information in a file is called its
	<ol class="answer_list">
	<li> file type.
	<li> file system.
	<li> file structure.
	<li> file attributes.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are the basic types of file structures?
	<ol class="answer_list">
	<li> Unstructured sequence of bytes.
	<li> Sequence of (structured) records.
	<li> List of object-oriented tables.
	<li> Tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> Regular files in Unix/Linux and Windows are organized as
	<ol class="answer_list">
	<li> an unstructured sequence of bytes.
	<li> a sequence of (structured) records.
	<li> a list of object-oriented tables.
	<li> a tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> Indexed Sequential Access Method (ISAM) files on mainframes are organized
	as
	<ol class="answer_list">
	<li> an unstructured sequence of bytes.
	<li> a sequence of (structured) records.
	<li> a list of object-oriented tables.
	<li> a tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> Indexed Virtual Storage Access Method (Indexed VSAM) files on mainframes
	are organized as
	<ol class="answer_list">
	<li> an unstructured sequence of bytes.
	<li> a sequence of (structured) records.
	<li> a list of object-oriented tables.
	<li> a tree of (structured) records.
	<li> None of the above
	</ol>
</li><br/>
<li> File types describe the broad categorization of the kinds of information
	a file represents/holds. Which of the following are common file types?
	<ol class="answer_list">
	<li> Regular (data) files.
	<li> Executable files.
	<li> Special (device) files.
	<li> Directories.
	<li> None of the above
	</ol>
</li><br/>
<li> Files that model I/O devices that work with one byte at time are called
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> Files that model I/O devices that work with arrays of bytes at a time
	are called
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> Devices such as keyboards, mice, and printers usually correspond to
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> Devices such as hard disk drives (HDDs) and solid-state disks (SSDs)
	usually correspond to
	<ol class="answer_list">
	<li> I/O files.
	<li> System files.
	<li> Character special files.
	<li> Block special files.
	<li> None of the above
	</ol>
</li><br/>
<li> The two primary file access methods are
	<ol class="answer_list">
	<li> Linear access.
	<li> Sequential access.
	<li> Indexed access.
	<li> Random access.
	<li> None of the above
	</ol>
</li><br/>
<li> If accessing the Nth byte of a file requires first accessing byte N-1,
	then the file access type is
	<ol class="answer_list">
	<li> Linear access.
	<li> Sequential access.
	<li> Indexed access.
	<li> Random access.
	<li> None of the above
	</ol>
</li><br/>
<li> If accessing the Nth byte of a file can be done <strong>without</strong>
	first accessing byte N-1, then the file access type is
	<ol class="answer_list">
	<li> Linear access.
	<li> Sequential access.
	<li> Indexed access.
	<li> Random access.
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX system call can be used to skip to a particular byte
	location within a file (thus supporting random access)?
	<ol class="answer_list">
	<li> find
	<li> lseek
	<li> skip
	<li> rand
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file attributes are common to many systems?
	<ol class="answer_list">
	<li> File name.
	<li> The number of disk blocks the file occupies.
	<li> Size of the file in bytes.
	<li> The optimal block size for reading or writing this file
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to create a new file?
	<ol class="answer_list">
	<li> creat
	<li> mkfile
	<li> new
	<li> make
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to open an existing file (for reading
	or writing)?
	<ol class="answer_list">
	<li> stat
	<li> fopen
	<li> find
	<li> create
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to close an open file (ensuring that any
	buffers are written back disk)?
	<ol class="answer_list">
	<li> end
	<li> flush
	<li> fclose
	<li> done
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to delete an existing file?
	<ol class="answer_list">
	<li> delete
	<li> free
	<li> deallocate
	<li> remove
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to read data from a file?
	<ol class="answer_list">
	<li> read
	<li> read_byte
	<li> scan
	<li> get_byte
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to write data to a file?
	<ol class="answer_list">
	<li> print
	<li> put_char
	<li> write
	<li> write_byte
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to set the current position within an open file?
	<ol class="answer_list">
	<li> find
	<li> locate
	<li> seek
	<li> position
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to obtain information about a file?
	<ol class="answer_list">
	<li> get_info
	<li> finfo
	<li> fattr
	<li> stat
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the name of an existing file?
	<ol class="answer_list">
	<li> move
	<li> rename
	<li> chfile
	<li> touch
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the owner of a file?
	<ol class="answer_list">
	<li> finfo
	<li> fattr
	<li> chown
	<li> owner
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the permissions of a file?
	<ol class="answer_list">
	<li> perm
	<li> chmod
	<li> chperm
	<li> stat
	<li> None of the above
	</ol>
</li><br/>

<li> File systems that have only a single directory of files, with no
	sub-directory hierarchies
	<ol class="answer_list">
	<li> are called flat file systems.
	<li> can accommodate larger files than a hierarchical file system.
	<li> were being used until the mid-1980s.
	<li> are in common use today, typically for USB flash drives.
	<li> None of the above
	</ol>
</li><br/>
<li> The most common type of file system in use today are
	<ol class="answer_list">
	<li> flat file systems.
	<li> linear file systems.
	<li> indexed file systems.
	<li> hierarchical file systems.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links to files
	<ol class="answer_list">
	<li> require the file to be copied, with future changes to the
		original being propigated to the copy.
	<li> maintain a single copy of the file, but accessible from different
		places/directories within the file system.
	<li> use "copy on write" to maintain a single copy of the file until
		a change is made.
	<li> is the kind used when a file is first created.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links to a directory, from within the current directory,
	<ol class="answer_list">
	<li> can be created <strong>without</strong> any issues.
	<li> are only allowed when the directory being linked to is an
		ancestor (i.e., occurs in the path of the current location).
	<li> are only allowed when the directory being linked to is a
		decendant (e.g., child, grandchild) of the current directory.
	<li> are <strong>not</strong> allowed since this would create a
		circular structure that wouldn't be freeable later.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links can be used
	<ol class="answer_list">
	<li> to link to files on the same computer but in a different file
		system.
	<li> to link to remote files on different computer systems.
	<li> only to link to files on the same computer, either in the same
		or a different file system.
	<li> only to link to files within the same physical file system.
	<li> None of the above
	</ol>
</li><br/>
<li> Symbolic (soft) links to files and directories
	<ol class="answer_list">
	<li> can link to files and directories in different file
		systems as well as on different computers.
	<li> can link to non-existent files.
	<li> are allowed to create circular structures (e.g., a directory
		can have itself as its parent/child).
	<li> are automatically deleted when the orignal file/directory is
		removed.
	<li> None of the above
	</ol>
</li><br/>
<li> Absolute path names begin with a
	<ol class="answer_list">
	<li> "./" on both Unix/Linux and Windows systems.
	<li> "../" on both Unix/Linux and Windows systems.
	<li> slash (/) on Unix/Linux systems.
	<li> drive letter (e.g., A:) on a Windows system.
	<li> None of the above
	</ol>
</li><br/>
<li> Relative path names specify the location of a file or directory
	<ol class="answer_list">
	<li> starting from the current working directory.
	<li> with respect to the root directory of the file system.
	<li> relative to the user's home directory.
	<li> starting from the directory where the program requesting the
		file is located.
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to create a new directory?
	<ol class="answer_list">
	<li> new
	<li> mkdir
	<li> dir
	<li> create
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to delete an existing directory?
	<ol class="answer_list">
	<li> remove
	<li> delete
	<li> rmdir
	<li> free
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to open a directory for examination?
	<ol class="answer_list">
	<li> find
	<li> stat
	<li> examine
	<li> opendir
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to close a directory and ensure that any
	changes to it are written back to the disk?
	<ol class="answer_list">
	<li> closedir
	<li> flush
	<li> finish
	<li> done
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the name of a directory?
	<ol class="answer_list">
	<li> move
	<li> rename
	<li> chname
	<li> chmod
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to create a new directory entry for an existing
	file?
	<ol class="answer_list">
	<li> add2dir
	<li> direntry
	<li> link
	<li> new
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to remove the directory entry for a file?
	<ol class="answer_list">
	<li> rmfile
	<li> delete
	<li> free
	<li> unlink
	<li> None of the above
	</ol>
</li><br/>
<li> Which POSIX call is used to change the current working directory?
	<ol class="answer_list">
	<li> pwd
	<li> chdir
	<li> cd
	<li> go2dir
	<li> None of the above
	</ol>
</li><br/>
<li> The key difference(s) between hard links and soft/symbolic links are that
	<ol class="answer_list">
	<li> soft links allow files to be accessed randomly while hard linked
		files are limited to sequential access. 
	<li> soft links are implemented by software but hard links require
		hardware support to be implemented.
	<li> hard links point to a physical (disk) location while soft links
		give the "directions" (i.e., path) to the linked file.
	<li> hard links provide copy on write semantics whereas symbolic links
		do <strong>not</strong>.
	<li> None of the above
	</ol>
</li><br/>
<li> Deleting a soft link
	<ol class="answer_list">
	<li> <strong>always</strong> deletes the file that the link pointed to.
	<li> will delete the file the link points to, but only if the file
		is located on the same file system as the link.
	<li> will delete the file the link points to, but only if this is
		the last soft link to the file.
	<li> <strong>never</strong> deletes the file that the link pointed to.
	<li> None of the above
	</ol>
</li><br/>
<li> Deleting a hard link
	<ol class="answer_list">
	<li> <strong>always</strong> deletes the file that the link pointed to.
	<li> will delete the file the link points to, but only if the file
		is located on the same file system as the link.
	<li> will delete the file the link points to, but only if this is
		the last hard link to the file.
	<li> <strong>never</strong> deletes the file that the link pointed to.
	<li> None of the above
	</ol>
</li><br/>
<li> Soft links can point to files
	<ol class="answer_list">
	<li> but only when there's <strong>not</strong> another soft link
		already pointing to them.
	<li> but only when there's <strong>not</strong> a hard link already
		pointing to them.
	<li> that don't actually exist.
	<li> on different file systems.
	<li> None of the above
	</ol>
</li><br/>
<li> Hard links can point to files
	<ol class="answer_list">
	<li> but only when there's <strong>not</strong> a soft link already
		pointing to them.
	<li> but only when there's <strong>not</strong> another hard link
		already pointing to them.
	<li> that don't actually exist.
	<li> on different file systems.
	<li> None of the above
	</ol>
</li><br/>

<li> File systems are
	<ol class="answer_list">
	<li> <strong>all</strong> very similar with the few differences
		between them of little importance.
	<li> nearly always stored on disk (either HDD or SSD).
	<li> dedicated to the OS, with each OS supporting only a single
		file system.
	<li> generally contained within a single disk partition (if stored on
		a disk).
	<li> None of the above
	</ol>
</li><br/>
<li> A disk (either HDD or SSD) has
	<ol class="answer_list">
	<li> a single Master Boot Record (MBR).
	<li> one or more partitions.
	<li> a boot block for each partition.
	<li> a partition table (stored at the end of the MBR).
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> steps in the boot process?
	<ol class="answer_list">
	<li> the BIOS identifies the boot device and ensures it's attached.
	<li> the program in the Master Boot Record (MBR) is loaded and run.
	<li> the MBR program loads and runs the code in the first block of the
		active partition.
	<li> the boot block program loads the OS from the active partition.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> part of every disk
	partition?
	<ol class="answer_list">
	<li> Root directory
	<li> Boot block
	<li> Superblock
	<li> Master Boot Record (MBR)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> a basic technique for
	implementing files?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique stores the file in consecutive disk
	blocks, so that only the last block has any wasted space?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique uses the first word of each block
	(or alternately a separate table representing those words) to indicate
	the disk block holding the next portion of the file?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique only requires the location of the
	first disk block and the number of disk blocks allocated for the file
	in order to access it?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file implementation technique uses a single data structure that
	stores standard metadata along with direct and indirect pointers to
	the file blocks containing the file data?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file implementation techniques suffers from
	external fragmentation if files can be removed or modified?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file implementation techniques completely
	avoid any internal fragmentation?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> File Allocation Tables are an aspect of which of the following file
	implementation techniques?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following file implementation techniques has the
	<strong>best</strong> support for random access?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> Linked List Allocation
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which file system implementation is suitable for smaller disks
	but is less suitable as the size of the disk grows larger?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> File Allocation Table (FAT)
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> An advantage that i-nodes have over FAT file systems is that
	<ol class="answer_list">
	<li> they have better performance for randomly accessing files.
	<li> they have less external fragmentation.
	<li> they have less internal fragmentation.
	<li> only direct and indirect links to the disk blocks for the desired
		file (and no other files) are needed in memory.
	<li> None of the above
	</ol>
</li><br/>
<li> ISO 9660 was developed for use by compact disks (for music) and later
	DVDs (for movies). Which file system implementation approach is
	ISO 9660 an example of?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Superblock Allocation
	<li> File Allocation Table (FAT)
	<li> Spiral Allocation
	<li> Index-nodes
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> a commonly used technique
	for storing file/directory names in directory entries?
	<ol class="answer_list">
	<li> Use a fixed amount of space for the name (e.g., 8.3 names).
	<li> Allocate the string for the name from heap storage and put the
		pointer in the directory entry.
	<li> Allow directory entries to be variable in length with the file
		name appearing at the end of the entry.
	<li> Each directory entire has a pointer into a shared string space
		for storing <strong>all</strong> the names in that directory.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are true about the root directory of a file
	system?
	<ol class="answer_list">
	<li> It's the only file/directory <strong>without</strong> a name.
	<li> Both hard and soft links to the root directory are
		<strong>not</strong> allowed.
	<li> The root is stored in the boot block of the file system partition.
	<li> A pointer to it <strong>must</strong> be kept in a known/standard
		location.
	<li> None of the above
	</ol>
</li><br/>
<li> The attributes associated with a file (or directory) are
	<ol class="answer_list">
	<li> <strong>always</strong> stored in its directory entry.
	<li> are stored in the directory entry for contiguous and linked list
		file allocations.
	<li> are stored in the file's (or directory's) i-node if index-nodes
		are used for file allocation.
	<li> <strong>never</strong> stored in its directory entry.
	<li> None of the above
	</ol>
</li><br/>
<li> As the number of directory entries increases (e.g., >= 100),
	<ol class="answer_list">
	<li> searching for a file (or directory) name may get slower if a
		hash table isn't used.
	<li> the i-nodes used (for an index-node implementation) increases
		faster than the number of files in the directory.
	<li> space within the directory (itself a special file) is likely
		to become exhausted.
	<li> the file system as a whole becomes slower to access.
	<li> None of the above
	</ol>
</li><br/>
<li> Soft links are slower to access a file than hard links because
	<ol class="answer_list">
	<li> every file system on the disk (in different partitions)
		<strong>must</strong> be checked for the file.
	<li> hard links point directly to the file (e.g., via its
		i-node number). 
	<li> the linked file is <strong>always</strong> specified as an
		absolute path.
	<li> they require visiting (multiple) other directories along the
		indicated file path to find the linked file.
	<li> None of the above
	</ol>
</li><br/>
<li> Copying soft links can be problematic because
	<ol class="answer_list">
	<li> there are two ways to copy them, making a copy of the link or
		making a copy of the file the link points to.
	<li> the link may point to another file system, and copies across
		file systems cannot be done.
	<li> the resulting copy will <strong>always</strong> be a soft link.
	<li> they can sometimes be mistaken for a hard link by the OS.
	<li> None of the above
	</ol>
</li><br/>
<li> Log structure files buffer writes, to a hard disk disk (HDD), in memory
	<ol class="answer_list">
	<li> improving the write efficiency to the disk while reducing wait
		time for processes writing to disk.
	<li> thus preventing file system problems if a system failure occurs.
	<li> but this increases the risk that information will be lost if a
		system failure occurs.
	<li> because file system operations generally require many small writes
		to the HDD, so bundling them together improves efficiency.
	<li> None of the above
	</ol>
</li><br/>
<li> Log structure files
	<ol class="answer_list">
	<li> keep a complete record of <strong>all</strong> writes that have
		ever been made to a disk drive.
	<li> are becoming increasingly important to have as solid state disks
		(SSDs) become more common.
	<li> are becoming less necessary as hard disk drives (HDDs) are replaced
		with solid state disks (SSDs).
	<li> have a special process that regularly "cleans" and compacts them
		(as some items in the log are no longer needed as time passes).
	<li> None of the above
	</ol>
</li><br/>
<li> Journaling file systems are used to
	<ol class="answer_list">
	<li> improve the write efficiency to the disk.
	<li> prevent file system problems if a system failure occurs.
	<li> enable access to remote file systems.
	<li> create an up-to-date backup of a file system, so that it can be
		restored in the case of a disk failure/crash.
	<li> None of the above
	</ol>
</li><br/>
<li> A journaling file system keeps a log of actions to be performed
	<ol class="answer_list">
	<li> to improve the write efficiency to the disk.
	<li> removing them only after their completion has been confirmed.
	<li> but each action <strong>must</strong> be <em>idempotent</em> in
		case there are multiple system crashes.
	<li> to create an up-to-date backup of a file system, so that it can be
		restored in the case of a disk failure/crash.
	<li> None of the above
	</ol>
</li><br/>
<li> An <em>idempotent</em> operation is one that
	<ol class="answer_list">
	<li> makes an atomic change to disk (i.e., either the entire operation
		completes or none of it does).
	<li> <strong>always</strong> runs from within a critical section.
	<li> is <strong>not</strong> critical, so that if it
		<strong>never</strong> gets performed it's okay.
	<li> <strong>must</strong> be executed <em>exactly</em> once
		(e.g., making a deposit to a bank account). 
	<li> None of the above
	</ol>
</li><br/>
<li> A virtual file system
	<ol class="answer_list">
	<li> implements both journaling and log file structures, improving
		both efficiency and safety.
	<li> enables multiple file systems to be seamless integrated so that
		they appear as a single file system.
	<li> provides access to file systems on remote computers.
	<li> ensures that both soft and hard links can be used across file
		systems.
	<li> None of the above
	</ol>
</li><br/>
<li> A virtual file system
	<ol class="answer_list">
	<li> does <strong>not</strong> actually store files itself, but
		interfaces with multiple other file systems.
	<li> stores files on disks that are shared among multiple computer
		systems.
	<li> provides access to file systems on remote computers.
	<li> ensures that both soft and hard links can be used across file
		systems.
	<li> None of the above
	</ol>
</li><br/>

<li> Most file systems do <strong>not</strong> store files in contiguous disk
	blocks because
	<ol class="answer_list">
	<li> this makes the file system design and implementation simpler.
	<li> of the delay that the rotational latency of a HDD requires when
		the disk blocks are next to one another.
	<li> it reduces the amount of internal fragmentation.
	<li> files tend to grow in size, requiring the disk blocks for the 
		file to be copied.
	<li> None of the above
	</ol>
</li><br/>
<li> For the same size disk, larger disk block sizes tend to
	<ol class="answer_list">
	<li> improve the data transfer rate to and from disk.
	<li> reduce internal fragmentation.
	<li> reduce the number of blocks needed to store a file.
	<li> decrease the amount of storage need to keep track of bad disk
		blocks.
	<li> None of the above
	</ol>
</li><br/>
<li> It's not uncommon, particularly for hard disk drives (HDDs), for disk
	blocks to become bad. To avoid using them, bad blocks are
	<ol class="answer_list">
	<li> tracked by the controller in a list stored in a pre-specified
		disk location.
	<li> filled with a special value to identify them.
	<li> moved to another location on the disk.
	<li> removed from the list of free blocks.
	<li> None of the above
	</ol>
</li><br/>
<li> The free (unused) blocks on a disk are often tracked by
	<ol class="answer_list">
	<li> moving the used blocks to the lower disk block numbers (i.e.,
		compacting) and keeping a single number which is the lowest
		disk number of the set of contiguous free blocks.
	<li> exchanging (copying) free blocks and used blocks (as a
		background process) to combine the free blocks into a small
		number of contiguous areas.
	<li> keeping a linked list of blocks, with each block in the list
		pointing to a large number of free blocks.
	<li> using a bit map contained in 1 or more blocks, with bits
		having either a value of 1 (used) or 0 (free).
	<li> None of the above
	</ol>
</li><br/>
<li> Disk quotas are a mechanism to prevent
	<ol class="answer_list">
	<li> account holders from using more than their "fair share"
		of the file system space.
	<li> disk failure due to overuse.
	<li> the inadvertent loss of files due to user error.
	<li> a disk from filling up.
	<li> None of the above
	</ol>
</li><br/>
<li> A disk quota can be used to limit the total
	<ol class="answer_list">
	<li> amount of space on the disk.
	<li> amount of disk space a user's files take up.
	<li> number of swap areas (and thus processes) that can exist. 
	<li> number of files a user has.
	<li> None of the above
	</ol>
</li><br/>
<li> A disk quota soft limit
	<ol class="answer_list">
	<li> warns the user when they are getting close to their hard limit.
	<li> prevents the creation of new files when exceeded, but allows
		existing files to be appended to.
	<li> restricts the number of executable files (software) that the
		user has.
	<li> indicates the maximum number of soft links that the user can
		have.
	<li> None of the above
	</ol>
</li><br/>
<li> A disk quota hard limit
	<ol class="answer_list">
	<li> is the maximum amount of space (or number of files) a user is
		permitted to have.
	<li> applies only to hard disk drives (HDDs).
	<li> can prevent a user from saving their work, if reached.
	<li> indicates the maximum number of hard links that the user can
		have.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary types of file system backups are
	<ol class="answer_list">
	<li> physical dump.
	<li> traditional dump.
	<li> logical dump.
	<li> virtual dump.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of file system dump is fast and simple to implement, but
	can't do incremental backups or restore select files?
	<ol class="answer_list">
	<li> physical dump.
	<li> traditional dump.
	<li> logical dump.
	<li> virtual dump.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of file system dump can restore select files and dump only
	changed files and directories, but is slower and more complex to
	implement?
	<ol class="answer_list">
	<li> physical dump.
	<li> traditional dump.
	<li> logical dump.
	<li> virtual dump.
	<li> None of the above
	</ol>
</li><br/>
<li> A <em>full backup</em> is
	<ol class="answer_list">
	<li> taken when a file system is full, so it can be stored off-site.
	<li> a complete copy of the current state of the file system.
	<li> done when each user has reached their disk quota soft limit.
	<li> done when each user has reached their disk quota hard limit.
	<li> None of the above
	</ol>
</li><br/>
<li> An <em>incremental backup</em> is
	<ol class="answer_list">
	<li> frequently used because it takes less space and finishes more
		quickly than a full backup.
	<li> created whenever a user reaches their disk quota soft limit.
	<li> used to make copies of only those files (and directories) that
		have changed since the last backup.
	<li> performed automatically by the file system on a periodic basis.
	<li> None of the above
	</ol>
</li><br/>
<li> Keeping file system backups on-site is
	<ol class="answer_list">
	<li> preferred as this makes it easier and faster to restore user files.
	<li> <strong>never</strong> a good idea since a single problem
		(e.g., tornado) can cause a loss of both the file system
		(on disks) and its backup.
	<li> no better or worse than keeping them off-site.
	<li> necessary only if the backup is made to other disks in near
		real-time.
	<li> None of the above
	</ol>
</li><br/>
<li> For an i-node based file system, which type of check recursively
	traverses a directory keeping a count for each i-node of the number
	of references to that i-node?
	<ol class="answer_list">
	<li> OS consistency check
	<li> File consistency check
	<li> Block consistency check
	<li> I-node check
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of check uses two counters per disk block to count the number
	of times they are pointed to by either an i-node (1st counter) or
	from the free list (2nd counter)?
	<ol class="answer_list">
	<li> OS consistency check
	<li> File consistency check
	<li> Block consistency check
	<li> I-node check
	<li> None of the above
	</ol>
</li><br/>
<li> The i-node counts created by a file consistency check should
	<ol class="answer_list">
	<li> equal the i-node reference counts.
	<li> sum to the total number of disk blocks.
	<li> equal the count of the number of free blocks.
	<li> <strong>never</strong> be greater than 1.
	<li> None of the above
	</ol>
</li><br/>
<li> After a block consistency check has created its counts corresponding to
	the number of times the block is used or appears in the free list
	respectively, a problem exists if
	<ol class="answer_list">
	<li> both counts are 0.
	<li> if the sum of the two counts = 1.
	<li> both counts are >= 1.
	<li> either count is > 1.
	<li> None of the above
	</ol>
</li><br/>
<li> To improve the performance of a file system, particularly those stored on
	HDDs,
	<ol class="answer_list">
	<li> the disk block size should be kept small (e.g., 1 KB) to reduce
		internal fragmentation.
	<li> a block cache should keep a number of disk blocks in memory to
		reduce read times.
	<li> changes to a file's disk block that's been loaded into memory,
		should <strong>not</strong> be written back to disk after
		every change.
	<li> Perform a regular incremental backup. 
	<li> None of the above
	</ol>
</li><br/>
<li> Pre-fetching the next few disk blocks for a file, can improve the
	performance for which type of file access (particularly on HDDs)?
	<ol class="answer_list">
	<li> Random access.
	<li> Spiral access.
	<li> Sequential access.
	<li> Tree access.
	<li> None of the above
	</ol>
</li><br/>
<li> Part of the advantage of caching disk blocks in memory is to reduce
	the total number of writes to disk (i.e., make several changes to the
	cache before writing the cached block back to disk), what if any
	advantage is there to having a cache that writes through
	to the disk every time the cache is changed?
	<ol class="answer_list">
	<li> In the event of a system failure, write-through-caches can reduce
		the amount of lost data.
	<li> All writes to disk <strong>must</strong> come from memory/cache
		anyway, so there is no difference in write performance.
	<li> The write-through-cache also provides the faster read access.
	<li> Using a write-through-cache lowers contention on the system bus
		since the disk block is written as soon as it's changed.
	<li> None of the above
	</ol>
</li><br/>
<li> When possible, in order to improve file read/write performance, the free
	blocks allocated to store the contents of a file should be
	<ol class="answer_list">
	<li> randomly distributed on the disk to avoid access contention.
	<li> in the same disk partition.
	<li> one after another (on HDDs) to reduce seek time.
	<li> of the same size.
	<li> None of the above
	</ol>
</li><br/>
<li> The Unix <em>sync</em> and Windows <em>FlushFileBuffers</em> processes
	<ol class="answer_list">
	<li> ensure that the contents of cached disk blocks are written to
		disk periodically when they've been modified. 
	<li> update the contents of any file disk blocks cached in memory
		that might have been altered on disk.
	<li> are unnecessary if write-through caches are
		<strong>always</strong> used.
	<li> only need to be used in combination with a virtual file system.
	<li> None of the above
	</ol>
</li><br/>
<li> Defragmenting a disk
	<ol class="answer_list">
	<li> compacts the file system, placing <strong>all</strong> of the
		free disk blocks at one end of the partition.
	<li> reduces the amount of internal fragmentation.
	<li> can place a file's disk blocks consecutively so as to increase
		read/write access speeds.
	<li> increases the number of free disk blocks available to the file
		system.
	<li> None of the above
	</ol>
</li><br/>
<li> Defragmenting a disk is <em>most</em> useful for which type of file system?
	<ol class="answer_list">
	<li> Contiguous Allocation
	<li> Linked List Allocation
	<li> Index Node
	<li> Virtual File System
	<li> None of the above
	</ol>
</li><br/>

<li> A kilobyte (KB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A gigabyte (GB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A megabyte (MB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A terabyte (TB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> A petabyte (PB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> An exabyte (EB) is how many bytes?
	<ol class="answer_list">
	<li> 2^10
	<li> 2^20
	<li> 2^30
	<li> 2^40
	<li> 2^50
	<li> 2^60
	</ol>
</li><br/>
<li> Which of the following are examples of a contiguous allocation file
	system?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660 with Joliet Extensions
	<li> ISO 9660 with Rock Ridge Extensions
	<li> ext2
	<li> ext4
	<li> Network File System (NFS)
	<li> Virtual File System (VFS)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are examples of a linked list allocation file 
	system?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660 with Joliet Extensions
	<li> ISO 9660 with Rock Ridge Extensions
	<li> ext2
	<li> ext4
	<li> Network File System (NFS)
	<li> Virtual File System (VFS)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are examples of an index-node allocation file 
	system?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660 with Joliet Extensions
	<li> ISO 9660 with Rock Ridge Extensions
	<li> ext2
	<li> ext4
	<li> Network File System (NFS)
	<li> Virtual File System (VFS)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following files systems provide journaling?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660
	<li> ext2
	<li> NTFS
	<li> ext4
	<li> ReFS
	<li> Btrfs
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following files systems support hard links?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660
	<li> ext2
	<li> NTFS
	<li> ext4
	<li> ReFS
	<li> Btrfs
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following files systems support soft links?
	<ol class="answer_list">
	<li> FAT-32
	<li> ISO 9660
	<li> ext2
	<li> NTFS
	<li> ext4
	<li> ReFS
	<li> Btrfs
	<li> None of the above
	</ol>
</li><br/>

<li> The primary kinds of devices are
	<ol class="answer_list">
	<li> character devices.
	<li> linear devices.
	<li> parallel devices.
	<li> block devices.
	<li> None of the above
	</ol>
</li><br/>
<li> What kind of device works with information in fixed size blocks and often
	provides random access?
	<ol class="answer_list">
	<li> character devices.
	<li> linear devices.
	<li> parallel devices.
	<li> block devices.
	<li> None of the above
	</ol>
</li><br/>
<li> What kind of device works with information as a sequence of bytes and
	only provides sequentially access?
	<ol class="answer_list">
	<li> character devices.
	<li> linear devices.
	<li> parallel devices.
	<li> block devices.
	<li> None of the above
	</ol>
</li><br/>
<li> What software interacts with the device controller to enable the OS to
	utilize a device?
	<ol class="answer_list">
	<li> I/O interface
	<li> Device driver
	<li> Interrupt driver
	<li> Control bus
	<li> None of the above
	</ol>
</li><br/>
<li> The primary nature of an I/O device is
	<ol class="answer_list">
	<li> mechanical and based on material properties. 
	<li> electronic (circuits).
	<li> software.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary nature of an device controller is
	<ol class="answer_list">
	<li> mechanical and based on material properties. 
	<li> electronic (circuits).
	<li> software.
	<li> None of the above
	</ol>
</li><br/>
<li> The primary nature of an device driver is
	<ol class="answer_list">
	<li> mechanical and based on material properties. 
	<li> electronic (circuits).
	<li> software.
	<li> None of the above
	</ol>
</li><br/>
<li> Each device controller
	<ol class="answer_list">
	<li> controls only a single device.
	<li> may control many devices.
	<li> communicates with its corresponding device driver.
	<li> <strong>must</strong> have its own dedicated bus to both the CPU
		and the Direct Memory Access (DMA) controller.
	<li> None of the above
	</ol>
</li><br/>
<li> Devices controllers have
	<ol class="answer_list">
	<li> support for <strong>all</strong> types of devices, so that any
		device can utilize any type of device controller.
	<li> data buffers that can be written to or read from.
	<li> control registers to communicate with the CPU.
	<li> their own instruction sets that <strong>must</strong> be
		supported by the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> Port I/O, used by early computers,
	<ol class="answer_list">
	<li> assigns each control register to its corresponding I/O port.
	<li> is very slow since large data transfers <strong>must</strong>
		be done by reading/writing data in many small chunks (using
		the control registers).
	<li> the I/O ports are separate from memory (requiring protected
		instructions to read/write the I/O ports).
	<li> requires some portion of the device drivers to be written in
		assembly.
	<li> cannot use device drivers as the OS kernel <strong>must</strong>
		directly control the device.
	<li> None of the above
	</ol>
</li><br/>
<li> The advantages of Memory-Mapped I/O are
	<ol class="answer_list">
	<li> reduces the number of CPU executed instructions to put information
		into control registers.
	<li> ease of protecting the control registers by <strong>not</strong>
		putting the mapped memory in a user accessible address space.
	<li> data can be read/written directly to the device since the device
		buffer is mapped to memory.
	<li> device drivers can be written in a higher-level language (e.g.,
		C) enabling them to be more portable.
	<li> it makes effective use of both cached memory and the memory bus
		between main memory and the CPU.
	<li> None of the above
	</ol>
</li><br/>
<li> The drawbacks of Port I/O include:
	<ol class="answer_list">
	<li> very slow transfers of large data amounts since they
		<strong>must</strong> read/write data in many small chunks
		(using the control registers).
	<li> the device controller data buffers cannot be utilized.
	<li> increases the number of CPU executed instructions to communicate
		with the device controller.
	<li> access to the control registers <strong>must</strong> be
		restricted/protected.
	<li> None of the above
	</ol>
</li><br/>
<li> The drawbacks of Memory-Mapped I/O include:
	<ol class="answer_list">
	<li> caching <strong>must</strong> be disabled for memory mapped
		control registers.
	<li> the device controller data buffers cannot be utilized.
	<li> increases the number of CPU executed instructions to communicate
		with the device controller.
	<li> the MMU <strong>must</strong> determine which bus to use
		(based on the address) if there's a dedicated bus between
		the CPU and main memory in addition to the system bus. 
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following uses the CPU to copy data into (or out of) memory
	from a device (e.g., HDD) using a tight read/write loop?
	<ol class="answer_list">
	<li> Programmed I/O
	<li> Memory-Mapped I/O
	<li> Device to Device copy (D2D)
	<li> Direct Memory Access (DMA)
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following has the CPU setup and initiate the copying of
	data into (or out of) memory, but the CPU is free to do other actions
	while the copying occurs?
	<ol class="answer_list">
	<li> Programmed I/O
	<li> Memory-Mapped I/O
	<li> Device to Device copy (D2D)
	<li> Direct Memory Access (DMA)
	<li> None of the above
	</ol>
</li><br/>
<li> If a system has a Direct Memory Access (DMA) capability, the process of
	writing a particular set of data directly to memory (or a device),
	instead of going through the DMA, is called
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> When the Direct Memory Access (DMA) transfers a chunk of data a single
	word at a time, by grabbing the system bus for short periods of time,
	this is called
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> When the Direct Memory Access (DMA) transfers a chunk of data
	<strong>all</strong> at once, this is called
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following makes efficient use of the system bus when large
	amounts of data <strong>must</strong> be transferred by the
	Direct Memory Access (DMA) unit?
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following makes efficient use of both the CPU and system bus
        when a single word of data <strong>must</strong> be
        transferred by the Direct Memory Access (DMA) unit?
	<ol class="answer_list">
	<li> burst mode.
	<li> direct mode.
	<li> fly-by mode.
	<li> cycle stealing.
	<li> None of the above
	</ol>
</li><br/>
<li> Device controllers generate interrupts by
	<ol class="answer_list">
	<li> writing specific values to the control registers.
	<li> having the CPU periodically check/ping each controller.
	<li> using the Direct Memory Access (DMA) unit to write a special
		value into a variable the OS kernel monitors.
	<li> putting a specific signal on the system bus.
	<li> None of the above
	</ol>
</li><br/>
<li> An interrupt is serviced only if
	<ol class="answer_list">
	<li> no other interrupts are currently being handled.
	<li> there's no process currently running in the CPU.
	<li> no higher-priority interrupts are simultaneously received.
	<li> the system bus is currently operating in direct mode.
	<li> None of the above
	</ol>
</li><br/>
<li> The value that the interrupt controller puts on the system bus address
	lines represents
	<ol class="answer_list">
	<li> an index into the interrupt vector.
	<li> the priority of the interrupt.
	<li> the time-stamp of when the interrupt occurred.
	<li> the beginning address of the interrupt handler.
	<li> None of the above
	</ol>
</li><br/>
<li> The interrupt vector is an array that holds
	<ol class="answer_list">
	<li> the priorities of the different kinds of interrupts (the
		interrupt number used as the array index).
	<li> a list of the currently pending interrupts as a queue.
	<li> references to the set of control registers associated with
		the device that generates that interrupt (the interrupt
		number is used as the array index). 
	<li> the beginning address of the interrupt handler for
		<strong>all</strong> possible interrupts (the interrupt number
		is used as the array index).
	<li> None of the above
	</ol>
</li><br/>
<li> When the interrupt controller handles an interrupt it 
	<ol class="answer_list">
	<li> interrupts the CPU.
	<li> prompts the CPU to save the state of the current process
		<em>before</em> running the interrupt handler.
	<li> restores the state of the previous process to the CPU
		<em>after</em> the interrupt handler finishes.
	<li> runs the next process from the ready "queue"
		<em>after</em> the interrupt handler finishes.
	<li> None of the above
	</ol>
</li><br/>
<li> Interrupts for which the instructions <em>before</em> the program counter
	(PC) have <strong>all</strong> been completed and those
	appearing <em>after</em> the PC have NOT been completed, are called
	<ol class="answer_list">
	<li> precision interrupts.
	<li> precise interrupts.
	<li> imprecise interrupts.
	<li> ambiguous interrupts.
	<li> None of the above
	</ol>
</li><br/>
<li> Interrupts for which some instructions <em>before</em> the PC may NOT
	have completed, while some instructions <em>after</em> the PC may
	been have completed, are called
	<ol class="answer_list">
	<li> precision interrupts.
	<li> precise interrupts.
	<li> imprecise interrupts.
	<li> ambiguous interrupts.
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following are <strong>not</strong> goals of I/O software?
	<ol class="answer_list">
	<li> Handling errors at the lowest level possible.
	<li> Making programs independent of the actual device(s) used.
	<li> Supporting device names that are independent of the actual
		device(s) used.
	<li> When practical, using buffering for block device communications.
	<li> None of the above
	</ol>
</li><br/>
<li> Asynchronous I/O 
	<ol class="answer_list">
	<li> can be made to look synchronous by the OS.
	<li> is often easier to program with.
	<li> is generally enabled by Direct Memory Access (DMA).
	<li> typically enables other actions to be performed while the I/O
		is occurring.
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O uses the CPU to directly perform the reading/writing of
	data to/from devices?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O is the simplest in design, but prevents the CPU from
	doing other work while I/O is occurring?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O may require the copying of data from a user's address
	space to the kernel address space?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O often reads/writes data from/to a device a single
	byte at a time using a tight loop run by the CPU?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O software uses polling to determine whether or not
	a device is ready for the piece of data to be read/written?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O blocks the reading/writing process so that no time is
	spent busy waiting?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>
<li> Which type of I/O makes the most efficient use of the CPU resource when
	large chunks of data <strong>must</strong> be read/written?
	<ol class="answer_list">
	<li> Directed I/O
	<li> Programmed I/O
	<li> Interrupt-Driven I/O
	<li> I/O via DMA
	<li> None of the above
	</ol>
</li><br/>

<li> Which of the following are part of the 4 layers of I/O software?
	<ol class="answer_list">
	<li> Device controller firmware
	<li> Interrupt handlers
	<li> Device drivers
	<li> User level I/O software
	<li> None of the above
	</ol>
</li><br/>
<li> An easy and efficient way to deal with I/O interrupts from devices is to
	<ol class="answer_list">
	<li> <strong>always</strong> use Direct Memory Access (DMA) for I/O
		so that interrupts aren't generated.
	<li> have the device driver block when I/O is initiated, so the
		interrupt handler simply unblocks the driver when the interrupt
		is received.
	<li> let the device driver run as part of the OS so that a full
		context switch isn't necessary when an interrupt unblocks a
		device driver.
	<li> combine the interrupt handler and device driver into a single
		user level system call so that <strong>all</strong> parts of
		the I/O software stack are run as a single unit.
	<li> None of the above
	</ol>
</li><br/>
<li> Device driver code, particularly in the consumer market, is most commonly
	<ol class="answer_list">
	<li> installed on the device controller.
	<li> compiled into the OS.
	<li> dynamically loaded into the OS.
	<li> no longer needed as all device manufacturers are moving to a
		single standard API.
	<li> None of the above
	</ol>
</li><br/>
<li> The device dependent code for performing I/O resides in which I/O software
	layer(s)?
	<ol class="answer_list">
	<li> Device controller firmware
	<li> Interrupt handlers
	<li> Device drivers
	<li> User level I/O software
	<li> None of the above
	</ol>
</li><br/>
<li> Devices drivers are
	<ol class="answer_list">
	<li> normally provided by the device manufacturer, but usually only
		for the most popular OSs.
	<li> <strong>always</strong> written to block during an I/O operation.
	<li> often run as part of the OS kernel, to avoid the overhead of a
		full context switch.
	<li> coded using static variables to reduce the size of the run-time
		stack, since the device driver only services one request at
		a time.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following help make I/O software independent of the specific
	device being used?
	<ol class="answer_list">
	<li> Using file names as the names for devices.
	<li> Controlling access to devices through file ownership and access
		permissions.
	<li> Adherence to a common and uniform Application Programming
		Interface (API).
	<li> Enable user programs, via system calls, to access specialized
		features of devices via manufacturer specific control codes.
	<li> None of the above
	</ol>
</li><br/>
<li> Device independent capabilities generally include mechanisms to control:
	<ol class="answer_list">
	<li> interrupt delay and timeouts.
	<li> buffering.
	<li> error reporting.
	<li> device acquisition and release.
	<li> the device data block size.
	<li> None of the above
	</ol>
</li><br/>
<li> Spooling (simultaneous peripheral operations on-line) is a technique that
	<ol class="answer_list">
	<li> uses buffering to prevent slow devices (e.g., printers) from
		making the CPU busy wait.
	<li> allows non-shareable devices to be used serial, but appear to
		user software as if they are being shared.
	<li> is only used in conjunction with printing devices.
	<li> uses a single program to operate a non-shareable device.
	<li> None of the above
	</ol>
</li><br/>
<li> System calls (e.g., read, write) and library routines (e.g., fprintf)
	are provided by which I/O software layer.
	<ol class="answer_list">
	<li> Device controller firmware
	<li> Interrupt handlers
	<li> Device drivers
	<li> User level I/O software
	<li> None of the above
	</ol>
</li><br/>

<li> On a keyboard, an interrupt is generated
	<ol class="answer_list">
	<li> only when a key is pressed.
	<li> only when a key is released.
	<li> every N milliseconds (as configured by the device driver) for as
		long as the key is held down.
	<li> once when the key is pressed, and once when it is released.
	<li> None of the above
	</ol>
</li><br/>
<li> A device driver for supporting keyboards that passes along every typed
	character (including backspacing) supports input in
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> None of the above
	</ol>
</li><br/>
<li> Which device driver mode for supporting keyboards works
	<strong>best</strong> for full screen editors (e.g., vi, emacs)?
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> None of the above
	</ol>
</li><br/>
<li> Which device driver mode for supporting keyboards works
	<strong>best</strong> for command line programs (e.g., shell)?
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> None of the above
	</ol>
</li><br/>
<li> The device driver approach for supporting keyboards that is character
	oriented is also called
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> raw mode.
	<li> cooked mode.
	<li> None of the above
	</ol>
</li><br/>
<li> The device driver approach for supporting keyboards that is line
	oriented is also called
	<ol class="answer_list">
	<li> canonical mode.
	<li> non-canonical mode.
	<li> half-duplex mode.
	<li> full-duplex mode.
	<li> raw mode.
	<li> cooked mode.
	<li> None of the above
	</ol>
</li><br/>
<li> For a mouse, an interrupt is generated
	<ol class="answer_list">
	<li> each time a button is pressed.
	<li> each time a button is released.
	<li> every 40 milliseconds (as configured by the device driver)
		regardless of what the user does with the mouse.
	<li> whenever the mouse has traveled a predetermined minimum distance.
	<li> None of the above
	</ol>
</li><br/>
<li> Mouse input, unlike keyboard input, 
	<ol class="answer_list">
	<li> only supports raw mode.
	<li> only supports cooked mode.
	<li> supports both raw and cooked modes.
	<li> doesn't support either raw or cooked modes, but uses echoing
		instead. 
	<li> None of the above
	</ol>
</li><br/>
<li> While touch screens operate much the same way that mice do, a notable
	difference is that
	<ol class="answer_list">
	<li> mice have button(s) that can be pressed and released, whereas
		touch screens do <strong>not</strong> have a comparable
		capability.
	<li> mice suffer fromm the ghosting problem, whereas touch screens
		do <strong>not</strong>.
	<li> touch screens supply the absolute position of a touch instead of
		the relative position which mice provide.
	<li> touch screens can support multitouch whereas mice do
		<strong>not</strong> have a comparable capability.
	<li> None of the above
	</ol>
</li><br/>
<li> In order to support multitouch, touch screens should provide a continuous
	stream of position data 
	<ol class="answer_list">
	<li> in order to create the relative position data that it needs. 
	<li> to avoid the ghosting problem (i.e., the touch position is
		ambiguous).
	<li> otherwise data reported at discrete time increments will be
		understood as multiple separate touches (e.g., mouse clicks).
	<li> to prevent echoing, in which a single touch point may look like
		multiple touches.
	<li> None of the above
	</ol>
</li><br/>
<li> Text (or terminal) windows use
	<ol class="answer_list">
	<li> special character sequences to position the cursor and perform
		text insertion and deletion.
	<li> mixed sized text and different font styles to support document
		processing (e.g., Microsoft Word).
	<li> terminal capability (termcap) libraries to provide device
		independent support.
	<li> the raw scan codes from the keyboard, which is why they were
		commonly used on early computers.
	<li> None of the above
	</ol>
</li><br/>
<li> X11 is a windowing system
	<ol class="answer_list">
	<li> commonly used by Linux based systems.
	<li> allows programs to be run on one computer, with the display and
		interaction occurring on another computer.
	<li> uses a client-server model to separate the program's GUI operation
		from the rest of the program.
	<li> that is event driven. 
	<li> None of the above
	</ol>
</li><br/>
<li> Microsoft Windows and X11 differ in that
	<ol class="answer_list">
	<li> X11 is implemented as part of the OS kernel.
	<li> X11 user programs <strong>must</strong> explicitly coordinate the
		communication between the client and server components.
	<li> Microsoft Windows is portable and relatively easy to maintain.
	<li> Microsoft Windows combines the windowing and GUI elements together
		within the OS.
	<li> None of the above
	</ol>
</li><br/>
<li> Graphical User Interfaces (GUIs) are characterized by their use of
	<ol class="answer_list">
	<li> Windows
	<li> Icons
	<li> Menus
	<li> Pointing devices
	<li> None of the above
	</ol>
</li><br/>
<li> Unlike text windows, graphical user interfaces (GUIs)
	<ol class="answer_list">
	<li> are slower since they <strong>must</strong> use Programmed I/O.
	<li> require a graphics processing unit (GPU) be part of the hardware.
	<li> leverage a common graphical API (e.g., OpenGL) to make the
		software more portable.
	<li> <strong>must</strong> use the integerated graphics provided by
		the computer hardware (on the motherboard).
	<li> None of the above
	</ol>
</li><br/>

<li> Computer clocks and timers controlled by the OS are used to
	<ol class="answer_list">
	<li> support preemptive process/thread scheduling.
	<li> control the speed at which the CPU performs instructions.
	<li> time order independent (serializable) events.
	<li> prevent any simultaneous actions occurring within the computer.
	<li> None of the above
	</ol>
</li><br/>
<li> The computer clock hardware uses a crystal (tuned to a specific frequency) 
	to
	<ol class="answer_list">
	<li> cause a special register to count down to 0, which then
		generates an interrupt.
	<li> cause a special register to count the number of ticks since the
		epoch.
	<li> directly generate timing interrupts for the computer.
	<li> None of the above
	</ol>
</li><br/>
<li> Programmable clocks
	<ol class="answer_list">
	<li> can be used as a complete replacement for clock hardware.
	<li> are able to generate periodic clock interrupts.
	<li> read the special clock register value, and perform specific
		actions when particular values are reached.
	<li> alter the starting value of the special clock register to
		control the interval between clock generated interrupts.
	<li> None of the above
	</ol>
</li><br/>
<li> The calendar date and "wall" clock time are calculated
	<ol class="answer_list">
	<li> based on the number of clock ticks (usually in microseconds)
		since a specific starting date and time.
	<li> by keeping track of the years, days (0-365), hours (0-24),
		minutes (0-60), and seconds (0-60)
		that have elapsed based on regular clock interrupts. 
	<li> on a daily (24 hour clock) basis at midnight, with the time each
		day kept as a count of the microseconds since the last day.
	<li> by contacting an internet based time keeping service whenever
		the current date and time is needed.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are <strong>not</strong> a usual responsibility
	of a clock (device) driver?
	<ol class="answer_list">
	<li> preventing processes from running too long.
	<li> collecting profiling and statistics information on processes.
	<li> maintaining the time of day.
	<li> providing watchdog timers.
	<li> None of the above
	</ol>
</li><br/>
<li> Which of the following are functionality often supported by
	the clock (device) driver?
	<ol class="answer_list">
	<li> Polling of some input devices (e.g., mice, touch screens).
	<li> CPU accounting.
	<li> Software profiling.
	<li> Watchdog timers.
	<li> None of the above
	</ol>
</li><br/>
<li> To keep track of the time of day, the OS typically
	<ol class="answer_list">
	<li> keeps track of the year, the day within the year, and
		the number of milliseconds within the current day.
	<li> keeps track of the year and counts the number of microseconds
		 within the current year.
	<li> keeps track of the year and counts the number of clock ticks
		 within the current year.
	<li> counts the number of clock ticks since the epoch.
	<li> None of the above
	</ol>
</li><br/>
<li> Watchdog timers often use a direct procedure call rather than causing a
	signal because
	<ol class="answer_list">
	<li> they are just another type of clock, and usually call an alarm
		procedure that in turn generates the signal.
	<li> as a special type of alarm, they are only used within the same
		process.
	<li> for user processes, it reduces the lag between the timer firing
		and the associated work being performed.
	<li> it's faster and the call is for kernel processes so the watchdog
		doesn't need to do a context switch.
	<li> None of the above
	</ol>
</li><br/>
<li> Alarms are set using a system call and are usually implemented as a
	<ol class="answer_list">
	<li> sorted queue of times when an interrupt should be generated.
	<li> special register that holds the next alarm time. However, only
		one alarm can be set/active at a time.
	<li> separate process that the clock (device) driver signals on a
		periodic basis.
	<li> set of count down registers, with a separate register
		corresponding to each alarm.
	<li> None of the above
	</ol>
</li><br/>
<li> Alarms can be implemented using either absolute or relative times.
	<ol class="answer_list">
	<li> Absolute times are more accurate since using relative times allows
		small inaccuracies in alarm activations to grow over time.
	<li> Relative times are preferred since even the 64 bit registers of
		modern computers are <strong>not always</strong> large enough
		to hold the appropriate absolute time relative to the epoch.
	<li> Relative times provide greater precision and accuracy than
		absolute times.
	<li> The are no advantages of using either absolute or relative times
		over the other for implementing alarms.
	<li> None of the above
	</ol>
</li><br/>
<li> A simple but less accurate way to implement CPU accounting for processes
	is to have a single counter associated with each process in the
	proc_table, incrementing the counter for the currently running process
	whenever
	<ol class="answer_list">
	<li> an interrupt handler is started. The counter value divided by the
		sum of <strong>all</strong> such values, is the proportion of
		the CPU the process has used.
	<li> the process uses its full time quantum. Charging the process 1.5
		times the counter value.
	<li> the process becomes blocked. Charging the process 0.5 times the
		counter value.
	<li> a clock tick occurs.  Charging the currently running process for
		the full clock tick.
	<li> None of the above
	</ol>
</li><br/>
<li> If a timer with an additional, but different, frequency than the main
	system timer is needed, and accuracy to within 20 microseconds is
	sufficient, which of the following is an efficient solution?
	<ol class="answer_list">
	<li> Use an ALARM system call that resets every time it is triggered. 
	<li> Have a separate process poll the system clock, triggering an
		event when the desired (recurring) time interval is reached.
	<li> Use a "soft timer" based on the frequent running of the OS
		kernel to check for the desired time interval.
	<li> Adjust the starting value of the programmable clock to correspond
		to the alternate frequency.
	<li> None of the above
	</ol>
</li><br/>

</ol>

<hr/>
<em>
<a href="mailto:eckart_dana@columbusstate.edu?subject=web_pages" style="float: left">eckart_dana@columbusstate.edu</a>
<a href="/eckart/classes/cpsc3125" style="float: right">CPSC 3125</a>
</em>

</body>
</html>

